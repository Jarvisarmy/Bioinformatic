{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab6012ad",
   "metadata": {},
   "source": [
    "https://github.com/SenticNet/context2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f91a3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6816218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from pycorrector.deepcontext.infer import Inference\n",
    "from pycorrector.deepcontext.preprocess import parse_xml_file, save_corpus_data, get_data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3cf5c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# required parameters\n",
    "\n",
    "parser.add_argument(\"--raw_train_path\",\n",
    "                    default=\"../pycorrector/data/cn/sighan_2015/train.tsv\", type=str,\n",
    "                    help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\",\n",
    "                    )\n",
    "\n",
    "parser.add_argument(\"--dataset\", default=\"sighan\", type=str,\n",
    "                    help=\"Dataset name. selected in the list:\" + \", \".join([\"sighan\", \"cged\"])\n",
    "                    )\n",
    "parser.add_argument(\"--no_segment\", action=\"store_true\", default=True, help=\"Whether not to segment train data in preprocess\")\n",
    "parser.add_argument(\"--do_train\", action=\"store_true\", default=True,help=\"Whether not to train\")\n",
    "parser.add_argument(\"--do_predict\", action=\"store_true\", default=True,help=\"Whether not to predict\")\n",
    "parser.add_argument(\"--segment_type\", default=\"char\", type=str,\n",
    "                    help=\"Segment data type, selected in list: \" + \", \".join([\"char\", \"word\"]))\n",
    "parser.add_argument(\"--model_dir\", default=\"output/models/\", type=str, help=\"Dir for model save.\")\n",
    "parser.add_argument(\"--train_path\", default=\"output/train.txt\", type=str, help=\"Train file after preprocess.\")\n",
    "parser.add_argument(\"--vocab_path\", default=\"output/vocab.txt\", type=str, help=\"Vocab file for train data.\")\n",
    "\n",
    "# Other parameters\n",
    "parser.add_argument(\"--batch_size\", default=8, type=int, help=\"Batch size.\")\n",
    "parser.add_argument(\"--embed_size\", default=128, type=int, help=\"Embedding size.\")\n",
    "parser.add_argument(\"--hidden_size\", default=128, type=int, help=\"Hidden size.\")\n",
    "parser.add_argument(\"--learning_rate\", default=1e-3, type=float, help=\"Learning rate.\")\n",
    "parser.add_argument(\"--n_layers\", default=2, type=int, help=\"Num layers.\")\n",
    "parser.add_argument(\"--min_freq\", default=1, type=int, help=\"Mini word frequency.\")\n",
    "parser.add_argument(\"--dropout\", default=0.0, type=float, help=\"Dropout rate.\")\n",
    "parser.add_argument(\"--epochs\", default=20, type=int, help=\"Epoch num.\")\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b967978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from xml.dom import minidom\n",
    "\n",
    "sys.path.append('../..')\n",
    "from pycorrector.utils.tokenizer import segment\n",
    "from pycorrector.deepcontext import config\n",
    "\n",
    "\n",
    "def parse_xml_file(path, use_segment, segment_type):\n",
    "    print('Parse data from %s' % path)\n",
    "    word_arr = []\n",
    "    dom_tree = minidom.parse(path)\n",
    "    docs = dom_tree.documentElement.getElementsByTagName('DOC')\n",
    "    for doc in docs:\n",
    "        # Input the text\n",
    "        text = doc.getElementsByTagName('CORRECTION')[0]. \\\n",
    "            childNodes[0].data.strip()\n",
    "        # Segment\n",
    "        word_seq = ' '.join(segment(text.strip(), cut_type=segment_type)) if use_segment else text.strip()\n",
    "        word_arr.append(word_seq)\n",
    "    return word_arr\n",
    "\n",
    "\n",
    "def get_data_file(path, use_segment, segment_type):\n",
    "    data_list = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            parts = line.split(\"\\t\")\n",
    "            if len(parts) != 2:\n",
    "                continue\n",
    "            target = ' '.join(segment(parts[1].strip(), cut_type=segment_type)) if use_segment else parts[1].strip()\n",
    "            data_list.append(target)\n",
    "    return data_list\n",
    "\n",
    "\n",
    "def save_corpus_data(data_list, data_path):\n",
    "    dirname = os.path.dirname(data_path)\n",
    "    os.makedirs(dirname, exist_ok=True)\n",
    "    with open(data_path, 'w', encoding='utf-8') as f:\n",
    "        count = 0\n",
    "        for line in data_list:\n",
    "            f.write(line + '\\n')\n",
    "            count += 1\n",
    "        print(\"save line size:%d to %s\" % (count, data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a1fd431",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.no_segment = True\n",
    "args.segment_type = \"char\"\n",
    "args.use_segment = False if args.no_segment else True\n",
    "data = get_data_file(\"../pycorrector/data/RNA/train\", args.use_segment, args.segment_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "629a057a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASP ALA ILE ALA ASP ALA SER LYS ARG PHE SER ASP ALA THR TYR PRO ILE ALA GLU LYS PHE ASP TRP GLY GLY SER SER ALA ILE ALA LYS TYR ILE ALA ASP ALA SER ALA GLY ASN PRO ARG GLN ALA ALA LEU ALA VAL GLU LYS LEU LEU GLU VAL GLY LEU THR MET ASP PRO LYS LEU VAL ARG ALA ALA VAL GLU ALA HIS SER LYS ALA LEU ASP SER ALA LYS LYS ASN ALA LYS LEU MET ALA SER LYS GLU ASP PHE ALA ALA VAL ASN GLU ALA LEU ALA ARG MET ILE ALA SER ALA ASP LYS GLN LYS PHE ALA ALA LEU ARG THR ALA PHE PRO GLU SER ARG GLU LEU GLN GLY LYS LEU PHE ALA GLY ASN ASN ALA PHE GLU ALA GLU LYS ALA TYR ASP SER PHE LYS ALA LEU THR SER ALA VAL ARG ASP ALA SER ILE ASN GLY ALA LYS ALA PRO VAL ILE ALA GLU ALA ALA ARG ALA GLU ARG TYR VAL GLY ASP GLY PRO VAL GLY ARG ALA ALA LYS LYS PHE SER GLU ALA THR TYR PRO ILE MET ASP LYS LEU ASP TRP GLY LYS SER PRO GLU ILE SER LYS TYR ILE GLU THR ALA SER ALA LYS ASN PRO LYS MET MET ALA ASP GLY ILE ASP LYS THR LEU GLU VAL ALA LEU THR MET ASN GLN ASN ALA ILE ASN ASP ALA VAL PHE ALA HIS VAL ARG ALA ILE LYS GLY ALA LEU ASN THR PRO GLY LEU VAL ALA GLU ARG ASP ASP PHE ALA ARG VAL ASN LEU ALA LEU ALA LYS MET ILE ALA THR ALA ASP PRO ALA LYS PHE LYS ALA LEU LEU THR ALA PHE PRO GLY ASN ALA ASP LEU GLN MET ALA LEU PHE ALA ALA ASN ASN PRO GLU GLN ALA LYS ALA ALA TYR GLU THR PHE VAL ALA LEU THR SER ALA VAL ALA SER SER THR\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfc5efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "from pycorrector.deepcontext import config\n",
    "from pycorrector.deepcontext.data_reader import write_config\n",
    "from pycorrector.deepcontext.model import Context2vec\n",
    "from pycorrector.deepcontext.dataset import Dataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def train(train_path,\n",
    "          model_dir,\n",
    "          vocab_path,\n",
    "          batch_size=64,\n",
    "          epochs=3,\n",
    "          word_embed_size=200,\n",
    "          hidden_size=200,\n",
    "          learning_rate=0.0001,\n",
    "          n_layers=1,\n",
    "          min_freq=1,\n",
    "          dropout=0.0):\n",
    "    print(\"device: {}\".format(device))\n",
    "    if not os.path.isfile(train_path):\n",
    "        raise FileNotFoundError\n",
    "\n",
    "    print('Loading input file')\n",
    "    dataset = Dataset(train_path,\n",
    "                      batch_size,\n",
    "                      min_freq,\n",
    "                      device,\n",
    "                      vocab_path)\n",
    "    counter = np.array([dataset.word_freqs[word] for word in dataset.vocab_2_ids])\n",
    "    model = Context2vec(vocab_size=len(dataset.vocab_2_ids),\n",
    "                        counter=counter,\n",
    "                        word_embed_size=word_embed_size,\n",
    "                        hidden_size=hidden_size,\n",
    "                        n_layers=n_layers,\n",
    "                        use_mlp=True,\n",
    "                        dropout=dropout,\n",
    "                        pad_index=dataset.pad_index,\n",
    "                        device=device,\n",
    "                        is_inference=False).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    print('batch_size:', batch_size, 'epochs:', epochs, 'word_embed_size:', word_embed_size, 'hidden_size:',\n",
    "          hidden_size, 'device:', device)\n",
    "    print('model:', model)\n",
    "\n",
    "    # save model config\n",
    "    output_config_file = os.path.join(model_dir, 'config.json')\n",
    "    write_config(output_config_file,\n",
    "                 vocab_size=len(dataset.vocab_2_ids),\n",
    "                 word_embed_size=word_embed_size,\n",
    "                 hidden_size=hidden_size,\n",
    "                 n_layers=n_layers,\n",
    "                 use_mlp=True,\n",
    "                 dropout=dropout,\n",
    "                 pad_index=dataset.pad_index,\n",
    "                 pad_token=dataset.pad_token,\n",
    "                 unk_token=dataset.unk_token,\n",
    "                 sos_token=dataset.sos_token,\n",
    "                 eos_token=dataset.eos_token,\n",
    "                 learning_rate=learning_rate\n",
    "                 )\n",
    "\n",
    "    interval = 1e5\n",
    "    best_loss = 1e3\n",
    "    print(\"train start...\")\n",
    "    for epoch in range(epochs):\n",
    "        begin_time = time.time()\n",
    "        cur_at = begin_time\n",
    "        total_loss = 0.0\n",
    "        word_count = 0\n",
    "        next_count = interval\n",
    "        last_accum_loss = 0.0\n",
    "        last_word_count = 0\n",
    "        cur_loss = 0\n",
    "        for it, (mb_x, mb_x_len) in enumerate(dataset.train_data):\n",
    "            sentence = torch.from_numpy(mb_x).to(device).long()\n",
    "\n",
    "            target = sentence[:, 1:-1]\n",
    "            if target.size(0) == 0:\n",
    "                continue\n",
    "            optimizer.zero_grad()\n",
    "            loss = model(sentence, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.data.mean()\n",
    "\n",
    "            minibatch_size, sentence_length = target.size()\n",
    "            word_count += minibatch_size * sentence_length\n",
    "            accum_mean_loss = float(total_loss) / word_count if total_loss > 0.0 else 0.0\n",
    "            cur_mean_loss = (float(total_loss) - last_accum_loss) / (word_count - last_word_count)\n",
    "            cur_loss = cur_mean_loss\n",
    "            if word_count >= next_count:\n",
    "                now = time.time()\n",
    "                duration = now - cur_at\n",
    "                throuput = float((word_count - last_word_count)) / (now - cur_at)\n",
    "                print('{} words, {:.2f} sec, {:.2f} words/sec, {:.4f} accum_loss/word, {:.4f} cur_loss/word'\n",
    "                      .format(word_count, duration, throuput, accum_mean_loss, cur_mean_loss))\n",
    "                next_count += interval\n",
    "                cur_at = now\n",
    "                last_accum_loss = float(total_loss)\n",
    "                last_word_count = word_count\n",
    "\n",
    "        # find best model\n",
    "        is_best = cur_loss < best_loss\n",
    "        best_loss = min(cur_loss, best_loss)\n",
    "        print('epoch:[{}/{}], total_loss:[{}], best_cur_loss:[{}]'\n",
    "              .format(epoch + 1, epochs, total_loss.item(), best_loss))\n",
    "        if is_best:\n",
    "            torch.save(model.state_dict(), os.path.join(model_dir, 'model.pth'))\n",
    "            torch.save(optimizer.state_dict(), os.path.join(model_dir, 'model_optimizer.pth'))\n",
    "            print('epoch:{}, save new bert model:{}'.format(epoch + 1, model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d878461b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save line size:1000 to output/train.txt\n",
      "device: cpu\n",
      "Loading input file\n",
      "batch_size: 8 epochs: 20 word_embed_size: 128 hidden_size: 128 device: cpu\n",
      "model: Context2vec(\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      "  (l2r_emb): Embedding(23, 128, padding_idx=0)\n",
      "  (l2r_rnn): LSTM(128, 128, num_layers=2, batch_first=True)\n",
      "  (r2l_emb): Embedding(23, 128, padding_idx=0)\n",
      "  (r2l_rnn): LSTM(128, 128, num_layers=2, batch_first=True)\n",
      "  (criterion): NegativeSampling(\n",
      "    (W): Embedding(23, 128, padding_idx=0)\n",
      "    (logsigmoid): LogSigmoid()\n",
      "  )\n",
      "  (MLP): MLP(\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (MLP): ModuleList(\n",
      "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (1): Linear(in_features=256, out_features=128, bias=True)\n",
      "    )\n",
      "    (activation_function): ReLU()\n",
      "  )\n",
      ")\n",
      "train start...\n",
      "102080 words, 17.85 sec, 5720.01 words/sec, 3.7169 accum_loss/word, 3.7169 cur_loss/word\n",
      "203064 words, 34.31 sec, 2943.09 words/sec, 2.2126 accum_loss/word, 0.6920 cur_loss/word\n",
      "301376 words, 15.98 sec, 6150.83 words/sec, 1.7166 accum_loss/word, 0.6920 cur_loss/word\n",
      "405312 words, 18.84 sec, 5516.19 words/sec, 1.4539 accum_loss/word, 0.6921 cur_loss/word\n",
      "500296 words, 16.30 sec, 5826.15 words/sec, 1.3092 accum_loss/word, 0.6921 cur_loss/word\n",
      "epoch:[1/20], total_loss:[687152.8125], best_cur_loss:[0.6917896113119835]\n",
      "epoch:1, save new bert model:output/models/\n",
      "102080 words, 16.10 sec, 6341.06 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "203064 words, 15.34 sec, 6582.94 words/sec, 0.6921 accum_loss/word, 0.6920 cur_loss/word\n",
      "301376 words, 15.02 sec, 6545.14 words/sec, 0.6920 accum_loss/word, 0.6920 cur_loss/word\n",
      "405312 words, 17.10 sec, 6077.17 words/sec, 0.6920 accum_loss/word, 0.6921 cur_loss/word\n",
      "500296 words, 15.03 sec, 6318.81 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "epoch:[2/20], total_loss:[378379.3125], best_cur_loss:[0.6917896113119835]\n",
      "102080 words, 15.79 sec, 6463.26 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "203064 words, 15.92 sec, 6342.07 words/sec, 0.6921 accum_loss/word, 0.6920 cur_loss/word\n",
      "301376 words, 15.17 sec, 6479.47 words/sec, 0.6920 accum_loss/word, 0.6920 cur_loss/word\n",
      "405312 words, 16.16 sec, 6430.03 words/sec, 0.6920 accum_loss/word, 0.6921 cur_loss/word\n",
      "500296 words, 14.70 sec, 6462.53 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "epoch:[3/20], total_loss:[378379.3125], best_cur_loss:[0.6917896113119835]\n",
      "102080 words, 17.01 sec, 6001.35 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "203064 words, 16.25 sec, 6216.21 words/sec, 0.6921 accum_loss/word, 0.6920 cur_loss/word\n",
      "301376 words, 15.84 sec, 6205.00 words/sec, 0.6920 accum_loss/word, 0.6920 cur_loss/word\n",
      "405312 words, 16.80 sec, 6185.37 words/sec, 0.6920 accum_loss/word, 0.6921 cur_loss/word\n",
      "500296 words, 15.29 sec, 6213.17 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "epoch:[4/20], total_loss:[378379.3125], best_cur_loss:[0.6917896113119835]\n",
      "102080 words, 16.59 sec, 6153.45 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "203064 words, 16.37 sec, 6168.80 words/sec, 0.6921 accum_loss/word, 0.6920 cur_loss/word\n",
      "301376 words, 15.79 sec, 6226.49 words/sec, 0.6920 accum_loss/word, 0.6920 cur_loss/word\n",
      "405312 words, 16.84 sec, 6173.24 words/sec, 0.6920 accum_loss/word, 0.6921 cur_loss/word\n",
      "500296 words, 15.32 sec, 6201.14 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "epoch:[5/20], total_loss:[378379.3125], best_cur_loss:[0.6917896113119835]\n",
      "102080 words, 16.65 sec, 6129.14 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "203064 words, 16.22 sec, 6224.01 words/sec, 0.6921 accum_loss/word, 0.6920 cur_loss/word\n",
      "301376 words, 15.75 sec, 6243.87 words/sec, 0.6920 accum_loss/word, 0.6920 cur_loss/word\n",
      "405312 words, 17.24 sec, 6029.40 words/sec, 0.6920 accum_loss/word, 0.6921 cur_loss/word\n",
      "500296 words, 15.47 sec, 6140.48 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "epoch:[6/20], total_loss:[378379.3125], best_cur_loss:[0.6917896113119835]\n",
      "102080 words, 16.63 sec, 6138.33 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "203064 words, 16.38 sec, 6166.82 words/sec, 0.6921 accum_loss/word, 0.6920 cur_loss/word\n",
      "301376 words, 16.18 sec, 6076.81 words/sec, 0.6920 accum_loss/word, 0.6920 cur_loss/word\n",
      "405312 words, 16.84 sec, 6172.60 words/sec, 0.6920 accum_loss/word, 0.6921 cur_loss/word\n",
      "500296 words, 15.45 sec, 6147.72 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "epoch:[7/20], total_loss:[378379.3125], best_cur_loss:[0.6917896113119835]\n",
      "102080 words, 16.70 sec, 6111.69 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "203064 words, 16.43 sec, 6148.05 words/sec, 0.6921 accum_loss/word, 0.6920 cur_loss/word\n",
      "301376 words, 15.87 sec, 6193.60 words/sec, 0.6920 accum_loss/word, 0.6920 cur_loss/word\n",
      "405312 words, 17.01 sec, 6111.30 words/sec, 0.6920 accum_loss/word, 0.6921 cur_loss/word\n",
      "500296 words, 15.51 sec, 6125.23 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "epoch:[8/20], total_loss:[378379.3125], best_cur_loss:[0.6917896113119835]\n",
      "102080 words, 16.61 sec, 6146.47 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "203064 words, 16.27 sec, 6207.77 words/sec, 0.6921 accum_loss/word, 0.6920 cur_loss/word\n",
      "301376 words, 16.17 sec, 6078.17 words/sec, 0.6920 accum_loss/word, 0.6920 cur_loss/word\n",
      "405312 words, 16.89 sec, 6152.86 words/sec, 0.6920 accum_loss/word, 0.6921 cur_loss/word\n",
      "500296 words, 15.34 sec, 6193.31 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "epoch:[9/20], total_loss:[378379.3125], best_cur_loss:[0.6917896113119835]\n",
      "102080 words, 17.23 sec, 5924.79 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "203064 words, 15.74 sec, 6415.53 words/sec, 0.6921 accum_loss/word, 0.6920 cur_loss/word\n",
      "301376 words, 15.13 sec, 6496.40 words/sec, 0.6920 accum_loss/word, 0.6920 cur_loss/word\n",
      "405312 words, 16.17 sec, 6427.86 words/sec, 0.6920 accum_loss/word, 0.6921 cur_loss/word\n",
      "500296 words, 14.68 sec, 6470.77 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "epoch:[10/20], total_loss:[378379.3125], best_cur_loss:[0.6917896113119835]\n",
      "102080 words, 15.91 sec, 6416.52 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "203064 words, 15.62 sec, 6466.03 words/sec, 0.6921 accum_loss/word, 0.6920 cur_loss/word\n",
      "301376 words, 15.12 sec, 6501.68 words/sec, 0.6920 accum_loss/word, 0.6920 cur_loss/word\n",
      "405312 words, 16.30 sec, 6375.50 words/sec, 0.6920 accum_loss/word, 0.6921 cur_loss/word\n",
      "500296 words, 14.69 sec, 6466.45 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "epoch:[11/20], total_loss:[378379.3125], best_cur_loss:[0.6917896113119835]\n",
      "102080 words, 16.32 sec, 6253.78 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "203064 words, 15.61 sec, 6467.37 words/sec, 0.6921 accum_loss/word, 0.6920 cur_loss/word\n",
      "301376 words, 15.24 sec, 6451.50 words/sec, 0.6920 accum_loss/word, 0.6920 cur_loss/word\n",
      "405312 words, 16.19 sec, 6419.32 words/sec, 0.6920 accum_loss/word, 0.6921 cur_loss/word\n",
      "500296 words, 14.72 sec, 6451.52 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "epoch:[12/20], total_loss:[378379.3125], best_cur_loss:[0.6917896113119835]\n",
      "102080 words, 15.88 sec, 6427.55 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "203064 words, 15.65 sec, 6451.49 words/sec, 0.6921 accum_loss/word, 0.6920 cur_loss/word\n",
      "301376 words, 15.22 sec, 6458.82 words/sec, 0.6920 accum_loss/word, 0.6920 cur_loss/word\n",
      "405312 words, 16.23 sec, 6403.04 words/sec, 0.6920 accum_loss/word, 0.6921 cur_loss/word\n",
      "500296 words, 14.78 sec, 6425.26 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "epoch:[13/20], total_loss:[378379.3125], best_cur_loss:[0.6917896113119835]\n",
      "102080 words, 15.96 sec, 6394.15 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "203064 words, 15.71 sec, 6426.52 words/sec, 0.6921 accum_loss/word, 0.6920 cur_loss/word\n",
      "301376 words, 15.37 sec, 6398.01 words/sec, 0.6920 accum_loss/word, 0.6920 cur_loss/word\n",
      "405312 words, 16.17 sec, 6428.68 words/sec, 0.6920 accum_loss/word, 0.6921 cur_loss/word\n",
      "500296 words, 14.67 sec, 6476.82 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "epoch:[14/20], total_loss:[378379.3125], best_cur_loss:[0.6917896113119835]\n",
      "102080 words, 16.00 sec, 6381.51 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203064 words, 15.66 sec, 6446.53 words/sec, 0.6921 accum_loss/word, 0.6920 cur_loss/word\n",
      "301376 words, 15.22 sec, 6458.01 words/sec, 0.6920 accum_loss/word, 0.6920 cur_loss/word\n",
      "405312 words, 16.18 sec, 6424.97 words/sec, 0.6920 accum_loss/word, 0.6921 cur_loss/word\n",
      "500296 words, 15.06 sec, 6306.11 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "epoch:[15/20], total_loss:[378379.3125], best_cur_loss:[0.6917896113119835]\n",
      "102080 words, 15.95 sec, 6398.20 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "203064 words, 15.63 sec, 6462.03 words/sec, 0.6921 accum_loss/word, 0.6920 cur_loss/word\n",
      "301376 words, 15.22 sec, 6457.57 words/sec, 0.6920 accum_loss/word, 0.6920 cur_loss/word\n",
      "405312 words, 16.14 sec, 6438.97 words/sec, 0.6920 accum_loss/word, 0.6921 cur_loss/word\n",
      "500296 words, 14.66 sec, 6478.72 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "epoch:[16/20], total_loss:[378379.3125], best_cur_loss:[0.6917896113119835]\n",
      "102080 words, 15.99 sec, 6385.24 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "203064 words, 15.70 sec, 6433.94 words/sec, 0.6921 accum_loss/word, 0.6920 cur_loss/word\n",
      "301376 words, 15.18 sec, 6475.24 words/sec, 0.6920 accum_loss/word, 0.6920 cur_loss/word\n",
      "405312 words, 16.23 sec, 6403.46 words/sec, 0.6920 accum_loss/word, 0.6921 cur_loss/word\n",
      "500296 words, 14.74 sec, 6443.08 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "epoch:[17/20], total_loss:[378379.3125], best_cur_loss:[0.6917896113119835]\n",
      "102080 words, 16.08 sec, 6350.02 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "203064 words, 15.65 sec, 6453.32 words/sec, 0.6921 accum_loss/word, 0.6920 cur_loss/word\n",
      "301376 words, 15.27 sec, 6438.97 words/sec, 0.6920 accum_loss/word, 0.6920 cur_loss/word\n",
      "405312 words, 16.19 sec, 6420.24 words/sec, 0.6920 accum_loss/word, 0.6921 cur_loss/word\n",
      "500296 words, 14.73 sec, 6450.13 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "epoch:[18/20], total_loss:[378379.3125], best_cur_loss:[0.6917896113119835]\n",
      "102080 words, 15.97 sec, 6392.44 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "203064 words, 15.68 sec, 6440.33 words/sec, 0.6921 accum_loss/word, 0.6920 cur_loss/word\n",
      "301376 words, 15.31 sec, 6422.50 words/sec, 0.6920 accum_loss/word, 0.6920 cur_loss/word\n",
      "405312 words, 16.17 sec, 6427.80 words/sec, 0.6920 accum_loss/word, 0.6921 cur_loss/word\n",
      "500296 words, 14.76 sec, 6436.84 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "epoch:[19/20], total_loss:[378379.3125], best_cur_loss:[0.6917896113119835]\n",
      "102080 words, 16.47 sec, 6199.58 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n",
      "203064 words, 15.73 sec, 6421.77 words/sec, 0.6921 accum_loss/word, 0.6920 cur_loss/word\n",
      "301376 words, 15.38 sec, 6391.38 words/sec, 0.6920 accum_loss/word, 0.6920 cur_loss/word\n",
      "405312 words, 16.44 sec, 6323.77 words/sec, 0.6920 accum_loss/word, 0.6921 cur_loss/word\n",
      "500296 words, 16.10 sec, 5900.81 words/sec, 0.6921 accum_loss/word, 0.6921 cur_loss/word\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:46:04.355 | DEBUG    | pycorrector.deepcontext.infer:__init__:31 - device: cpu\n",
      "2022-08-30 17:46:04.397 | DEBUG    | pycorrector.deepcontext.infer:__init__:43 - Loaded deep context model: output/models/, spend: 0.042 s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[20/20], total_loss:[378379.3125], best_cur_loss:[0.6917896113119835]\n",
      "input  : ASP ALA ILE ALA ASP ALA SER LYS ARG PHE SER ASP ALA THR TYR PRO ILE ALA GLU LYS PHE ASP TRP GLY GLY SER SER ALA ILE ALA LYS TYR ILE ALA ASP ALA SER ALA GLY ASN PRO ARG GLN ALA ALA LEU ALA VAL GLU LYS LEU LEU GLU VAL GLY LEU THR MET ASP PRO LYS LEU VAL ARG ALA ALA VAL GLU ALA HIS SER LYS ALA LEU ASP SER ALA LYS LYS ASN ALA LYS LEU MET ALA SER LYS GLU ASP PHE ALA ALA VAL ASN GLU ALA LEU ALA ARG MET ILE ALA SER ALA ASP LYS GLN LYS PHE ALA ALA LEU ARG THR ALA PHE PRO GLU SER ARG GLU LEU GLN GLY LYS LEU PHE ALA GLY ASN ASN ALA PHE GLU ALA GLU LYS ALA TYR ASP SER PHE LYS ALA LEU THR SER ALA VAL ARG ASP ALA SER ILE ASN GLY ALA LYS ALA PRO VAL ILE ALA GLU ALA ALA ARG ALA GLU ARG TYR VAL GLY ASP GLY PRO VAL GLY ARG ALA ALA LYS LYS PHE SER GLU ALA THR TYR PRO ILE MET ASP LYS LEU ASP TRP GLY LYS SER PRO GLU ILE SER LYS TYR ILE GLU THR ALA SER ALA LYS ASN PRO LYS MET MET ALA ASP GLY ILE ASP LYS THR LEU GLU VAL ALA LEU THR MET ASN GLN ASN ALA ILE ASN ASP ALA VAL PHE ALA HIS VAL ARG ALA ILE LYS GLY ALA LEU ASN THR PRO GLY LEU VAL ALA GLU ARG ASP ASP PHE ALA ARG VAL ASN LEU ALA LEU ALA LYS MET ILE ALA THR ALA ASP PRO ALA LYS PHE LYS ALA LEU LEU THR ALA PHE PRO GLY ASN ALA ASP LEU GLN MET ALA LEU PHE ALA ALA ASN ASN PRO GLU GLN ALA LYS ALA ALA TYR GLU THR PHE VAL ALA LEU THR SER ALA VAL ALA SER SER THR\n",
      "predict: ('ASP ALA ILE ALA ASP ALA SER LYS ARG PHE SER ASP ALA THR TYR PRO ILE ALA GLU LYS PHE ASP TRP GLY GLY SER SER ALA ILE ALA LYS TYR ILE ALA ASP ALA SER ALA GLY ASN PRO ARG GLN ALA ALA LEU ALA VAL GLU LYS LEU LEU GLU VAL GLY LEU THR MET ASP PRO LYS LEU VAL ARG ALA ALA VAL GLU ALA HIS SER LYS ALA LEU ASP SER ALA LYS LYS ASN ALA LYS LEU MET ALA SER LYS GLU ASP PHE ALA ALA VAL ASN GLU ALA LEU ALA ARG MET ILE ALA SER ALA ASP LYS GLN LYS PHE ALA ALA LEU ARG THR ALA PHE PRO GLU SER ARG GLU LEU GLN GLY LYS LEU PHE ALA GLY ASN ASN ALA PHE GLU ALA GLU LYS ALA TYR ASP SER PHE LYS ALA LEU THR SER ALA VAL ARG ASP ALA SER ILE ASN GLY ALA LYS ALA PRO VAL ILE ALA GLU ALA ALA ARG ALA GLU ARG TYR VAL GLY ASP GLY PRO VAL GLY ARG ALA ALA LYS LYS PHE SER GLU ALA THR TYR PRO ILE MET ASP LYS LEU ASP TRP GLY LYS SER PRO GLU ILE SER LYS TYR ILE GLU THR ALA SER ALA LYS ASN PRO LYS MET MET ALA ASP GLY ILE ASP LYS THR LEU GLU VAL ALA LEU THR MET ASN GLN ASN ALA ILE ASN ASP ALA VAL PHE ALA HIS VAL ARG ALA ILE LYS GLY ALA LEU ASN THR PRO GLY LEU VAL ALA GLU ARG ASP ASP PHE ALA ARG VAL ASN LEU ALA LEU ALA LYS MET ILE ALA THR ALA ASP PRO ALA LYS PHE LYS ALA LEU LEU THR ALA PHE PRO GLY ASN ALA ASP LEU GLN MET ALA LEU PHE ALA ALA ASN ASN PRO GLU GLN ALA LYS ALA ALA TYR GLU THR PHE VAL ALA LEU THR SER ALA VAL ALA SER SER THR', [])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Preprocess\n",
    "    os.makedirs(args.model_dir, exist_ok=True)\n",
    "\n",
    "    # Train\n",
    "    if args.do_train:\n",
    "        # Preprocess\n",
    "        args.use_segment = False if args.no_segment else True\n",
    "        data_list = []\n",
    "        '''\n",
    "        if args.dataset == 'sighan':\n",
    "            data_list.extend(get_data_file(args.raw_train_path, args.use_segment, args.segment_type))\n",
    "        else:\n",
    "            data_list.extend(parse_xml_file(args.raw_train_path, args.use_segment, args.segment_type))\n",
    "        '''\n",
    "        data_list.extend(get_data_file(\"../pycorrector/data/RNA/train\", args.use_segment, args.segment_type)[:1000])\n",
    "        save_corpus_data(data_list, args.train_path)\n",
    "        \n",
    "\n",
    "        # Train model with train data file\n",
    "        train(args.train_path,\n",
    "              args.model_dir,\n",
    "              args.vocab_path,\n",
    "              batch_size=args.batch_size,\n",
    "              epochs=args.epochs,\n",
    "              word_embed_size=args.embed_size,\n",
    "              hidden_size=args.hidden_size,\n",
    "              learning_rate=args.learning_rate,\n",
    "              n_layers=args.n_layers,\n",
    "              min_freq=args.min_freq,\n",
    "              dropout=args.dropout\n",
    "              )\n",
    "\n",
    "    # Predict\n",
    "    if args.do_predict:\n",
    "        inference = Inference(args.model_dir, args.vocab_path)\n",
    "        inputs = [\n",
    "            'ASP ALA ILE ALA ASP ALA SER LYS ARG PHE SER ASP ALA THR TYR PRO ILE ALA GLU LYS PHE ASP TRP GLY GLY SER SER ALA ILE ALA LYS TYR ILE ALA ASP ALA SER ALA GLY ASN PRO ARG GLN ALA ALA LEU ALA VAL GLU LYS LEU LEU GLU VAL GLY LEU THR MET ASP PRO LYS LEU VAL ARG ALA ALA VAL GLU ALA HIS SER LYS ALA LEU ASP SER ALA LYS LYS ASN ALA LYS LEU MET ALA SER LYS GLU ASP PHE ALA ALA VAL ASN GLU ALA LEU ALA ARG MET ILE ALA SER ALA ASP LYS GLN LYS PHE ALA ALA LEU ARG THR ALA PHE PRO GLU SER ARG GLU LEU GLN GLY LYS LEU PHE ALA GLY ASN ASN ALA PHE GLU ALA GLU LYS ALA TYR ASP SER PHE LYS ALA LEU THR SER ALA VAL ARG ASP ALA SER ILE ASN GLY ALA LYS ALA PRO VAL ILE ALA GLU ALA ALA ARG ALA GLU ARG TYR VAL GLY ASP GLY PRO VAL GLY ARG ALA ALA LYS LYS PHE SER GLU ALA THR TYR PRO ILE MET ASP LYS LEU ASP TRP GLY LYS SER PRO GLU ILE SER LYS TYR ILE GLU THR ALA SER ALA LYS ASN PRO LYS MET MET ALA ASP GLY ILE ASP LYS THR LEU GLU VAL ALA LEU THR MET ASN GLN ASN ALA ILE ASN ASP ALA VAL PHE ALA HIS VAL ARG ALA ILE LYS GLY ALA LEU ASN THR PRO GLY LEU VAL ALA GLU ARG ASP ASP PHE ALA ARG VAL ASN LEU ALA LEU ALA LYS MET ILE ALA THR ALA ASP PRO ALA LYS PHE LYS ALA LEU LEU THR ALA PHE PRO GLY ASN ALA ASP LEU GLN MET ALA LEU PHE ALA ALA ASN ASN PRO GLU GLN ALA LYS ALA ALA TYR GLU THR PHE VAL ALA LEU THR SER ALA VAL ALA SER SER THR'\n",
    "        ]\n",
    "        for i in inputs:\n",
    "            output = inference.predict(i)\n",
    "            print('input  :', i)\n",
    "            print('predict:', output)\n",
    "            print()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee327949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:48:12.242 | DEBUG    | pycorrector.deepcontext.infer:__init__:31 - device: cpu\n",
      "2022-08-30 17:48:12.272 | DEBUG    | pycorrector.deepcontext.infer:__init__:43 - Loaded deep context model: output/models/, spend: 0.030 s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input  : ALA ALA ALA ALA ASP ALA SER LYS ARG PHE ALA ASP ALA THR TYR PRO ILE ALA GLU LYS PHE ASP TRP GLY GLY SER SER ALA ILE ALA LYS TYR ILE ALA ASP ALA SER ALA GLY ASN PRO ARG GLN ALA ALA LEU ALA VAL GLU LYS LEU LEU GLU VAL GLY LEU THR MET ASP PRO LYS LEU VAL ARG ALA ALA VAL GLU ALA HIS SER LYS ALA LEU ASP SER ALA LYS LYS ASN ALA LYS LEU MET ALA SER LYS GLU ASP PHE ALA ALA VAL ASN GLU ALA LEU ALA ARG MET ILE ALA SER ALA ASP LYS GLN LYS PHE ALA ALA LEU ARG THR ALA PHE PRO GLU SER ARG GLU LEU GLN GLY LYS LEU PHE ALA GLY ASN ASN ALA PHE GLU ALA GLU LYS ALA TYR ASP SER PHE LYS ALA LEU THR SER ALA VAL ARG ASP ALA SER ILE ASN GLY ALA LYS ALA PRO VAL ILE ALA GLU ALA ALA ARG ALA GLU ARG TYR VAL GLY ASP GLY PRO VAL GLY ARG ALA ALA LYS LYS PHE SER GLU ALA THR TYR PRO ILE MET ASP LYS LEU ASP TRP GLY LYS SER PRO GLU ILE SER LYS TYR ILE GLU THR ALA SER ALA LYS ASN PRO LYS MET MET ALA ASP GLY ILE ASP LYS THR LEU GLU VAL ALA LEU THR MET ASN GLN ASN ALA ILE ASN ASP ALA VAL PHE ALA HIS VAL ARG ALA ILE LYS GLY ALA LEU ASN THR PRO GLY LEU VAL ALA GLU ARG ASP ASP PHE ALA ARG VAL ASN LEU ALA LEU ALA LYS MET ILE ALA THR ALA ASP PRO ALA LYS PHE LYS ALA LEU LEU THR ALA PHE PRO GLY ASN ALA ASP LEU GLN MET ALA LEU PHE ALA ALA ASN ASN PRO GLU GLN ALA LYS ALA ALA TYR GLU THR PHE VAL ALA LEU THR SER ALA VAL ALA SER SER THR\n",
      "predict: ('ALA ALA ALA ALA ASP ALA SER LYS ARG PHE ALA ASP ALA THR TYR PRO ILE ALA GLU LYS PHE ASP TRP GLY GLY SER SER ALA ILE ALA LYS TYR ILE ALA ASP ALA SER ALA GLY ASN PRO ARG GLN ALA ALA LEU ALA VAL GLU LYS LEU LEU GLU VAL GLY LEU THR MET ASP PRO LYS LEU VAL ARG ALA ALA VAL GLU ALA HIS SER LYS ALA LEU ASP SER ALA LYS LYS ASN ALA LYS LEU MET ALA SER LYS GLU ASP PHE ALA ALA VAL ASN GLU ALA LEU ALA ARG MET ILE ALA SER ALA ASP LYS GLN LYS PHE ALA ALA LEU ARG THR ALA PHE PRO GLU SER ARG GLU LEU GLN GLY LYS LEU PHE ALA GLY ASN ASN ALA PHE GLU ALA GLU LYS ALA TYR ASP SER PHE LYS ALA LEU THR SER ALA VAL ARG ASP ALA SER ILE ASN GLY ALA LYS ALA PRO VAL ILE ALA GLU ALA ALA ARG ALA GLU ARG TYR VAL GLY ASP GLY PRO VAL GLY ARG ALA ALA LYS LYS PHE SER GLU ALA THR TYR PRO ILE MET ASP LYS LEU ASP TRP GLY LYS SER PRO GLU ILE SER LYS TYR ILE GLU THR ALA SER ALA LYS ASN PRO LYS MET MET ALA ASP GLY ILE ASP LYS THR LEU GLU VAL ALA LEU THR MET ASN GLN ASN ALA ILE ASN ASP ALA VAL PHE ALA HIS VAL ARG ALA ILE LYS GLY ALA LEU ASN THR PRO GLY LEU VAL ALA GLU ARG ASP ASP PHE ALA ARG VAL ASN LEU ALA LEU ALA LYS MET ILE ALA THR ALA ASP PRO ALA LYS PHE LYS ALA LEU LEU THR ALA PHE PRO GLY ASN ALA ASP LEU GLN MET ALA LEU PHE ALA ALA ASN ASN PRO GLU GLN ALA LYS ALA ALA TYR GLU THR PHE VAL ALA LEU THR SER ALA VAL ALA SER SER THR', [])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inference = Inference(args.model_dir, args.vocab_path)\n",
    "inputs = [\n",
    "    'ALA ALA ALA ALA ASP ALA SER LYS ARG PHE ALA ASP ALA THR TYR PRO ILE ALA GLU LYS PHE ASP TRP GLY GLY SER SER ALA ILE ALA LYS TYR ILE ALA ASP ALA SER ALA GLY ASN PRO ARG GLN ALA ALA LEU ALA VAL GLU LYS LEU LEU GLU VAL GLY LEU THR MET ASP PRO LYS LEU VAL ARG ALA ALA VAL GLU ALA HIS SER LYS ALA LEU ASP SER ALA LYS LYS ASN ALA LYS LEU MET ALA SER LYS GLU ASP PHE ALA ALA VAL ASN GLU ALA LEU ALA ARG MET ILE ALA SER ALA ASP LYS GLN LYS PHE ALA ALA LEU ARG THR ALA PHE PRO GLU SER ARG GLU LEU GLN GLY LYS LEU PHE ALA GLY ASN ASN ALA PHE GLU ALA GLU LYS ALA TYR ASP SER PHE LYS ALA LEU THR SER ALA VAL ARG ASP ALA SER ILE ASN GLY ALA LYS ALA PRO VAL ILE ALA GLU ALA ALA ARG ALA GLU ARG TYR VAL GLY ASP GLY PRO VAL GLY ARG ALA ALA LYS LYS PHE SER GLU ALA THR TYR PRO ILE MET ASP LYS LEU ASP TRP GLY LYS SER PRO GLU ILE SER LYS TYR ILE GLU THR ALA SER ALA LYS ASN PRO LYS MET MET ALA ASP GLY ILE ASP LYS THR LEU GLU VAL ALA LEU THR MET ASN GLN ASN ALA ILE ASN ASP ALA VAL PHE ALA HIS VAL ARG ALA ILE LYS GLY ALA LEU ASN THR PRO GLY LEU VAL ALA GLU ARG ASP ASP PHE ALA ARG VAL ASN LEU ALA LEU ALA LYS MET ILE ALA THR ALA ASP PRO ALA LYS PHE LYS ALA LEU LEU THR ALA PHE PRO GLY ASN ALA ASP LEU GLN MET ALA LEU PHE ALA ALA ASN ASN PRO GLU GLN ALA LYS ALA ALA TYR GLU THR PHE VAL ALA LEU THR SER ALA VAL ALA SER SER THR'\n",
    "]\n",
    "for i in inputs:\n",
    "    output = inference.predict(i)\n",
    "    print('input  :', i)\n",
    "    print('predict:', output)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8a0ab3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ('a', 'b')}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_two_strings(a,b):\n",
    "    res = {}\n",
    "    for i, (ca, cb) in enumerate(zip(a,b)):\n",
    "        if ca!=cb:\n",
    "            res[i] = (ca,cb)\n",
    "    return res\n",
    "compare_two_strings(\"a\",\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a02a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
