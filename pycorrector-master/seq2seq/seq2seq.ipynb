{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bbf3c2f",
   "metadata": {},
   "source": [
    "# install all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58213b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20cb4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b4a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fbf512",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install loguru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1c2b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2213d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypinyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42bf554",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09782ad",
   "metadata": {},
   "source": [
    "# SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "006b3936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import operator\n",
    "from sklearn.model_selection import train_test_split\n",
    "sys.path.append('../')\n",
    "sys.path.append('../..')\n",
    "#from pycorrector.seq2seq.data_reader import *\n",
    "#from pycorrector.seq2seq.train import *\n",
    "#from pycorrector.seq2seq.infer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3ce4d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--raw_train_path\",\n",
    "                    default=\"../pycorrector/data/cn/sighan_2015/train.tsv\", type=str,\n",
    "                    help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\",\n",
    "                    )\n",
    "parser.add_argument(\"--dataset\", default=\"sighan\", type=str,\n",
    "                    help=\"Dataset name. selected in the list:\" + \", \".join([\"sighan\", \"cged\"])\n",
    "                    )\n",
    "parser.add_argument(\"--use_segment\", action=\"store_true\", help=\"Whether not to segment train data\")\n",
    "parser.add_argument(\"--do_preprocess\", action=\"store_true\", default=\"True\",help=\"Whether not to preprocess train data\")\n",
    "parser.add_argument(\"--segment_type\", default=\"char\", type=str,\n",
    "                        help=\"Segment data type, selected in list: \" + \", \".join([\"char\", \"word\"]))\n",
    "parser.add_argument(\"--model_name_or_path\",\n",
    "                    default=\"bert-base-chinese\", type=str,\n",
    "                    help=\"Path to pretrained model or model identifier from huggingface.co/models\",\n",
    "                    )\n",
    "parser.add_argument(\"--model_dir\", default=\"output/RNA/\", type=str, help=\"Dir for model save.\")\n",
    "parser.add_argument(\"--arch\", default=\"seq2seq\", type=str,\n",
    "                    help=\"The name of the task to train selected in the list: \" + \", \".join(\n",
    "                        ['seq2seq', 'convseq2seq', 'bertseq2seq']),\n",
    "                    )\n",
    "parser.add_argument(\"--train_path\", default=\"output/train.txt\", type=str, help=\"Train file after preprocess.\")\n",
    "parser.add_argument(\"--test_path\", default=\"output/test.txt\", type=str, help=\"Test file after preprocess.\")\n",
    "parser.add_argument(\"--max_length\", default=128, type=int,\n",
    "                    help=\"The maximum total input sequence length after tokenization. \\n\"\n",
    "                            \"Sequences longer than this will be truncated, sequences shorter padded.\",\n",
    "                    )\n",
    "parser.add_argument(\"--batch_size\", default=32, type=int, help=\"Batch size.\")\n",
    "parser.add_argument(\"--embed_size\", default=128, type=int, help=\"Embedding size.\")\n",
    "parser.add_argument(\"--hidden_size\", default=128, type=int, help=\"Hidden size.\")\n",
    "parser.add_argument(\"--dropout\", default=0.25, type=float, help=\"Dropout rate.\")\n",
    "parser.add_argument(\"--epochs\", default=10, type=int, help=\"Epoch num.\")\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35b7943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f95f03",
   "metadata": {},
   "source": [
    "# preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "497f6463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_file(path, use_segment, segment_type):\n",
    "    data_list = []\n",
    "    if not os.path.exists(path):\n",
    "        print('%s not exists' % path)\n",
    "        return data_list\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            parts = line.split(\"\\t\")\n",
    "            if len(parts) != 2:\n",
    "                continue\n",
    "            source = ' '.join(segment(parts[0].strip(), cut_type=segment_type)) if use_segment else parts[0].strip()\n",
    "            target = ' '.join(segment(parts[1].strip(), cut_type=segment_type)) if use_segment else parts[1].strip()\n",
    "\n",
    "            pair = [source, target]\n",
    "            if pair not in data_list:\n",
    "                data_list.append(pair)\n",
    "    return data_list\n",
    "\n",
    "\n",
    "def _save_data(data_list, data_path):\n",
    "    dirname = os.path.dirname(data_path)\n",
    "    os.makedirs(dirname, exist_ok=True)\n",
    "    with open(data_path, 'w', encoding='utf-8') as f:\n",
    "        count = 0\n",
    "        for src, dst in data_list:\n",
    "            f.write(src + '\\t' + dst + '\\n')\n",
    "            count += 1\n",
    "        print(\"save line size:%d to %s\" % (count, data_path))\n",
    "\n",
    "\n",
    "def save_corpus_data(data_list, train_data_path, test_data_path):\n",
    "    train_lst, test_lst = train_test_split(data_list, test_size=0.1)\n",
    "    _save_data(train_lst, train_data_path)\n",
    "    _save_data(test_lst, test_data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e086b810",
   "metadata": {},
   "source": [
    "# data_reader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7611ef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants associated with the usual special tokens.\n",
    "SOS_TOKEN = '<sos>'\n",
    "EOS_TOKEN = '<eos>'\n",
    "UNK_TOKEN = '<unk>'\n",
    "PAD_TOKEN = '<pad>'\n",
    "class CscDataset(object):\n",
    "    def __init__(self, file_path):\n",
    "        self.data = json.load(open(file_path, 'r', encoding='utf-8'))\n",
    "\n",
    "    def load(self):\n",
    "        data_list = []\n",
    "        for item in self.data:\n",
    "            data_list.append(item['original_text'] + '\\t' + item['correct_text'])\n",
    "        return data_list\n",
    "\n",
    "def create_dataset(path, num_examples=None, split_on_space=False):\n",
    "    if path.endswith('.json'):\n",
    "        d = CscDataset(path)\n",
    "        lines = d.load()\n",
    "    else:\n",
    "        lines = open(path, 'r', encoding='utf-8').read().strip().split('\\n')\n",
    "    word_pairs = [[preprocess_sentence(s, split_on_space) for s in l.split('\\t')] for l in lines[:num_examples]]\n",
    "    return zip(*word_pairs)\n",
    "\n",
    "\n",
    "def preprocess_sentence(sentence, split_on_space=False):\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    return [SOS_TOKEN] + sentence.split() if split_on_space else list(sentence) + [EOS_TOKEN]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aab244fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "'''\n",
    "class Counter(object):\n",
    "    def __init__(self):\n",
    "        self.counter = {}\n",
    "    def update(self, token):\n",
    "'''    \n",
    "\n",
    "\n",
    "def save_word_dict(dict_data, save_path):\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        for k, v in dict_data.items():\n",
    "            f.write(\"%s\\t%d\\n\" % (k, v))\n",
    "\n",
    "\n",
    "def load_word_dict(save_path):\n",
    "    dict_data = dict()\n",
    "    num = 0\n",
    "    with open(save_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip('\\n')\n",
    "            items = line.split('\\t')\n",
    "            num += 1\n",
    "            try:\n",
    "                dict_data[items[0]] = int(items[1])\n",
    "            except IndexError:\n",
    "                logger.error('IndexError, index:%s, line:%s' % (num, line))\n",
    "    return dict_data\n",
    "def read_vocab(input_texts, max_size=None, min_count=0):\n",
    "    token_counts = Counter()\n",
    "    special_tokens = [PAD_TOKEN, UNK_TOKEN, SOS_TOKEN, EOS_TOKEN]\n",
    "    '''\n",
    "    for texts in input_texts:\n",
    "        for token in texts:\n",
    "            token_counts.update(token)\n",
    "    '''\n",
    "    for texts in input_texts:\n",
    "        for token in texts:\n",
    "            token_counts.update(token)\n",
    "    # Sort word count by value\n",
    "    count_pairs = token_counts.most_common()\n",
    "    vocab = [k for k, v in count_pairs if v >= min_count]\n",
    "    print(vocab)\n",
    "    # Insert the special tokens to the beginning\n",
    "    vocab[0:0] = special_tokens\n",
    "    full_token_id = list(zip(vocab, range(len(vocab))))[:max_size]\n",
    "    vocab2id = dict(full_token_id)\n",
    "    return vocab2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04dc4dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(seqs, max_length=None):\n",
    "    if max_length:\n",
    "        seqs = [seq[:max_length] for seq in seqs]\n",
    "    lengths = [len(seq) for seq in seqs]\n",
    "    n_samples = len(seqs)\n",
    "    max_len = np.max(lengths)\n",
    "\n",
    "    x = np.zeros((n_samples, max_len)).astype('int32')\n",
    "    x_lengths = np.array(lengths).astype(\"int32\")\n",
    "    for idx, seq in enumerate(seqs):\n",
    "        x[idx, :lengths[idx]] = seq\n",
    "    return x, x_lengths  # x_mask\n",
    "def get_minibatches(n, minibatch_size, shuffle=True):\n",
    "    idx_list = np.arange(0, n, minibatch_size)  # [0, 1, ..., n-1]\n",
    "    if shuffle:\n",
    "        np.random.shuffle(idx_list)\n",
    "    minibatches = []\n",
    "    for idx in idx_list:\n",
    "        minibatches.append(np.arange(idx, min(idx + minibatch_size, n)))\n",
    "    return minibatches\n",
    "def gen_examples(src_sentences, trg_sentences, batch_size, max_length=None):\n",
    "    minibatches = get_minibatches(len(src_sentences), batch_size)\n",
    "    examples = []\n",
    "    for minibatch in minibatches:\n",
    "        mb_src_sentences = [src_sentences[t] for t in minibatch]\n",
    "        mb_trg_sentences = [trg_sentences[t] for t in minibatch]\n",
    "        mb_x, mb_x_len = prepare_data(mb_src_sentences, max_length)\n",
    "        mb_y, mb_y_len = prepare_data(mb_trg_sentences, max_length)\n",
    "        examples.append((mb_x, mb_x_len, mb_y, mb_y_len))\n",
    "    return examples\n",
    "def one_hot(src_sentences, trg_sentences, src_dict, trg_dict, sort_by_len=True):\n",
    "    \"\"\"vector the sequences.\n",
    "    \"\"\"\n",
    "\n",
    "    out_src_sentences = [[src_dict.get(w, 0) for w in sent] for sent in src_sentences]\n",
    "    out_trg_sentences = [[trg_dict.get(w, 0) for w in sent] for sent in trg_sentences]\n",
    "\n",
    "    # sort sentences by english lengths\n",
    "    def len_argsort(seq):\n",
    "        return sorted(range(len(seq)), key=lambda x: len(seq[x]))\n",
    "\n",
    "    # sort length\n",
    "    if sort_by_len:\n",
    "        sorted_index = len_argsort(out_src_sentences)\n",
    "        out_src_sentences = [out_src_sentences[i] for i in sorted_index]\n",
    "        out_trg_sentences = [out_trg_sentences[i] for i in sorted_index]\n",
    "\n",
    "    return out_src_sentences, out_trg_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d8d5ff",
   "metadata": {},
   "source": [
    "# seq2se2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d076ddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author:XuMing(xuming624@qq.com)\n",
    "@description: \n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, enc_hidden_size, dec_hidden_size, dropout=0.2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        '''\n",
    "            torch.nn.Embedding(numembeddings, embeddingdim)\n",
    "                * numembeddings代表一共有多少个词\n",
    "                * embedding_dim代表每个词创建一个多少维的向量来表示他\n",
    "        '''\n",
    "        self.rnn = nn.GRU(embed_size, enc_hidden_size, batch_first=True, bidirectional=True)\n",
    "        '''\n",
    "            torch.nn.GRU(input_size, hidden_size, num_layers, bias,batch_first,dropout,bidirectional)\n",
    "                * input_size: the number of expected features in the input x\n",
    "                * hidden_size: the number of features in the hidden state h\n",
    "                * batch_first: if True, then (batch, seq, feature), else (seq, batch, feature)\n",
    "                * bidirectional: if True, becomes a bidirectional GRU. Default: False\n",
    "            \n",
    "        '''\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(enc_hidden_size * 2, dec_hidden_size)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # 将x根据长度来排序\n",
    "        sorted_len, sorted_idx = lengths.sort(0, descending=True)\n",
    "        x_sorted = x[sorted_idx.long()]\n",
    "        embedded = self.dropout(self.embed(x_sorted))\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, sorted_len.long().cpu().data.numpy(),\n",
    "                                                            batch_first=True)\n",
    "        '''\n",
    "            https://zhuanlan.zhihu.com/p/34418001\n",
    "            torch.nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=False,enforce_sorted=True)\n",
    "            当我们进行batch个训练数据一起计算的时候，我们会遇到多个训练样例长度不同时的情况，这样我们就会很自然的进行padding，\n",
    "            将短句子padding为跟最长的句子一样\n",
    "            \n",
    "            pytorch中RNN处理变长padding主要用torch.nn.utils.rnn.pack_padded_sequence()以及torch.nn.utils.rnn.pad_packed_sequence()来进行。\n",
    "            \n",
    "            \n",
    "            \n",
    "        '''\n",
    "        packed_out, hid = self.rnn(packed_embedded)\n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)\n",
    "        _, original_idx = sorted_idx.sort(0, descending=False)\n",
    "        out = out[original_idx.long()].contiguous()\n",
    "        hid = hid[:, original_idx.long()].contiguous()\n",
    "\n",
    "        hid = torch.cat([hid[-2], hid[-1]], dim=1)\n",
    "        hid = torch.tanh(self.fc(hid)).unsqueeze(0)\n",
    "\n",
    "        return out, hid\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    Luong Attention,根据context vectors和当前的输出hidden states，计算输出\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, enc_hidden_size, dec_hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.enc_hidden_size = enc_hidden_size\n",
    "        self.dec_hidden_size = dec_hidden_size\n",
    "\n",
    "        self.linear_in = nn.Linear(enc_hidden_size * 2, dec_hidden_size, bias=False)\n",
    "        self.linear_out = nn.Linear(enc_hidden_size * 2 + dec_hidden_size, dec_hidden_size)\n",
    "\n",
    "    def forward(self, output, context, mask):\n",
    "        # output: batch_size, output_len, dec_hidden_size\n",
    "        # context: batch_size, context_len, 2*enc_hidden_size\n",
    "\n",
    "        batch_size = output.size(0)\n",
    "        output_len = output.size(1)\n",
    "        input_len = context.size(1)\n",
    "\n",
    "        context_in = self.linear_in(context.view(batch_size * input_len, -1)).view(\n",
    "            batch_size, input_len, -1)  # batch_size, context_len, dec_hidden_size\n",
    "\n",
    "        # context_in.transpose(1,2): batch_size, dec_hidden_size, context_len\n",
    "        # output: batch_size, output_len, dec_hidden_size\n",
    "        attn = torch.bmm(output, context_in.transpose(1, 2))\n",
    "        # batch_size, output_len, context_len\n",
    "\n",
    "        attn.data.masked_fill(mask, -1e6)\n",
    "\n",
    "        attn = F.softmax(attn, dim=2)\n",
    "        # batch_size, output_len, context_len\n",
    "\n",
    "        context = torch.bmm(attn, context)\n",
    "        # batch_size, output_len, enc_hidden_size\n",
    "\n",
    "        output = torch.cat((context, output), dim=2)  # batch_size, output_len, hidden_size*2\n",
    "\n",
    "        output = output.view(batch_size * output_len, -1)\n",
    "        output = torch.tanh(self.linear_out(output))\n",
    "        output = output.view(batch_size, output_len, -1)\n",
    "        return output, attn\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    decoder会根据已经翻译的句子内容，和context vectors，来决定下一个输出的单词\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embed_size, enc_hidden_size, dec_hidden_size, dropout=0.2):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.attention = Attention(enc_hidden_size, dec_hidden_size)\n",
    "        self.rnn = nn.GRU(embed_size, enc_hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(dec_hidden_size, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def create_mask(self, x_len, y_len):\n",
    "        # a mask of shape x_len * y_len\n",
    "        max_x_len = x_len.max()\n",
    "        max_y_len = y_len.max()\n",
    "        x_mask = torch.arange(max_x_len, device=x_len.device)[None, :] < x_len[:, None]\n",
    "        y_mask = torch.arange(max_y_len, device=x_len.device)[None, :] < y_len[:, None]\n",
    "        mask = ~ x_mask[:, :, None] * y_mask[:, None, :]\n",
    "        return mask\n",
    "\n",
    "    def forward(self, ctx, ctx_lengths, y, y_lengths, hid):\n",
    "        sorted_len, sorted_idx = y_lengths.sort(0, descending=True)\n",
    "        y_sorted = y[sorted_idx.long()]\n",
    "        hid = hid[:, sorted_idx.long()]\n",
    "\n",
    "        y_sorted = self.dropout(self.embed(y_sorted))  # batch_size, output_length, embed_size\n",
    "\n",
    "        packed_seq = nn.utils.rnn.pack_padded_sequence(y_sorted, sorted_len.long().cpu().data.numpy(), batch_first=True)\n",
    "        out, hid = self.rnn(packed_seq, hid)\n",
    "        unpacked, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
    "        _, original_idx = sorted_idx.sort(0, descending=False)\n",
    "        output_seq = unpacked[original_idx.long()].contiguous()\n",
    "        hid = hid[:, original_idx.long()].contiguous()\n",
    "\n",
    "        mask = self.create_mask(y_lengths, ctx_lengths)\n",
    "\n",
    "        output, attn = self.attention(output_seq, ctx, mask)\n",
    "        output = F.log_softmax(self.out(output), -1)\n",
    "\n",
    "        return output, hid, attn\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    \"\"\"\n",
    "    Seq2Seq, 最后我们构建Seq2Seq模型把encoder, attention, decoder串到一起\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 encoder_vocab_size,\n",
    "                 decoder_vocab_size,\n",
    "                 embed_size,\n",
    "                 enc_hidden_size,\n",
    "                 dec_hidden_size,\n",
    "                 dropout,\n",
    "                 ):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = Encoder(vocab_size=encoder_vocab_size,\n",
    "                               embed_size=embed_size,\n",
    "                               enc_hidden_size=enc_hidden_size,\n",
    "                               dec_hidden_size=dec_hidden_size,\n",
    "                               dropout=dropout)\n",
    "        self.decoder = Decoder(vocab_size=decoder_vocab_size,  # len(trg_2_ids),\n",
    "                               embed_size=embed_size,\n",
    "                               enc_hidden_size=enc_hidden_size,\n",
    "                               dec_hidden_size=dec_hidden_size,\n",
    "                               dropout=dropout)\n",
    "\n",
    "    def forward(self, x, x_lengths, y, y_lengths):\n",
    "        encoder_out, hid = self.encoder(x, x_lengths)\n",
    "        output, hid, attn = self.decoder(ctx=encoder_out,\n",
    "                                         ctx_lengths=x_lengths,\n",
    "                                         y=y,\n",
    "                                         y_lengths=y_lengths,\n",
    "                                         hid=hid)\n",
    "        return output, attn\n",
    "\n",
    "    def translate(self, x, x_lengths, y, max_length=128):\n",
    "        print(len(x))\n",
    "        encoder_out, hid = self.encoder(x, x_lengths)\n",
    "        preds = []\n",
    "        batch_size = x.shape[0]\n",
    "        attns = []\n",
    "        for i in range(max_length):\n",
    "            output, hid, attn = self.decoder(ctx=encoder_out,\n",
    "                                             ctx_lengths=x_lengths,\n",
    "                                             y=y,\n",
    "                                             y_lengths=torch.ones(batch_size).long().to(y.device),\n",
    "                                             hid=hid)\n",
    "            \n",
    "            y = output.max(2)[1].view(batch_size, 1)\n",
    "            preds.append(y)\n",
    "            \n",
    "            attns.append(attn)\n",
    "        return torch.cat(preds, 1), torch.cat(attns, 1)\n",
    "\n",
    "\n",
    "class LanguageModelCriterion(nn.Module):\n",
    "    \"\"\"\n",
    "    masked cross entropy loss\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LanguageModelCriterion, self).__init__()\n",
    "\n",
    "    def forward(self, input, target, mask):\n",
    "        # input: (batch_size * seq_len) * vocab_size\n",
    "        input = input.contiguous().view(-1, input.size(2))\n",
    "        # target: batch_size * 1\n",
    "        target = target.contiguous().view(-1, 1)\n",
    "        mask = mask.contiguous().view(-1, 1)\n",
    "        output = -input.gather(1, target) * mask\n",
    "        output = torch.sum(output) / torch.sum(mask)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2057f58c",
   "metadata": {},
   "source": [
    "# infer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "249d787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_tokens = [' ', '“', '”', '‘', '’', '琊', '\\n', '…', '—', '擤', '\\t', '֍', '玕', '', '《', '》']\n",
    "\n",
    "\n",
    "def get_errors(corrected_text, origin_text):\n",
    "    sub_details = []\n",
    "    for i, ori_char in enumerate(origin_text):\n",
    "        if i >= len(corrected_text):\n",
    "            continue\n",
    "        if ori_char in unk_tokens:\n",
    "            # deal with unk word\n",
    "            corrected_text = corrected_text[:i] + ori_char + corrected_text[i:]\n",
    "            continue\n",
    "        if ori_char != corrected_text[i]:\n",
    "            sub_details.append((ori_char, corrected_text[i], i, i + 1))\n",
    "    sub_details = sorted(sub_details, key=operator.itemgetter(2))\n",
    "    return corrected_text, sub_details\n",
    "\n",
    "\n",
    "class Inference(object):\n",
    "    def __init__(self, model_dir, arch='convseq2seq',\n",
    "                 embed_size=128, hidden_size=128, dropout=0.25, max_length=128):\n",
    "        logger.debug(\"Device: {}\".format(device))\n",
    "        logger.debug(f'Use {arch} model.')\n",
    "        if arch in ['seq2seq', 'convseq2seq']:\n",
    "            src_vocab_path = os.path.join(model_dir, 'vocab_source.txt')\n",
    "            trg_vocab_path = os.path.join(model_dir, 'vocab_target.txt')\n",
    "            self.src_2_ids = load_word_dict(src_vocab_path)\n",
    "            self.trg_2_ids = load_word_dict(trg_vocab_path)\n",
    "            self.id_2_trgs = {v: k for k, v in self.trg_2_ids.items()}\n",
    "            if arch == 'seq2seq':\n",
    "                self.model = Seq2Seq(encoder_vocab_size=len(self.src_2_ids),\n",
    "                                     decoder_vocab_size=len(self.trg_2_ids),\n",
    "                                     embed_size=embed_size,\n",
    "                                     enc_hidden_size=hidden_size,\n",
    "                                     dec_hidden_size=hidden_size,\n",
    "                                     dropout=dropout).to(device)\n",
    "                model_path = os.path.join(model_dir, 'seq2seq.pth')\n",
    "                logger.debug('Load model from {}'.format(model_path))\n",
    "                self.model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "                self.model.eval()\n",
    "            else:\n",
    "                trg_pad_idx = self.trg_2_ids[PAD_TOKEN]\n",
    "                self.model = ConvSeq2Seq(encoder_vocab_size=len(self.src_2_ids),\n",
    "                                         decoder_vocab_size=len(self.trg_2_ids),\n",
    "                                         embed_size=embed_size,\n",
    "                                         enc_hidden_size=hidden_size,\n",
    "                                         dec_hidden_size=hidden_size,\n",
    "                                         dropout=dropout,\n",
    "                                         trg_pad_idx=trg_pad_idx,\n",
    "                                         device=device,\n",
    "                                         max_length=max_length).to(device)\n",
    "                model_path = os.path.join(model_dir, 'convseq2seq.pth')\n",
    "                self.model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "                logger.debug('Load model from {}'.format(model_path))\n",
    "                self.model.eval()\n",
    "        elif arch == 'bertseq2seq':\n",
    "            # Bert Seq2seq model\n",
    "            use_cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "            # encoder_type=None, encoder_name=None, decoder_name=None\n",
    "            self.model = Seq2SeqModel(\"bert\", \"{}/encoder\".format(model_dir),\n",
    "                                      \"{}/decoder\".format(model_dir), use_cuda=use_cuda)\n",
    "        else:\n",
    "            logger.error('error arch: {}'.format(arch))\n",
    "            raise ValueError(\"Model arch choose error. Must use one of seq2seq model.\")\n",
    "        self.arch = arch\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def predict(self, sentence_list):\n",
    "        result = []\n",
    "        if self.arch in ['seq2seq', 'convseq2seq']:\n",
    "            for query in sentence_list:\n",
    "                out = []\n",
    "                tokens = query.split()\n",
    "                tokens = [SOS_TOKEN] + tokens + [EOS_TOKEN]\n",
    "                src_ids = [self.src_2_ids[i] for i in tokens if i in self.src_2_ids]\n",
    "\n",
    "                sos_idx = self.trg_2_ids[SOS_TOKEN]\n",
    "                if self.arch == 'seq2seq':\n",
    "                    src_tensor = torch.from_numpy(np.array(src_ids).reshape(1, -1)).long().to(device)\n",
    "                    src_tensor_len = torch.from_numpy(np.array([len(src_ids)])).long().to(device)\n",
    "                    sos_tensor = torch.Tensor([[self.trg_2_ids[SOS_TOKEN]]]).long().to(device)\n",
    "                    translation, attn = self.model.translate(src_tensor, src_tensor_len, sos_tensor, self.max_length)\n",
    "                    translation = [self.id_2_trgs[i] for i in translation.data.cpu().numpy().reshape(-1) if\n",
    "                                   i in self.id_2_trgs]\n",
    "                else:\n",
    "                    src_tensor = torch.from_numpy(np.array(src_ids).reshape(1, -1)).long().to(device)\n",
    "                    translation, attn = self.model.translate(src_tensor, sos_idx)\n",
    "                    translation = [self.id_2_trgs[i] for i in translation if i in self.id_2_trgs]\n",
    "                for word in translation:\n",
    "                    if word != EOS_TOKEN:\n",
    "                        out.append(word)\n",
    "                    else:\n",
    "                        break\n",
    "                corrected_text = ''.join(out)\n",
    "                corrected_text, sub_details = get_errors(corrected_text, query)\n",
    "                result.append([corrected_text, sub_details])\n",
    "        else:\n",
    "            corrected_sents = self.model.predict(sentence_list)\n",
    "            corrected_sents = [i.replace(' ', '') for i in corrected_sents]\n",
    "            for c, s in zip(corrected_sents, sentence_list):\n",
    "                c = c.replace(' ', '')\n",
    "                c, sub_details = get_errors(c, s)\n",
    "                result.append([c, sub_details])\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ea9c26",
   "metadata": {},
   "source": [
    "# train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88377ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_seq2seq_model(model, data, device, loss_fn):\n",
    "    model.eval()\n",
    "    total_num_words = 0.\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for it, (mb_x, mb_x_len, mb_y, mb_y_len) in enumerate(data):\n",
    "            mb_x = torch.from_numpy(mb_x).to(device).long()\n",
    "            mb_x_len = torch.from_numpy(mb_x_len).to(device).long()\n",
    "            mb_input = torch.from_numpy(mb_y[:, :-1]).to(device).long()\n",
    "            mb_output = torch.from_numpy(mb_y[:, 1:]).to(device).long()\n",
    "            mb_y_len = torch.from_numpy(mb_y_len - 1).to(device).long()\n",
    "            mb_y_len[mb_y_len <= 0] = 1\n",
    "\n",
    "            mb_pred, attn = model(mb_x, mb_x_len, mb_input, mb_y_len)\n",
    "\n",
    "            mb_out_mask = torch.arange(mb_y_len.max().item(), device=device)[None, :] < mb_y_len[:, None]\n",
    "            mb_out_mask = mb_out_mask.float()\n",
    "\n",
    "            loss = loss_fn(mb_pred, mb_output, mb_out_mask)\n",
    "\n",
    "            num_words = torch.sum(mb_y_len).item()\n",
    "            total_loss += loss.item() * num_words\n",
    "            total_num_words += num_words\n",
    "    loss = total_loss / total_num_words\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_seq2seq_model(model, train_data, device, loss_fn, optimizer, model_dir, epochs=20):\n",
    "    best_loss = 1e3\n",
    "    train_data, dev_data = train_test_split(train_data, test_size=0.1, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_num_words = 0.\n",
    "        total_loss = 0.\n",
    "        for it, (mb_x, mb_x_len, mb_y, mb_y_len) in enumerate(train_data):\n",
    "            mb_x = torch.from_numpy(mb_x).to(device).long()\n",
    "            mb_x_len = torch.from_numpy(mb_x_len).to(device).long()\n",
    "            mb_input = torch.from_numpy(mb_y[:, :-1]).to(device).long()\n",
    "            mb_output = torch.from_numpy(mb_y[:, 1:]).to(device).long()\n",
    "            mb_y_len = torch.from_numpy(mb_y_len - 1).to(device).long()\n",
    "            mb_y_len[mb_y_len <= 0] = 1\n",
    "\n",
    "            mb_pred, attn = model(mb_x, mb_x_len, mb_input, mb_y_len)\n",
    "\n",
    "            mb_out_mask = torch.arange(mb_y_len.max().item(), device=device)[None, :] < mb_y_len[:, None]\n",
    "            mb_out_mask = mb_out_mask.float()\n",
    "\n",
    "            loss = loss_fn(mb_pred, mb_output, mb_out_mask)\n",
    "\n",
    "            num_words = torch.sum(mb_y_len).item()\n",
    "            total_loss += loss.item() * num_words\n",
    "            total_num_words += num_words\n",
    "\n",
    "            # update optimizer\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.)\n",
    "            optimizer.step()\n",
    "\n",
    "            if it % 100 == 0:\n",
    "                logger.info(\"Epoch :{}/{}, iteration :{}/{} loss:{:.4f}\".format(epoch, epochs, it, len(train_data),\n",
    "                                                                                loss.item()))\n",
    "        cur_loss = total_loss / total_num_words\n",
    "        logger.info(\"Epoch :{}/{}, training loss:{:.4f}\".format(epoch, epochs, cur_loss))\n",
    "        if epoch % 1 == 0:\n",
    "            if dev_data:\n",
    "                eval_loss = evaluate_seq2seq_model(model, dev_data, device, loss_fn)\n",
    "                logger.info('Epoch:{}, dev loss:{:.4f}'.format(epoch, eval_loss))\n",
    "                cur_loss = eval_loss\n",
    "            # find best model\n",
    "            is_best = cur_loss < best_loss\n",
    "            best_loss = min(cur_loss, best_loss)\n",
    "            if is_best:\n",
    "                model_path = os.path.join(model_dir, 'seq2seq.pth')\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                logger.info('Epoch:{}, save new bert model:{}'.format(epoch, model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2dd74a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(arch, train_path, batch_size, embed_size, hidden_size, dropout, epochs,\n",
    "          model_dir, max_length, use_segment, model_name_or_path):\n",
    "    logger.info(\"device: {}\".format(device))\n",
    "    arch = arch.lower()\n",
    "    logger.debug(f'use {arch} model.')\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    if arch in ['seq2seq', 'convseq2seq']:\n",
    "        src_vocab_path = os.path.join(model_dir, 'vocab_source.txt')\n",
    "        trg_vocab_path = os.path.join(model_dir, 'vocab_target.txt')\n",
    "\n",
    "        source_texts, target_texts = create_dataset(train_path, split_on_space=True)\n",
    "        logger.debug(\"source_texts:\",source_texts)\n",
    "        #src_2_ids = read_vocab(source_texts)\n",
    "        #trg_2_ids = read_vocab(target_texts)\n",
    "        #print(src_2_ids)\n",
    "        #save_word_dict(src_2_ids, src_vocab_path)\n",
    "        #save_word_dict(trg_2_ids, trg_vocab_path)\n",
    "\n",
    "        src_2_ids = load_word_dict(src_vocab_path)\n",
    "        trg_2_ids = load_word_dict(trg_vocab_path)\n",
    "        id_2_srcs = {v: k for k, v in src_2_ids.items()}\n",
    "        id_2_trgs = {v: k for k, v in trg_2_ids.items()}\n",
    "        train_src, train_trg = one_hot(source_texts, target_texts, src_2_ids, trg_2_ids, sort_by_len=True)\n",
    "\n",
    "        logger.debug(f'src: {[id_2_srcs[i] for i in train_src[0]]}')\n",
    "        logger.debug(f'trg: {[id_2_trgs[i] for i in train_trg[0]]}')\n",
    "\n",
    "        train_data = gen_examples(train_src, train_trg, batch_size, max_length)\n",
    "\n",
    "        if arch == 'seq2seq':\n",
    "            # Normal seq2seq\n",
    "            model = Seq2Seq(encoder_vocab_size=len(src_2_ids),\n",
    "                            decoder_vocab_size=len(trg_2_ids),\n",
    "                            embed_size=embed_size,\n",
    "                            enc_hidden_size=hidden_size,\n",
    "                            dec_hidden_size=hidden_size,\n",
    "                            dropout=dropout).to(device)\n",
    "            logger.info(model)\n",
    "            loss_fn = LanguageModelCriterion().to(device)\n",
    "            optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "            train_seq2seq_model(model, train_data, device, loss_fn, optimizer, model_dir, epochs=epochs)\n",
    "        else:\n",
    "            # Conv seq2seq model\n",
    "            trg_pad_idx = trg_2_ids[PAD_TOKEN]\n",
    "            model = ConvSeq2Seq(encoder_vocab_size=len(src_2_ids),\n",
    "                                decoder_vocab_size=len(trg_2_ids),\n",
    "                                embed_size=embed_size,\n",
    "                                enc_hidden_size=hidden_size,\n",
    "                                dec_hidden_size=hidden_size,\n",
    "                                dropout=dropout,\n",
    "                                trg_pad_idx=trg_pad_idx,\n",
    "                                device=device,\n",
    "                                max_length=max_length).to(device)\n",
    "            logger.info(model)\n",
    "            loss_fn = nn.CrossEntropyLoss(ignore_index=trg_pad_idx)\n",
    "            optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "            train_convseq2seq_model(model, train_data, device, loss_fn, optimizer, model_dir, epochs=epochs)\n",
    "    elif arch == 'bertseq2seq':\n",
    "        # Bert Seq2seq model\n",
    "        model_args = {\n",
    "            \"reprocess_input_data\": True,\n",
    "            \"overwrite_output_dir\": True,\n",
    "            \"max_seq_length\": max_length if max_length else 128,\n",
    "            \"train_batch_size\": batch_size if batch_size else 8,\n",
    "            \"num_train_epochs\": epochs if epochs else 10,\n",
    "            \"save_eval_checkpoints\": False,\n",
    "            \"save_model_every_epoch\": False,\n",
    "            \"silent\": False,\n",
    "            \"evaluate_generated_text\": True,\n",
    "            \"evaluate_during_training\": True,\n",
    "            \"evaluate_during_training_verbose\": True,\n",
    "            \"best_model_dir\": os.path.join(model_dir, 'best_model'),\n",
    "            \"use_multiprocessing\": False,\n",
    "            \"save_best_model\": True,\n",
    "            \"max_length\": max_length if max_length else 128,  # The maximum length of the sequence to be generated.\n",
    "            \"output_dir\": model_dir if model_dir else \"./output/bertseq2seq/\",\n",
    "        }\n",
    "\n",
    "        use_cuda = True if torch.cuda.is_available() else False\n",
    "        # encoder_type=None, encoder_name=None, decoder_name=None\n",
    "        # encoder_name=\"bert-base-chinese\"\n",
    "        model = Seq2SeqModel(\"bert\", model_name_or_path, model_name_or_path, args=model_args, use_cuda=use_cuda)\n",
    "\n",
    "        logger.info('start train bertseq2seq ...')\n",
    "        data = load_bert_data(train_path, use_segment)\n",
    "        logger.info(f'load data done, data size: {len(data)}')\n",
    "        logger.debug(f'data samples: {data[:10]}')\n",
    "        train_data, dev_data = train_test_split(data, test_size=0.1, shuffle=False)\n",
    "\n",
    "        train_df = pd.DataFrame(train_data, columns=['input_text', 'target_text'])\n",
    "        dev_df = pd.DataFrame(dev_data, columns=['input_text', 'target_text'])\n",
    "\n",
    "        def count_matches(labels, preds):\n",
    "            logger.debug(f\"labels: {labels[:10]}\")\n",
    "            logger.debug(f\"preds: {preds[:10]}\")\n",
    "            match = sum([1 if label == pred else 0 for label, pred in zip(labels, preds)])\n",
    "            logger.debug(f\"match: {match}\")\n",
    "            return match\n",
    "\n",
    "        model.train_model(train_df, eval_data=dev_df, matches=count_matches)\n",
    "    else:\n",
    "        logger.error('error arch: {}'.format(arch))\n",
    "        raise ValueError(\"Model arch choose error. Must use one of seq2seq model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6793d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 00:51:46.259 | INFO     | __main__:train:3 - device: cuda\n",
      "2022-09-16 00:51:46.260 | DEBUG    | __main__:train:5 - use seq2seq model.\n",
      "2022-09-16 00:51:46.286 | DEBUG    | __main__:train:12 - source_texts:\n",
      "2022-09-16 00:51:46.331 | DEBUG    | __main__:train:26 - src: ['<pad>', 'PHE', 'ARG', 'TYR', 'LEU', 'GLY']\n",
      "2022-09-16 00:51:46.331 | DEBUG    | __main__:train:27 - trg: ['<pad>', 'PHE', 'ARG', 'TYR', 'LEU', 'GLY']\n",
      "2022-09-16 00:51:46.349 | INFO     | __main__:train:39 - Seq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (embed): Embedding(24, 128)\n",
      "    (rnn): GRU(128, 128, batch_first=True, bidirectional=True)\n",
      "    (dropout): Dropout(p=0.25, inplace=False)\n",
      "    (fc): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embed): Embedding(24, 128)\n",
      "    (attention): Attention(\n",
      "      (linear_in): Linear(in_features=256, out_features=128, bias=False)\n",
      "      (linear_out): Linear(in_features=384, out_features=128, bias=True)\n",
      "    )\n",
      "    (rnn): GRU(128, 128, batch_first=True)\n",
      "    (out): Linear(in_features=128, out_features=24, bias=True)\n",
      "    (dropout): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      ")\n",
      "2022-09-16 00:51:46.443 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/10, iteration :0/26 loss:3.1912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save line size:900 to output/train.txt\n",
      "save line size:100 to output/test.txt\n",
      "{'<pad>': 0, '<unk>': 1, '<sos> ': 2, '<eos>': 3, 'ALA': 4, 'ARG': 5, 'ASN': 6, 'ASP': 7, 'CYS': 8, 'GLN': 9, 'GLU': 10, 'GLY': 11, 'HIS': 12, 'ILE': 13, 'LEU': 14, 'LYS': 15, 'MET': 16, 'PHE': 17, 'PRO': 18, 'SER': 19, 'THR': 20, 'TRP': 21, 'TYR': 22, 'VAL': 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 00:51:47.110 | INFO     | __main__:train_seq2seq_model:65 - Epoch :0/10, training loss:2.9531\n",
      "2022-09-16 00:51:47.130 | INFO     | __main__:train_seq2seq_model:69 - Epoch:0, dev loss:2.8951\n",
      "2022-09-16 00:51:47.135 | INFO     | __main__:train_seq2seq_model:77 - Epoch:0, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-16 00:51:47.160 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/10, iteration :0/26 loss:2.8807\n",
      "2022-09-16 00:51:47.678 | INFO     | __main__:train_seq2seq_model:65 - Epoch :1/10, training loss:2.8614\n",
      "2022-09-16 00:51:47.697 | INFO     | __main__:train_seq2seq_model:69 - Epoch:1, dev loss:2.8061\n",
      "2022-09-16 00:51:47.703 | INFO     | __main__:train_seq2seq_model:77 - Epoch:1, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-16 00:51:47.726 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/10, iteration :0/26 loss:2.8130\n",
      "2022-09-16 00:51:48.249 | INFO     | __main__:train_seq2seq_model:65 - Epoch :2/10, training loss:2.4821\n",
      "2022-09-16 00:51:48.267 | INFO     | __main__:train_seq2seq_model:69 - Epoch:2, dev loss:1.6736\n",
      "2022-09-16 00:51:48.272 | INFO     | __main__:train_seq2seq_model:77 - Epoch:2, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-16 00:51:48.296 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/10, iteration :0/26 loss:1.7842\n",
      "2022-09-16 00:51:48.814 | INFO     | __main__:train_seq2seq_model:65 - Epoch :3/10, training loss:1.1356\n",
      "2022-09-16 00:51:48.835 | INFO     | __main__:train_seq2seq_model:69 - Epoch:3, dev loss:0.5278\n",
      "2022-09-16 00:51:48.840 | INFO     | __main__:train_seq2seq_model:77 - Epoch:3, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-16 00:51:48.864 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/10, iteration :0/26 loss:0.6312\n",
      "2022-09-16 00:51:49.377 | INFO     | __main__:train_seq2seq_model:65 - Epoch :4/10, training loss:0.5027\n",
      "2022-09-16 00:51:49.396 | INFO     | __main__:train_seq2seq_model:69 - Epoch:4, dev loss:0.3102\n",
      "2022-09-16 00:51:49.401 | INFO     | __main__:train_seq2seq_model:77 - Epoch:4, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-16 00:51:49.425 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/10, iteration :0/26 loss:0.3938\n",
      "2022-09-16 00:51:49.947 | INFO     | __main__:train_seq2seq_model:65 - Epoch :5/10, training loss:0.3242\n",
      "2022-09-16 00:51:49.966 | INFO     | __main__:train_seq2seq_model:69 - Epoch:5, dev loss:0.2193\n",
      "2022-09-16 00:51:49.971 | INFO     | __main__:train_seq2seq_model:77 - Epoch:5, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-16 00:51:49.995 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/10, iteration :0/26 loss:0.2635\n",
      "2022-09-16 00:51:50.515 | INFO     | __main__:train_seq2seq_model:65 - Epoch :6/10, training loss:0.2436\n",
      "2022-09-16 00:51:50.533 | INFO     | __main__:train_seq2seq_model:69 - Epoch:6, dev loss:0.1761\n",
      "2022-09-16 00:51:50.539 | INFO     | __main__:train_seq2seq_model:77 - Epoch:6, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-16 00:51:50.563 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/10, iteration :0/26 loss:0.2027\n",
      "2022-09-16 00:51:51.084 | INFO     | __main__:train_seq2seq_model:65 - Epoch :7/10, training loss:0.1868\n",
      "2022-09-16 00:51:51.103 | INFO     | __main__:train_seq2seq_model:69 - Epoch:7, dev loss:0.1338\n",
      "2022-09-16 00:51:51.109 | INFO     | __main__:train_seq2seq_model:77 - Epoch:7, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-16 00:51:51.137 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/10, iteration :0/26 loss:0.1531\n",
      "2022-09-16 00:51:51.656 | INFO     | __main__:train_seq2seq_model:65 - Epoch :8/10, training loss:0.1497\n",
      "2022-09-16 00:51:51.675 | INFO     | __main__:train_seq2seq_model:69 - Epoch:8, dev loss:0.1230\n",
      "2022-09-16 00:51:51.680 | INFO     | __main__:train_seq2seq_model:77 - Epoch:8, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-16 00:51:51.705 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/10, iteration :0/26 loss:0.1513\n",
      "2022-09-16 00:51:52.231 | INFO     | __main__:train_seq2seq_model:65 - Epoch :9/10, training loss:0.1371\n",
      "2022-09-16 00:51:52.251 | INFO     | __main__:train_seq2seq_model:69 - Epoch:9, dev loss:0.1055\n",
      "2022-09-16 00:51:52.257 | INFO     | __main__:train_seq2seq_model:77 - Epoch:9, save new bert model:output/RNA/seq2seq.pth\n"
     ]
    }
   ],
   "source": [
    "if args.do_preprocess:\n",
    "    # Preprocess\n",
    "    data_list = []\n",
    "    os.makedirs(args.model_dir, exist_ok=True)\n",
    "    '''\n",
    "    if args.dataset == 'sighan':\n",
    "        data_list.extend(get_data_file(args.raw_train_path, args.use_segment, args.segment_type))\n",
    "    else:\n",
    "        data_list.extend(parse_xml_file(args.raw_train_path, args.use_segment, args.segment_type))\n",
    "    '''\n",
    "    data_list.extend(get_data_file(\"../pycorrector/data/RNA/train\", args.use_segment, args.segment_type)[:1000])\n",
    "    if data_list:\n",
    "        save_corpus_data(data_list, args.train_path, args.test_path)\n",
    "# Train model with train data file\n",
    "train(args.arch,\n",
    "        args.train_path,\n",
    "        args.batch_size,\n",
    "        args.embed_size,\n",
    "        args.hidden_size,\n",
    "        args.dropout,\n",
    "        args.epochs,\n",
    "        args.model_dir,\n",
    "        args.max_length,\n",
    "        args.use_segment,\n",
    "        args.model_name_or_path,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28819632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 00:56:41.812 | DEBUG    | __main__:__init__:22 - Device: cuda\n",
      "2022-09-16 00:56:41.813 | DEBUG    | __main__:__init__:23 - Use seq2seq model.\n",
      "2022-09-16 00:56:41.821 | DEBUG    | __main__:__init__:38 - Load model from output/RNA/seq2seq.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "input  : MET LYS LYS LEU GLN ILE ALA VAL GLY ILE ILE ARG ASN GLU ASN ASN GLU ILE PHE ILE THR ARG ARG ALA ALA ASP ALA HIS MET ALA ASN LYS LEU GLU PHE PRO GLY GLY LYS ILE GLU MET GLY GLU THR PRO GLU GLN ALA VAL VAL ARG GLU LEU GLN GLU GLU VAL GLY ILE THR PRO GLN HIS PHE SER LEU PHE GLU LYS LEU GLU TYR GLU PHE PRO ASP ARG HIS ILE THR LEU TRP PHE TRP LEU VAL GLU ARG TRP GLU GLY GLU PRO TRP GLY LYS GLU GLY GLN PRO GLY GLU TRP MET SER LEU VAL GLY LEU ASN ALA ASP ASP PHE PRO PRO ALA ASN GLU PRO VAL ILE ALA LYS LEU LYS ARG LEU\n",
      "predict: PHE SER LEU PHE GLU LYS LEU GLU TYR GLU PHE PRO ASP ARG HIS ILE THR LEU TRP PHE TRP LEU VAL GLU ARG TRP GLU GLU GLY GLU PRO TRP GLY LYS GLU GLY GLN PRO GLY GLU TRP MET SER LEU VAL GLY LEU ASN ALA ASP ASP PHE PRO PRO ALA ASN GLU PRO VAL ILE ALA LYS LEU LYS ARG LEU LEU LEU LEU LEU LEU VAL GLU ARG TRP GLU GLU GLY GLU PRO TRP GLY LYS GLU GLY GLN PRO GLY GLU TRP MET SER LEU VAL GLY LEU ASN ALA ASP ASP PHE PRO PRO ALA ASN GLU PRO VAL ILE ALA LYS LEU LYS ARG LEU LEU LEU LEU LEU LEU VAL GLU ARG TRP GLU GLU GLY GLU [('M', 'P', 0, 1), ('E', 'H', 1, 2), ('T', 'E', 2, 3), ('L', 'S', 4, 5), ('Y', 'E', 5, 6), ('S', 'R', 6, 7), ('Y', 'E', 9, 10), ('S', 'U', 10, 11), ('L', 'P', 12, 13), ('E', 'H', 13, 14), ('U', 'E', 14, 15), ('N', 'U', 18, 19), ('I', 'L', 20, 21), ('L', 'Y', 21, 22), ('E', 'S', 22, 23), ('A', 'L', 24, 25), ('L', 'E', 25, 26), ('A', 'U', 26, 27), ('V', 'G', 28, 29), ('A', 'L', 29, 30), ('L', 'U', 30, 31), ('G', 'T', 32, 33), ('L', 'Y', 33, 34), ('Y', 'R', 34, 35), ('I', 'G', 36, 37), ('E', 'U', 38, 39), ('I', 'P', 40, 41), ('L', 'H', 41, 42), ('A', 'P', 44, 45), ('G', 'O', 46, 47), ('N', 'P', 50, 51), ('G', 'A', 52, 53), ('L', 'R', 53, 54), ('U', 'G', 54, 55), ('A', 'H', 56, 57), ('S', 'I', 57, 58), ('N', 'S', 58, 59), ('A', 'I', 60, 61), ('S', 'L', 61, 62), ('N', 'E', 62, 63), ('G', 'T', 64, 65), ('L', 'H', 65, 66), ('U', 'R', 66, 67), ('I', 'L', 68, 69), ('L', 'E', 69, 70), ('E', 'U', 70, 71), ('P', 'T', 72, 73), ('H', 'R', 73, 74), ('E', 'P', 74, 75), ('I', 'P', 76, 77), ('L', 'H', 77, 78), ('H', 'R', 81, 82), ('R', 'P', 82, 83), ('A', 'L', 84, 85), ('R', 'E', 85, 86), ('G', 'U', 86, 87), ('A', 'V', 88, 89), ('R', 'A', 89, 90), ('G', 'L', 90, 91), ('A', 'G', 92, 93), ('A', 'U', 94, 95), ('L', 'R', 97, 98), ('A', 'G', 98, 99), ('A', 'T', 100, 101), ('S', 'R', 101, 102), ('A', 'G', 104, 105), ('A', 'U', 106, 107), ('H', 'G', 108, 109), ('I', 'L', 109, 110), ('S', 'U', 110, 111), ('M', 'G', 112, 113), ('E', 'L', 113, 114), ('T', 'Y', 114, 115), ('A', 'G', 116, 117), ('A', 'U', 118, 119), ('A', 'P', 120, 121), ('S', 'R', 121, 122), ('N', 'O', 122, 123), ('L', 'T', 124, 125), ('Y', 'R', 125, 126), ('S', 'P', 126, 127), ('L', 'G', 128, 129), ('E', 'L', 129, 130), ('U', 'Y', 130, 131), ('G', 'L', 132, 133), ('L', 'Y', 133, 134), ('U', 'S', 134, 135), ('P', 'G', 136, 137), ('H', 'L', 137, 138), ('E', 'U', 138, 139), ('P', 'G', 140, 141), ('R', 'L', 141, 142), ('O', 'Y', 142, 143), ('Y', 'N', 146, 147), ('G', 'P', 148, 149), ('L', 'R', 149, 150), ('Y', 'O', 150, 151), ('L', 'G', 152, 153), ('Y', 'L', 153, 154), ('S', 'Y', 154, 155), ('I', 'G', 156, 157), ('E', 'U', 158, 159), ('G', 'T', 160, 161), ('L', 'R', 161, 162), ('U', 'P', 162, 163), ('G', 'S', 168, 169), ('L', 'E', 169, 170), ('Y', 'R', 170, 171), ('G', 'L', 172, 173), ('L', 'E', 173, 174), ('T', 'V', 176, 177), ('H', 'A', 177, 178), ('R', 'L', 178, 179), ('P', 'G', 180, 181), ('R', 'L', 181, 182), ('O', 'Y', 182, 183), ('G', 'L', 184, 185), ('L', 'E', 185, 186), ('G', 'A', 188, 189), ('L', 'S', 189, 190), ('V', 'A', 196, 197), ('A', 'S', 197, 198), ('L', 'P', 198, 199), ('V', 'A', 200, 201), ('A', 'S', 201, 202), ('L', 'P', 202, 203), ('A', 'P', 204, 205), ('R', 'H', 205, 206), ('G', 'E', 206, 207), ('G', 'P', 208, 209), ('L', 'R', 209, 210), ('U', 'O', 210, 211), ('L', 'P', 212, 213), ('E', 'R', 213, 214), ('U', 'O', 214, 215), ('G', 'A', 216, 217), ('N', 'A', 218, 219), ('G', 'A', 220, 221), ('L', 'S', 221, 222), ('U', 'N', 222, 223), ('V', 'P', 228, 229), ('A', 'R', 229, 230), ('L', 'O', 230, 231), ('G', 'V', 232, 233), ('L', 'A', 233, 234), ('Y', 'L', 234, 235), ('T', 'A', 240, 241), ('H', 'L', 241, 242), ('R', 'A', 242, 243), ('P', 'L', 244, 245), ('R', 'Y', 245, 246), ('O', 'S', 246, 247), ('G', 'L', 248, 249), ('L', 'E', 249, 250), ('N', 'U', 250, 251), ('H', 'L', 252, 253), ('I', 'Y', 253, 254), ('P', 'A', 256, 257), ('H', 'R', 257, 258), ('E', 'G', 258, 259), ('S', 'L', 260, 261), ('R', 'U', 262, 263), ('P', 'L', 268, 269), ('H', 'E', 269, 270), ('E', 'U', 270, 271), ('G', 'L', 272, 273), ('L', 'E', 273, 274), ('Y', 'E', 277, 278), ('S', 'U', 278, 279), ('G', 'V', 284, 285), ('L', 'A', 285, 286), ('U', 'L', 286, 287), ('T', 'G', 288, 289), ('Y', 'L', 289, 290), ('R', 'U', 290, 291), ('G', 'A', 292, 293), ('L', 'R', 293, 294), ('U', 'G', 294, 295), ('P', 'T', 296, 297), ('H', 'R', 297, 298), ('E', 'P', 298, 299), ('P', 'G', 300, 301), ('R', 'L', 301, 302), ('O', 'U', 302, 303), ('A', 'G', 304, 305), ('S', 'L', 305, 306), ('P', 'U', 306, 307), ('A', 'G', 308, 309), ('R', 'L', 309, 310), ('G', 'Y', 310, 311), ('H', 'G', 312, 313), ('I', 'L', 313, 314), ('S', 'U', 314, 315), ('I', 'P', 316, 317), ('L', 'R', 317, 318), ('E', 'O', 318, 319), ('H', 'R', 321, 322), ('R', 'P', 322, 323), ('L', 'G', 324, 325), ('E', 'L', 325, 326), ('U', 'Y', 326, 327), ('T', 'L', 328, 329), ('R', 'Y', 329, 330), ('P', 'S', 330, 331), ('P', 'G', 332, 333), ('H', 'L', 333, 334), ('E', 'U', 334, 335), ('T', 'G', 336, 337), ('R', 'L', 337, 338), ('P', 'Y', 338, 339), ('L', 'G', 340, 341), ('E', 'L', 341, 342), ('U', 'N', 342, 343), ('V', 'P', 344, 345), ('A', 'R', 345, 346), ('L', 'O', 346, 347), ('U', 'Y', 350, 351), ('A', 'G', 352, 353), ('R', 'L', 353, 354), ('G', 'U', 354, 355), ('G', 'M', 360, 361), ('L', 'E', 361, 362), ('U', 'T', 362, 363), ('G', 'S', 364, 365), ('L', 'E', 365, 366), ('Y', 'R', 366, 367), ('G', 'L', 368, 369), ('L', 'E', 369, 370), ('P', 'V', 372, 373), ('R', 'A', 373, 374), ('O', 'L', 374, 375), ('T', 'G', 376, 377), ('R', 'L', 377, 378), ('P', 'Y', 378, 379), ('G', 'L', 380, 381), ('L', 'E', 381, 382), ('Y', 'U', 382, 383), ('L', 'A', 384, 385), ('Y', 'S', 385, 386), ('S', 'N', 386, 387), ('G', 'A', 388, 389), ('U', 'A', 390, 391), ('G', 'A', 392, 393), ('L', 'S', 393, 394), ('Y', 'P', 394, 395), ('G', 'A', 396, 397), ('L', 'S', 397, 398), ('N', 'P', 398, 399), ('R', 'H', 401, 402), ('O', 'E', 402, 403), ('G', 'P', 404, 405), ('L', 'R', 405, 406), ('Y', 'O', 406, 407), ('G', 'P', 408, 409), ('L', 'R', 409, 410), ('U', 'O', 410, 411), ('T', 'A', 412, 413), ('R', 'L', 413, 414), ('P', 'A', 414, 415), ('M', 'A', 416, 417), ('E', 'S', 417, 418), ('T', 'N', 418, 419), ('S', 'G', 420, 421), ('E', 'L', 421, 422), ('R', 'U', 422, 423), ('L', 'P', 424, 425), ('E', 'R', 425, 426), ('U', 'O', 426, 427), ('G', 'I', 432, 433), ('Y', 'E', 434, 435), ('L', 'A', 436, 437), ('E', 'L', 437, 438), ('U', 'A', 438, 439), ('A', 'L', 440, 441), ('S', 'Y', 441, 442), ('N', 'S', 442, 443), ('A', 'L', 444, 445), ('L', 'E', 445, 446), ('A', 'U', 446, 447), ('A', 'L', 448, 449), ('S', 'Y', 449, 450), ('P', 'S', 450, 451), ('S', 'R', 453, 454), ('P', 'G', 454, 455), ('P', 'L', 456, 457), ('H', 'E', 457, 458), ('E', 'U', 458, 459), ('P', 'L', 460, 461), ('R', 'E', 461, 462), ('O', 'U', 462, 463), ('P', 'L', 464, 465), ('R', 'E', 465, 466), ('O', 'U', 466, 467), ('A', 'L', 468, 469), ('L', 'E', 469, 470), ('A', 'U', 470, 471), ('A', 'L', 472, 473), ('S', 'E', 473, 474), ('N', 'U', 474, 475), ('G', 'L', 476, 477), ('L', 'E', 477, 478), ('P', 'V', 480, 481), ('R', 'A', 481, 482), ('O', 'L', 482, 483), ('V', 'G', 484, 485), ('A', 'L', 485, 486), ('L', 'U', 486, 487), ('I', 'A', 488, 489), ('L', 'R', 489, 490), ('E', 'G', 490, 491), ('A', 'T', 492, 493), ('L', 'R', 493, 494), ('A', 'P', 494, 495), ('L', 'G', 496, 497), ('Y', 'L', 497, 498), ('S', 'U', 498, 499), ('L', 'G', 500, 501), ('E', 'L', 501, 502), ('L', 'G', 504, 505), ('Y', 'L', 505, 506), ('S', 'Y', 506, 507), ('A', 'G', 508, 509), ('R', 'L', 509, 510), ('G', 'U', 510, 511)]\n",
      "\n",
      "input  : ASP ALA ILE ALA ASP ALA SER LYS ARG PHE SER ASP ALA THR TYR PRO ILE ALA GLU LYS PHE ASP TRP GLY GLY SER SER ALA ILE ALA LYS TYR ILE ALA ASP ALA SER ALA GLY ASN PRO ARG GLN ALA ALA LEU ALA VAL GLU LYS LEU LEU GLU VAL GLY LEU THR MET ASP PRO LYS LEU VAL ARG ALA ALA VAL GLU ALA HIS SER LYS ALA LEU ASP SER ALA LYS LYS ASN ALA LYS LEU MET ALA SER LYS GLU ASP PHE ALA ALA VAL ASN GLU ALA LEU ALA ARG MET ILE ALA SER ALA ASP LYS GLN LYS PHE ALA ALA LEU ARG THR ALA PHE PRO GLU SER ARG GLU LEU GLN GLY LYS LEU PHE ALA GLY ASN ASN ALA PHE GLU ALA GLU LYS ALA TYR ASP SER PHE LYS ALA LEU THR SER ALA VAL ARG ASP ALA SER ILE ASN GLY ALA LYS ALA PRO VAL ILE ALA GLU ALA ALA ARG ALA GLU ARG TYR VAL GLY ASP GLY PRO VAL GLY ARG ALA ALA LYS LYS PHE SER GLU ALA THR TYR PRO ILE MET ASP LYS LEU ASP TRP GLY LYS SER PRO GLU ILE SER LYS TYR ILE GLU THR ALA SER ALA LYS ASN PRO LYS MET MET ALA ASP GLY ILE ASP LYS THR LEU GLU VAL ALA LEU THR MET ASN GLN ASN ALA ILE ASN ASP ALA VAL PHE ALA HIS VAL ARG ALA ILE LYS GLY ALA LEU ASN THR PRO GLY LEU VAL ALA GLU ARG ASP ASP PHE ALA ARG VAL ASN LEU ALA LEU ALA LYS MET ILE ALA THR ALA ASP PRO ALA LYS PHE LYS ALA LEU LEU THR ALA PHE PRO GLY ASN ALA ASP LEU GLN MET ALA LEU PHE ALA ALA ASN ASN PRO GLU GLN ALA LYS ALA ALA TYR GLU THR PHE VAL ALA LEU THR SER ALA VAL ALA SER SER THR\n",
      "predict: ALA ASP GLY ILE ASP LYS THR LEU GLU VAL ALA LEU THR MET ASN GLN ASN ALA ILE ASN ASP ALA VAL PHE ALA HIS VAL ARG ALA ILE LYS GLY ALA LEU ASN THR PRO GLY LEU VAL ALA GLU ARG ASP ASP PHE ALA ARG VAL ASN LEU ALA ARG MET ILE ALA SER ALA ASP LYS GLN LYS PHE ALA ALA LEU ARG THR ALA PHE PRO GLU SER ARG GLU LEU GLN GLY LYS LEU PHE ALA GLY ASN ASN ALA ASP LEU GLN MET ALA LEU PHE ALA ALA ASN ASN PRO GLU GLN ALA LYS ALA ALA TYR GLU THR PHE VAL ALA LEU THR SER ALA VAL ALA SER SER THR SER THR SER LEU ALA VAL ALA SER SER [('S', 'L', 1, 2), ('P', 'A', 2, 3), ('L', 'S', 5, 6), ('A', 'P', 6, 7), ('I', 'G', 8, 9), ('E', 'Y', 10, 11), ('A', 'I', 12, 13), ('A', 'E', 14, 15), ('A', 'L', 20, 21), ('L', 'Y', 21, 22), ('A', 'S', 22, 23), ('S', 'T', 24, 25), ('E', 'H', 25, 26), ('Y', 'E', 29, 30), ('S', 'U', 30, 31), ('A', 'G', 32, 33), ('R', 'L', 33, 34), ('G', 'U', 34, 35), ('P', 'V', 36, 37), ('H', 'A', 37, 38), ('E', 'L', 38, 39), ('S', 'A', 40, 41), ('E', 'L', 41, 42), ('R', 'A', 42, 43), ('A', 'L', 44, 45), ('S', 'E', 45, 46), ('P', 'U', 46, 47), ('A', 'T', 48, 49), ('L', 'H', 49, 50), ('A', 'R', 50, 51), ('T', 'M', 52, 53), ('H', 'E', 53, 54), ('R', 'T', 54, 55), ('T', 'A', 56, 57), ('Y', 'S', 57, 58), ('R', 'N', 58, 59), ('P', 'G', 60, 61), ('R', 'L', 61, 62), ('O', 'N', 62, 63), ('I', 'A', 64, 65), ('L', 'S', 65, 66), ('E', 'N', 66, 67), ('G', 'I', 72, 73), ('U', 'E', 74, 75), ('L', 'A', 76, 77), ('Y', 'S', 77, 78), ('S', 'N', 78, 79), ('P', 'A', 80, 81), ('H', 'S', 81, 82), ('E', 'P', 82, 83), ('S', 'L', 85, 86), ('P', 'A', 86, 87), ('T', 'V', 88, 89), ('R', 'A', 89, 90), ('P', 'L', 90, 91), ('G', 'P', 92, 93), ('L', 'H', 93, 94), ('Y', 'E', 94, 95), ('G', 'A', 96, 97), ('Y', 'A', 98, 99), ('S', 'H', 100, 101), ('E', 'I', 101, 102), ('R', 'S', 102, 103), ('S', 'V', 104, 105), ('E', 'A', 105, 106), ('R', 'L', 106, 107), ('L', 'R', 109, 110), ('A', 'G', 110, 111), ('I', 'A', 112, 113), ('E', 'A', 114, 115), ('A', 'I', 116, 117), ('A', 'E', 118, 119), ('T', 'G', 124, 125), ('Y', 'L', 125, 126), ('R', 'Y', 126, 127), ('I', 'A', 128, 129), ('E', 'A', 130, 131), ('A', 'L', 132, 133), ('L', 'E', 133, 134), ('A', 'U', 134, 135), ('P', 'N', 138, 139), ('A', 'T', 140, 141), ('L', 'H', 141, 142), ('A', 'R', 142, 143), ('S', 'P', 144, 145), ('E', 'R', 145, 146), ('R', 'O', 146, 147), ('A', 'G', 148, 149), ('A', 'Y', 150, 151), ('G', 'L', 152, 153), ('L', 'E', 153, 154), ('Y', 'U', 154, 155), ('A', 'V', 156, 157), ('S', 'A', 157, 158), ('N', 'L', 158, 159), ('P', 'A', 160, 161), ('R', 'L', 161, 162), ('O', 'A', 162, 163), ('A', 'G', 164, 165), ('R', 'L', 165, 166), ('G', 'U', 166, 167), ('G', 'A', 168, 169), ('L', 'R', 169, 170), ('N', 'G', 170, 171), ('L', 'S', 173, 174), ('A', 'P', 174, 175), ('L', 'S', 177, 178), ('A', 'P', 178, 179), ('L', 'P', 180, 181), ('E', 'H', 181, 182), ('U', 'E', 182, 183), ('V', 'A', 188, 189), ('A', 'R', 189, 190), ('L', 'G', 190, 191), ('G', 'V', 192, 193), ('L', 'A', 193, 194), ('U', 'L', 194, 195), ('L', 'A', 196, 197), ('Y', 'S', 197, 198), ('S', 'N', 198, 199), ('L', 'A', 204, 205), ('E', 'L', 205, 206), ('U', 'A', 206, 207), ('G', 'A', 208, 209), ('L', 'R', 209, 210), ('U', 'G', 210, 211), ('V', 'M', 212, 213), ('A', 'E', 213, 214), ('L', 'T', 214, 215), ('G', 'I', 216, 217), ('Y', 'E', 218, 219), ('L', 'A', 220, 221), ('E', 'L', 221, 222), ('U', 'A', 222, 223), ('T', 'S', 224, 225), ('H', 'E', 225, 226), ('M', 'A', 228, 229), ('E', 'L', 229, 230), ('T', 'A', 230, 231), ('P', 'L', 236, 237), ('R', 'Y', 237, 238), ('O', 'S', 238, 239), ('L', 'G', 240, 241), ('Y', 'L', 241, 242), ('S', 'N', 242, 243), ('E', 'Y', 245, 246), ('U', 'S', 246, 247), ('V', 'P', 248, 249), ('A', 'H', 249, 250), ('L', 'E', 250, 251), ('R', 'L', 253, 254), ('G', 'A', 254, 255), ('A', 'L', 260, 261), ('L', 'E', 261, 262), ('A', 'U', 262, 263), ('V', 'A', 264, 265), ('A', 'R', 265, 266), ('L', 'G', 266, 267), ('G', 'T', 268, 269), ('L', 'H', 269, 270), ('U', 'R', 270, 271), ('H', 'P', 276, 277), ('I', 'H', 277, 278), ('S', 'E', 278, 279), ('S', 'P', 280, 281), ('E', 'R', 281, 282), ('R', 'O', 282, 283), ('L', 'G', 284, 285), ('Y', 'L', 285, 286), ('S', 'U', 286, 287), ('A', 'S', 288, 289), ('L', 'E', 289, 290), ('A', 'R', 290, 291), ('L', 'A', 292, 293), ('E', 'R', 293, 294), ('U', 'G', 294, 295), ('A', 'G', 296, 297), ('S', 'L', 297, 298), ('P', 'U', 298, 299), ('S', 'L', 300, 301), ('R', 'U', 302, 303), ('A', 'G', 304, 305), ('A', 'N', 306, 307), ('L', 'G', 308, 309), ('Y', 'L', 309, 310), ('S', 'Y', 310, 311), ('A', 'L', 316, 317), ('S', 'E', 317, 318), ('N', 'U', 318, 319), ('A', 'P', 320, 321), ('L', 'H', 321, 322), ('A', 'E', 322, 323), ('L', 'A', 324, 325), ('Y', 'L', 325, 326), ('S', 'A', 326, 327), ('L', 'G', 328, 329), ('E', 'L', 329, 330), ('U', 'Y', 330, 331), ('M', 'A', 332, 333), ('E', 'S', 333, 334), ('T', 'N', 334, 335), ('L', 'S', 337, 338), ('A', 'N', 338, 339), ('S', 'A', 340, 341), ('E', 'L', 341, 342), ('R', 'A', 342, 343), ('L', 'A', 344, 345), ('Y', 'S', 345, 346), ('S', 'P', 346, 347), ('G', 'L', 348, 349), ('L', 'E', 349, 350), ('A', 'G', 352, 353), ('S', 'L', 353, 354), ('P', 'N', 354, 355), ('P', 'M', 356, 357), ('H', 'E', 357, 358), ('E', 'T', 358, 359), ('A', 'L', 364, 365), ('L', 'E', 365, 366), ('A', 'U', 366, 367), ('V', 'P', 368, 369), ('A', 'H', 369, 370), ('L', 'E', 370, 371), ('S', 'L', 373, 374), ('N', 'A', 374, 375), ('G', 'A', 376, 377), ('U', 'A', 378, 379), ('L', 'S', 381, 382), ('A', 'N', 382, 383), ('L', 'A', 384, 385), ('E', 'S', 385, 386), ('U', 'N', 386, 387), ('A', 'P', 388, 389), ('L', 'R', 389, 390), ('A', 'O', 390, 391), ('A', 'G', 392, 393), ('R', 'L', 393, 394), ('G', 'U', 394, 395), ('M', 'G', 396, 397), ('E', 'L', 397, 398), ('T', 'N', 398, 399), ('I', 'A', 400, 401), ('E', 'A', 402, 403), ('A', 'L', 404, 405), ('L', 'Y', 405, 406), ('A', 'S', 406, 407), ('S', 'A', 408, 409), ('E', 'L', 409, 410), ('R', 'A', 410, 411), ('A', 'T', 416, 417), ('S', 'Y', 417, 418), ('P', 'R', 418, 419), ('L', 'G', 420, 421), ('Y', 'L', 421, 422), ('S', 'U', 422, 423), ('G', 'T', 424, 425), ('L', 'H', 425, 426), ('N', 'R', 426, 427), ('L', 'P', 428, 429), ('Y', 'H', 429, 430), ('S', 'E', 430, 431), ('P', 'V', 432, 433), ('H', 'A', 433, 434), ('E', 'L', 434, 435), ('A', 'L', 440, 441), ('L', 'E', 441, 442), ('A', 'U', 442, 443), ('L', 'T', 444, 445), ('E', 'H', 445, 446), ('U', 'R', 446, 447), ('A', 'S', 448, 449), ('R', 'E', 449, 450), ('G', 'R', 450, 451), ('T', 'A', 452, 453), ('H', 'L', 453, 454), ('R', 'A', 454, 455), ('A', 'V', 456, 457), ('L', 'A', 457, 458), ('A', 'L', 458, 459), ('P', 'A', 460, 461), ('H', 'L', 461, 462), ('E', 'A', 462, 463), ('P', 'S', 464, 465), ('R', 'E', 465, 466), ('O', 'R', 466, 467), ('G', 'S', 468, 469), ('L', 'E', 469, 470), ('U', 'R', 470, 471), ('S', 'T', 472, 473), ('E', 'H', 473, 474), ('A', 'S', 476, 477), ('R', 'E', 477, 478), ('G', 'R', 478, 479), ('G', 'T', 480, 481), ('L', 'H', 481, 482), ('U', 'R', 482, 483), ('L', 'S', 484, 485), ('U', 'R', 486, 487), ('G', 'L', 488, 489), ('L', 'E', 489, 490), ('N', 'U', 490, 491), ('G', 'A', 492, 493), ('Y', 'A', 494, 495), ('L', 'V', 496, 497), ('Y', 'A', 497, 498), ('S', 'L', 498, 499), ('L', 'A', 500, 501), ('E', 'L', 501, 502), ('U', 'A', 502, 503), ('P', 'S', 504, 505), ('H', 'E', 505, 506), ('E', 'R', 506, 507), ('A', 'S', 508, 509), ('L', 'E', 509, 510), ('A', 'R', 510, 511)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m = Inference(args.model_dir,\n",
    "                  args.arch,\n",
    "                  embed_size=args.embed_size,\n",
    "                  hidden_size=args.hidden_size,\n",
    "                  dropout=args.dropout,\n",
    "                  max_length=args.max_length\n",
    "                  )\n",
    "inputs = [\n",
    "    'MET LYS LYS LEU GLN ILE ALA VAL GLY ILE ILE ARG ASN GLU ASN ASN GLU ILE PHE ILE THR ARG ARG ALA ALA ASP ALA HIS MET ALA ASN LYS LEU GLU PHE PRO GLY GLY LYS ILE GLU MET GLY GLU THR PRO GLU GLN ALA VAL VAL ARG GLU LEU GLN GLU GLU VAL GLY ILE THR PRO GLN HIS PHE SER LEU PHE GLU LYS LEU GLU TYR GLU PHE PRO ASP ARG HIS ILE THR LEU TRP PHE TRP LEU VAL GLU ARG TRP GLU GLY GLU PRO TRP GLY LYS GLU GLY GLN PRO GLY GLU TRP MET SER LEU VAL GLY LEU ASN ALA ASP ASP PHE PRO PRO ALA ASN GLU PRO VAL ILE ALA LYS LEU LYS ARG LEU',\n",
    "    'ASP ALA ILE ALA ASP ALA SER LYS ARG PHE SER ASP ALA THR TYR PRO ILE ALA GLU LYS PHE ASP TRP GLY GLY SER SER ALA ILE ALA LYS TYR ILE ALA ASP ALA SER ALA GLY ASN PRO ARG GLN ALA ALA LEU ALA VAL GLU LYS LEU LEU GLU VAL GLY LEU THR MET ASP PRO LYS LEU VAL ARG ALA ALA VAL GLU ALA HIS SER LYS ALA LEU ASP SER ALA LYS LYS ASN ALA LYS LEU MET ALA SER LYS GLU ASP PHE ALA ALA VAL ASN GLU ALA LEU ALA ARG MET ILE ALA SER ALA ASP LYS GLN LYS PHE ALA ALA LEU ARG THR ALA PHE PRO GLU SER ARG GLU LEU GLN GLY LYS LEU PHE ALA GLY ASN ASN ALA PHE GLU ALA GLU LYS ALA TYR ASP SER PHE LYS ALA LEU THR SER ALA VAL ARG ASP ALA SER ILE ASN GLY ALA LYS ALA PRO VAL ILE ALA GLU ALA ALA ARG ALA GLU ARG TYR VAL GLY ASP GLY PRO VAL GLY ARG ALA ALA LYS LYS PHE SER GLU ALA THR TYR PRO ILE MET ASP LYS LEU ASP TRP GLY LYS SER PRO GLU ILE SER LYS TYR ILE GLU THR ALA SER ALA LYS ASN PRO LYS MET MET ALA ASP GLY ILE ASP LYS THR LEU GLU VAL ALA LEU THR MET ASN GLN ASN ALA ILE ASN ASP ALA VAL PHE ALA HIS VAL ARG ALA ILE LYS GLY ALA LEU ASN THR PRO GLY LEU VAL ALA GLU ARG ASP ASP PHE ALA ARG VAL ASN LEU ALA LEU ALA LYS MET ILE ALA THR ALA ASP PRO ALA LYS PHE LYS ALA LEU LEU THR ALA PHE PRO GLY ASN ALA ASP LEU GLN MET ALA LEU PHE ALA ALA ASN ASN PRO GLU GLN ALA LYS ALA ALA TYR GLU THR PHE VAL ALA LEU THR SER ALA VAL ALA SER SER THR'\n",
    "]\n",
    "outputs = m.predict(inputs)\n",
    "\n",
    "for a, b in zip(inputs, outputs):\n",
    "    print('input  :', a)\n",
    "    print('predict:', b[0], b[1])\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3cd0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf5ef44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
