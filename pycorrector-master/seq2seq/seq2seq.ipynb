{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bbf3c2f",
   "metadata": {},
   "source": [
    "# install all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58213b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20cb4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b4a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fbf512",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install loguru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1c2b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2213d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypinyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42bf554",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09782ad",
   "metadata": {},
   "source": [
    "# SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "006b3936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import operator\n",
    "from sklearn.model_selection import train_test_split\n",
    "sys.path.append('../')\n",
    "sys.path.append('../..')\n",
    "#from pycorrector.seq2seq.data_reader import *\n",
    "#from pycorrector.seq2seq.train import *\n",
    "#from pycorrector.seq2seq.infer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3ce4d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--raw_train_path\",\n",
    "                    default=\"../pycorrector/data/cn/sighan_2015/train.tsv\", type=str,\n",
    "                    help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\",\n",
    "                    )\n",
    "parser.add_argument(\"--dataset\", default=\"sighan\", type=str,\n",
    "                    help=\"Dataset name. selected in the list:\" + \", \".join([\"sighan\", \"cged\"])\n",
    "                    )\n",
    "parser.add_argument(\"--use_segment\", action=\"store_true\", help=\"Whether not to segment train data\")\n",
    "parser.add_argument(\"--do_preprocess\", action=\"store_true\", default=\"True\",help=\"Whether not to preprocess train data\")\n",
    "parser.add_argument(\"--segment_type\", default=\"char\", type=str,\n",
    "                        help=\"Segment data type, selected in list: \" + \", \".join([\"char\", \"word\"]))\n",
    "parser.add_argument(\"--model_name_or_path\",\n",
    "                    default=\"bert-base-chinese\", type=str,\n",
    "                    help=\"Path to pretrained model or model identifier from huggingface.co/models\",\n",
    "                    )\n",
    "parser.add_argument(\"--model_dir\", default=\"output/RNA/\", type=str, help=\"Dir for model save.\")\n",
    "parser.add_argument(\"--arch\", default=\"seq2seq\", type=str,\n",
    "                    help=\"The name of the task to train selected in the list: \" + \", \".join(\n",
    "                        ['seq2seq', 'convseq2seq', 'bertseq2seq']),\n",
    "                    )\n",
    "parser.add_argument(\"--train_path\", default=\"output/train.txt\", type=str, help=\"Train file after preprocess.\")\n",
    "parser.add_argument(\"--test_path\", default=\"output/test.txt\", type=str, help=\"Test file after preprocess.\")\n",
    "parser.add_argument(\"--max_length\", default=128, type=int,\n",
    "                    help=\"The maximum total input sequence length after tokenization. \\n\"\n",
    "                            \"Sequences longer than this will be truncated, sequences shorter padded.\",\n",
    "                    )\n",
    "parser.add_argument(\"--batch_size\", default=32, type=int, help=\"Batch size.\")\n",
    "parser.add_argument(\"--embed_size\", default=128, type=int, help=\"Embedding size.\")\n",
    "parser.add_argument(\"--hidden_size\", default=128, type=int, help=\"Hidden size.\")\n",
    "parser.add_argument(\"--dropout\", default=0.25, type=float, help=\"Dropout rate.\")\n",
    "parser.add_argument(\"--epochs\", default=100, type=int, help=\"Epoch num.\")\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35b7943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f95f03",
   "metadata": {},
   "source": [
    "# preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "497f6463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_file(path, use_segment, segment_type):\n",
    "    data_list = []\n",
    "    if not os.path.exists(path):\n",
    "        print('%s not exists' % path)\n",
    "        return data_list\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            parts = line.split(\"\\t\")\n",
    "            if len(parts) != 2:\n",
    "                continue\n",
    "            source = ' '.join(segment(parts[0].strip(), cut_type=segment_type)) if use_segment else parts[0].strip()\n",
    "            target = ' '.join(segment(parts[1].strip(), cut_type=segment_type)) if use_segment else parts[1].strip()\n",
    "\n",
    "            pair = [source, target]\n",
    "            if pair not in data_list:\n",
    "                data_list.append(pair)\n",
    "    return data_list\n",
    "\n",
    "\n",
    "def _save_data(data_list, data_path):\n",
    "    dirname = os.path.dirname(data_path)\n",
    "    os.makedirs(dirname, exist_ok=True)\n",
    "    with open(data_path, 'w', encoding='utf-8') as f:\n",
    "        count = 0\n",
    "        for src, dst in data_list:\n",
    "            f.write(src + '\\t' + dst + '\\n')\n",
    "            count += 1\n",
    "        print(\"save line size:%d to %s\" % (count, data_path))\n",
    "\n",
    "\n",
    "def save_corpus_data(data_list, train_data_path, test_data_path):\n",
    "    train_lst, test_lst = train_test_split(data_list, test_size=0.1)\n",
    "    _save_data(train_lst, train_data_path)\n",
    "    _save_data(test_lst, test_data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e086b810",
   "metadata": {},
   "source": [
    "# data_reader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7611ef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants associated with the usual special tokens.\n",
    "SOS_TOKEN = '<sos>'\n",
    "EOS_TOKEN = '<eos>'\n",
    "UNK_TOKEN = '<unk>'\n",
    "PAD_TOKEN = '<pad>'\n",
    "class CscDataset(object):\n",
    "    def __init__(self, file_path):\n",
    "        self.data = json.load(open(file_path, 'r', encoding='utf-8'))\n",
    "\n",
    "    def load(self):\n",
    "        data_list = []\n",
    "        for item in self.data:\n",
    "            data_list.append(item['original_text'] + '\\t' + item['correct_text'])\n",
    "        return data_list\n",
    "\n",
    "def create_dataset(path, num_examples=None, split_on_space=False):\n",
    "    if path.endswith('.json'):\n",
    "        d = CscDataset(path)\n",
    "        lines = d.load()\n",
    "    else:\n",
    "        lines = open(path, 'r', encoding='utf-8').read().strip().split('\\n')\n",
    "    word_pairs = [[preprocess_sentence(s, split_on_space) for s in l.split('\\t')] for l in lines[:num_examples]]\n",
    "    return zip(*word_pairs)\n",
    "\n",
    "\n",
    "def preprocess_sentence(sentence, split_on_space=False):\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    return [SOS_TOKEN] + sentence.split() if split_on_space else list(sentence) + [EOS_TOKEN]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aab244fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "'''\n",
    "class Counter(object):\n",
    "    def __init__(self):\n",
    "        self.counter = {}\n",
    "    def update(self, token):\n",
    "'''    \n",
    "\n",
    "\n",
    "def save_word_dict(dict_data, save_path):\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        for k, v in dict_data.items():\n",
    "            f.write(\"%s\\t%d\\n\" % (k, v))\n",
    "\n",
    "\n",
    "def load_word_dict(save_path):\n",
    "    dict_data = dict()\n",
    "    num = 0\n",
    "    with open(save_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip('\\n')\n",
    "            items = line.split('\\t')\n",
    "            num += 1\n",
    "            try:\n",
    "                dict_data[items[0]] = int(items[1])\n",
    "            except IndexError:\n",
    "                logger.error('IndexError, index:%s, line:%s' % (num, line))\n",
    "    return dict_data\n",
    "def read_vocab(input_texts, max_size=None, min_count=0):\n",
    "    token_counts = Counter()\n",
    "    special_tokens = [PAD_TOKEN, UNK_TOKEN, SOS_TOKEN, EOS_TOKEN]\n",
    "    '''\n",
    "    for texts in input_texts:\n",
    "        for token in texts:\n",
    "            token_counts.update(token)\n",
    "    '''\n",
    "    for texts in input_texts:\n",
    "        for token in texts:\n",
    "            token_counts.update(token)\n",
    "    # Sort word count by value\n",
    "    count_pairs = token_counts.most_common()\n",
    "    vocab = [k for k, v in count_pairs if v >= min_count]\n",
    "    print(vocab)\n",
    "    # Insert the special tokens to the beginning\n",
    "    vocab[0:0] = special_tokens\n",
    "    full_token_id = list(zip(vocab, range(len(vocab))))[:max_size]\n",
    "    vocab2id = dict(full_token_id)\n",
    "    return vocab2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04dc4dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(seqs, max_length=None):\n",
    "    if max_length:\n",
    "        seqs = [seq[:max_length] for seq in seqs]\n",
    "    lengths = [len(seq) for seq in seqs]\n",
    "    n_samples = len(seqs)\n",
    "    max_len = np.max(lengths)\n",
    "\n",
    "    x = np.zeros((n_samples, max_len)).astype('int32')\n",
    "    x_lengths = np.array(lengths).astype(\"int32\")\n",
    "    for idx, seq in enumerate(seqs):\n",
    "        x[idx, :lengths[idx]] = seq\n",
    "    return x, x_lengths  # x_mask\n",
    "def get_minibatches(n, minibatch_size, shuffle=True):\n",
    "    idx_list = np.arange(0, n, minibatch_size)  # [0, 1, ..., n-1]\n",
    "    if shuffle:\n",
    "        np.random.shuffle(idx_list)\n",
    "    minibatches = []\n",
    "    for idx in idx_list:\n",
    "        minibatches.append(np.arange(idx, min(idx + minibatch_size, n)))\n",
    "    return minibatches\n",
    "def gen_examples(src_sentences, trg_sentences, batch_size, max_length=None):\n",
    "    minibatches = get_minibatches(len(src_sentences), batch_size)\n",
    "    examples = []\n",
    "    for minibatch in minibatches:\n",
    "        mb_src_sentences = [src_sentences[t] for t in minibatch]\n",
    "        mb_trg_sentences = [trg_sentences[t] for t in minibatch]\n",
    "        mb_x, mb_x_len = prepare_data(mb_src_sentences, max_length)\n",
    "        mb_y, mb_y_len = prepare_data(mb_trg_sentences, max_length)\n",
    "        examples.append((mb_x, mb_x_len, mb_y, mb_y_len))\n",
    "    return examples\n",
    "def one_hot(src_sentences, trg_sentences, src_dict, trg_dict, sort_by_len=True):\n",
    "    \"\"\"vector the sequences.\n",
    "    \"\"\"\n",
    "\n",
    "    out_src_sentences = [[src_dict.get(w, 0) for w in sent] for sent in src_sentences]\n",
    "    out_trg_sentences = [[trg_dict.get(w, 0) for w in sent] for sent in trg_sentences]\n",
    "\n",
    "    # sort sentences by english lengths\n",
    "    def len_argsort(seq):\n",
    "        return sorted(range(len(seq)), key=lambda x: len(seq[x]))\n",
    "\n",
    "    # sort length\n",
    "    if sort_by_len:\n",
    "        sorted_index = len_argsort(out_src_sentences)\n",
    "        out_src_sentences = [out_src_sentences[i] for i in sorted_index]\n",
    "        out_trg_sentences = [out_trg_sentences[i] for i in sorted_index]\n",
    "\n",
    "    return out_src_sentences, out_trg_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d8d5ff",
   "metadata": {},
   "source": [
    "# seq2se2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d076ddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author:XuMing(xuming624@qq.com)\n",
    "@description: \n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, enc_hidden_size, dec_hidden_size, dropout=0.2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        '''\n",
    "            torch.nn.Embedding(numembeddings, embeddingdim)\n",
    "                * numembeddings代表一共有多少个词\n",
    "                * embedding_dim代表每个词创建一个多少维的向量来表示他\n",
    "        '''\n",
    "        self.rnn = nn.GRU(embed_size, enc_hidden_size, batch_first=True, bidirectional=True)\n",
    "        '''\n",
    "            torch.nn.GRU(input_size, hidden_size, num_layers, bias,batch_first,dropout,bidirectional)\n",
    "                * input_size: the number of expected features in the input x\n",
    "                * hidden_size: the number of features in the hidden state h\n",
    "                * batch_first: if True, then (batch, seq, feature), else (seq, batch, feature)\n",
    "                * bidirectional: if True, becomes a bidirectional GRU. Default: False\n",
    "            \n",
    "        '''\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(enc_hidden_size * 2, dec_hidden_size)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # 将x根据长度来排序\n",
    "        sorted_len, sorted_idx = lengths.sort(0, descending=True)\n",
    "        x_sorted = x[sorted_idx.long()]\n",
    "        embedded = self.dropout(self.embed(x_sorted))\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, sorted_len.long().cpu().data.numpy(),\n",
    "                                                            batch_first=True)\n",
    "        '''\n",
    "            https://zhuanlan.zhihu.com/p/34418001\n",
    "            torch.nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=False,enforce_sorted=True)\n",
    "            当我们进行batch个训练数据一起计算的时候，我们会遇到多个训练样例长度不同时的情况，这样我们就会很自然的进行padding，\n",
    "            将短句子padding为跟最长的句子一样\n",
    "            \n",
    "            pytorch中RNN处理变长padding主要用torch.nn.utils.rnn.pack_padded_sequence()以及torch.nn.utils.rnn.pad_packed_sequence()来进行。\n",
    "            \n",
    "            \n",
    "            \n",
    "        '''\n",
    "        packed_out, hid = self.rnn(packed_embedded)\n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)\n",
    "        _, original_idx = sorted_idx.sort(0, descending=False)\n",
    "        out = out[original_idx.long()].contiguous()\n",
    "        hid = hid[:, original_idx.long()].contiguous()\n",
    "\n",
    "        hid = torch.cat([hid[-2], hid[-1]], dim=1)\n",
    "        hid = torch.tanh(self.fc(hid)).unsqueeze(0)\n",
    "\n",
    "        return out, hid\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    Luong Attention,根据context vectors和当前的输出hidden states，计算输出\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, enc_hidden_size, dec_hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.enc_hidden_size = enc_hidden_size\n",
    "        self.dec_hidden_size = dec_hidden_size\n",
    "\n",
    "        self.linear_in = nn.Linear(enc_hidden_size * 2, dec_hidden_size, bias=False)\n",
    "        self.linear_out = nn.Linear(enc_hidden_size * 2 + dec_hidden_size, dec_hidden_size)\n",
    "\n",
    "    def forward(self, output, context, mask):\n",
    "        # output: batch_size, output_len, dec_hidden_size\n",
    "        # context: batch_size, context_len, 2*enc_hidden_size\n",
    "\n",
    "        batch_size = output.size(0)\n",
    "        output_len = output.size(1)\n",
    "        input_len = context.size(1)\n",
    "\n",
    "        context_in = self.linear_in(context.view(batch_size * input_len, -1)).view(\n",
    "            batch_size, input_len, -1)  # batch_size, context_len, dec_hidden_size\n",
    "\n",
    "        # context_in.transpose(1,2): batch_size, dec_hidden_size, context_len\n",
    "        # output: batch_size, output_len, dec_hidden_size\n",
    "        attn = torch.bmm(output, context_in.transpose(1, 2))\n",
    "        # batch_size, output_len, context_len\n",
    "\n",
    "        attn.data.masked_fill(mask, -1e6)\n",
    "\n",
    "        attn = F.softmax(attn, dim=2)\n",
    "        # batch_size, output_len, context_len\n",
    "\n",
    "        context = torch.bmm(attn, context)\n",
    "        # batch_size, output_len, enc_hidden_size\n",
    "\n",
    "        output = torch.cat((context, output), dim=2)  # batch_size, output_len, hidden_size*2\n",
    "\n",
    "        output = output.view(batch_size * output_len, -1)\n",
    "        output = torch.tanh(self.linear_out(output))\n",
    "        output = output.view(batch_size, output_len, -1)\n",
    "        return output, attn\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    decoder会根据已经翻译的句子内容，和context vectors，来决定下一个输出的单词\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embed_size, enc_hidden_size, dec_hidden_size, dropout=0.2):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.attention = Attention(enc_hidden_size, dec_hidden_size)\n",
    "        self.rnn = nn.GRU(embed_size, enc_hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(dec_hidden_size, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def create_mask(self, x_len, y_len):\n",
    "        # a mask of shape x_len * y_len\n",
    "        max_x_len = x_len.max()\n",
    "        max_y_len = y_len.max()\n",
    "        x_mask = torch.arange(max_x_len, device=x_len.device)[None, :] < x_len[:, None]\n",
    "        y_mask = torch.arange(max_y_len, device=x_len.device)[None, :] < y_len[:, None]\n",
    "        mask = ~ x_mask[:, :, None] * y_mask[:, None, :]\n",
    "        return mask\n",
    "\n",
    "    def forward(self, ctx, ctx_lengths, y, y_lengths, hid):\n",
    "        sorted_len, sorted_idx = y_lengths.sort(0, descending=True)\n",
    "        y_sorted = y[sorted_idx.long()]\n",
    "        hid = hid[:, sorted_idx.long()]\n",
    "\n",
    "        y_sorted = self.dropout(self.embed(y_sorted))  # batch_size, output_length, embed_size\n",
    "\n",
    "        packed_seq = nn.utils.rnn.pack_padded_sequence(y_sorted, sorted_len.long().cpu().data.numpy(), batch_first=True)\n",
    "        out, hid = self.rnn(packed_seq, hid)\n",
    "        unpacked, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
    "        _, original_idx = sorted_idx.sort(0, descending=False)\n",
    "        output_seq = unpacked[original_idx.long()].contiguous()\n",
    "        hid = hid[:, original_idx.long()].contiguous()\n",
    "\n",
    "        mask = self.create_mask(y_lengths, ctx_lengths)\n",
    "\n",
    "        output, attn = self.attention(output_seq, ctx, mask)\n",
    "        output = F.log_softmax(self.out(output), -1)\n",
    "\n",
    "        return output, hid, attn\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    \"\"\"\n",
    "    Seq2Seq, 最后我们构建Seq2Seq模型把encoder, attention, decoder串到一起\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 encoder_vocab_size,\n",
    "                 decoder_vocab_size,\n",
    "                 embed_size,\n",
    "                 enc_hidden_size,\n",
    "                 dec_hidden_size,\n",
    "                 dropout,\n",
    "                 ):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = Encoder(vocab_size=encoder_vocab_size,\n",
    "                               embed_size=embed_size,\n",
    "                               enc_hidden_size=enc_hidden_size,\n",
    "                               dec_hidden_size=dec_hidden_size,\n",
    "                               dropout=dropout)\n",
    "        self.decoder = Decoder(vocab_size=decoder_vocab_size,  # len(trg_2_ids),\n",
    "                               embed_size=embed_size,\n",
    "                               enc_hidden_size=enc_hidden_size,\n",
    "                               dec_hidden_size=dec_hidden_size,\n",
    "                               dropout=dropout)\n",
    "\n",
    "    def forward(self, x, x_lengths, y, y_lengths):\n",
    "        encoder_out, hid = self.encoder(x, x_lengths)\n",
    "        output, hid, attn = self.decoder(ctx=encoder_out,\n",
    "                                         ctx_lengths=x_lengths,\n",
    "                                         y=y,\n",
    "                                         y_lengths=y_lengths,\n",
    "                                         hid=hid)\n",
    "        return output, attn\n",
    "\n",
    "    def translate(self, x, x_lengths, y, max_length=128):\n",
    "        print(len(x))\n",
    "        encoder_out, hid = self.encoder(x, x_lengths)\n",
    "        preds = []\n",
    "        batch_size = x.shape[0]\n",
    "        attns = []\n",
    "        for i in range(max_length):\n",
    "            output, hid, attn = self.decoder(ctx=encoder_out,\n",
    "                                             ctx_lengths=x_lengths,\n",
    "                                             y=y,\n",
    "                                             y_lengths=torch.ones(batch_size).long().to(y.device),\n",
    "                                             hid=hid)\n",
    "            \n",
    "            y = output.max(2)[1].view(batch_size, 1)\n",
    "            preds.append(y)\n",
    "            \n",
    "            attns.append(attn)\n",
    "        return torch.cat(preds, 1), torch.cat(attns, 1)\n",
    "\n",
    "\n",
    "class LanguageModelCriterion(nn.Module):\n",
    "    \"\"\"\n",
    "    masked cross entropy loss\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LanguageModelCriterion, self).__init__()\n",
    "\n",
    "    def forward(self, input, target, mask):\n",
    "        # input: (batch_size * seq_len) * vocab_size\n",
    "        input = input.contiguous().view(-1, input.size(2))\n",
    "        # target: batch_size * 1\n",
    "        target = target.contiguous().view(-1, 1)\n",
    "        mask = mask.contiguous().view(-1, 1)\n",
    "        output = -input.gather(1, target) * mask\n",
    "        output = torch.sum(output) / torch.sum(mask)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2057f58c",
   "metadata": {},
   "source": [
    "# infer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "249d787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_tokens = [' ', '“', '”', '‘', '’', '琊', '\\n', '…', '—', '擤', '\\t', '֍', '玕', '', '《', '》']\n",
    "\n",
    "\n",
    "def get_errors(corrected_text, origin_text):\n",
    "    sub_details = []\n",
    "    for i, ori_char in enumerate(origin_text):\n",
    "        if i >= len(corrected_text):\n",
    "            continue\n",
    "        if ori_char in unk_tokens:\n",
    "            # deal with unk word\n",
    "            corrected_text = corrected_text[:i] + ori_char + corrected_text[i:]\n",
    "            continue\n",
    "        if ori_char != corrected_text[i]:\n",
    "            sub_details.append((ori_char, corrected_text[i], i, i + 1))\n",
    "    sub_details = sorted(sub_details, key=operator.itemgetter(2))\n",
    "    return corrected_text, sub_details\n",
    "\n",
    "\n",
    "class Inference(object):\n",
    "    def __init__(self, model_dir, arch='convseq2seq',\n",
    "                 embed_size=128, hidden_size=128, dropout=0.25, max_length=128):\n",
    "        logger.debug(\"Device: {}\".format(device))\n",
    "        logger.debug(f'Use {arch} model.')\n",
    "        if arch in ['seq2seq', 'convseq2seq']:\n",
    "            src_vocab_path = os.path.join(model_dir, 'vocab_source.txt')\n",
    "            trg_vocab_path = os.path.join(model_dir, 'vocab_target.txt')\n",
    "            self.src_2_ids = load_word_dict(src_vocab_path)\n",
    "            self.trg_2_ids = load_word_dict(trg_vocab_path)\n",
    "            self.id_2_trgs = {v: k for k, v in self.trg_2_ids.items()}\n",
    "            if arch == 'seq2seq':\n",
    "                self.model = Seq2Seq(encoder_vocab_size=len(self.src_2_ids),\n",
    "                                     decoder_vocab_size=len(self.trg_2_ids),\n",
    "                                     embed_size=embed_size,\n",
    "                                     enc_hidden_size=hidden_size,\n",
    "                                     dec_hidden_size=hidden_size,\n",
    "                                     dropout=dropout).to(device)\n",
    "                model_path = os.path.join(model_dir, 'seq2seq.pth')\n",
    "                logger.debug('Load model from {}'.format(model_path))\n",
    "                self.model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "                self.model.eval()\n",
    "            else:\n",
    "                trg_pad_idx = self.trg_2_ids[PAD_TOKEN]\n",
    "                self.model = ConvSeq2Seq(encoder_vocab_size=len(self.src_2_ids),\n",
    "                                         decoder_vocab_size=len(self.trg_2_ids),\n",
    "                                         embed_size=embed_size,\n",
    "                                         enc_hidden_size=hidden_size,\n",
    "                                         dec_hidden_size=hidden_size,\n",
    "                                         dropout=dropout,\n",
    "                                         trg_pad_idx=trg_pad_idx,\n",
    "                                         device=device,\n",
    "                                         max_length=max_length).to(device)\n",
    "                model_path = os.path.join(model_dir, 'convseq2seq.pth')\n",
    "                self.model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "                logger.debug('Load model from {}'.format(model_path))\n",
    "                self.model.eval()\n",
    "        elif arch == 'bertseq2seq':\n",
    "            # Bert Seq2seq model\n",
    "            use_cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "            # encoder_type=None, encoder_name=None, decoder_name=None\n",
    "            self.model = Seq2SeqModel(\"bert\", \"{}/encoder\".format(model_dir),\n",
    "                                      \"{}/decoder\".format(model_dir), use_cuda=use_cuda)\n",
    "        else:\n",
    "            logger.error('error arch: {}'.format(arch))\n",
    "            raise ValueError(\"Model arch choose error. Must use one of seq2seq model.\")\n",
    "        self.arch = arch\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def predict(self, sentence_list):\n",
    "        result = []\n",
    "        if self.arch in ['seq2seq', 'convseq2seq']:\n",
    "            for query in sentence_list:\n",
    "                out = []\n",
    "                tokens = query.split()\n",
    "                tokens = [SOS_TOKEN] + tokens + [EOS_TOKEN]\n",
    "                src_ids = [self.src_2_ids[i] for i in tokens if i in self.src_2_ids]\n",
    "\n",
    "                sos_idx = self.trg_2_ids[SOS_TOKEN]\n",
    "                if self.arch == 'seq2seq':\n",
    "                    src_tensor = torch.from_numpy(np.array(src_ids).reshape(1, -1)).long().to(device)\n",
    "                    src_tensor_len = torch.from_numpy(np.array([len(src_ids)])).long().to(device)\n",
    "                    sos_tensor = torch.Tensor([[self.trg_2_ids[SOS_TOKEN]]]).long().to(device)\n",
    "                    translation, attn = self.model.translate(src_tensor, src_tensor_len, sos_tensor, self.max_length)\n",
    "                    translation = [self.id_2_trgs[i] for i in translation.data.cpu().numpy().reshape(-1) if\n",
    "                                   i in self.id_2_trgs]\n",
    "                else:\n",
    "                    src_tensor = torch.from_numpy(np.array(src_ids).reshape(1, -1)).long().to(device)\n",
    "                    translation, attn = self.model.translate(src_tensor, sos_idx)\n",
    "                    translation = [self.id_2_trgs[i] for i in translation if i in self.id_2_trgs]\n",
    "                for word in translation:\n",
    "                    if word != EOS_TOKEN:\n",
    "                        out.append(word)\n",
    "                    else:\n",
    "                        break\n",
    "                corrected_text = ''.join(out)\n",
    "                corrected_text, sub_details = get_errors(corrected_text, query)\n",
    "                result.append([corrected_text, sub_details])\n",
    "        else:\n",
    "            corrected_sents = self.model.predict(sentence_list)\n",
    "            corrected_sents = [i.replace(' ', '') for i in corrected_sents]\n",
    "            for c, s in zip(corrected_sents, sentence_list):\n",
    "                c = c.replace(' ', '')\n",
    "                c, sub_details = get_errors(c, s)\n",
    "                result.append([c, sub_details])\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ea9c26",
   "metadata": {},
   "source": [
    "# train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88377ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_seq2seq_model(model, data, device, loss_fn):\n",
    "    model.eval()\n",
    "    total_num_words = 0.\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for it, (mb_x, mb_x_len, mb_y, mb_y_len) in enumerate(data):\n",
    "            mb_x = torch.from_numpy(mb_x).to(device).long()\n",
    "            mb_x_len = torch.from_numpy(mb_x_len).to(device).long()\n",
    "            mb_input = torch.from_numpy(mb_y[:, :-1]).to(device).long()\n",
    "            mb_output = torch.from_numpy(mb_y[:, 1:]).to(device).long()\n",
    "            mb_y_len = torch.from_numpy(mb_y_len - 1).to(device).long()\n",
    "            mb_y_len[mb_y_len <= 0] = 1\n",
    "\n",
    "            mb_pred, attn = model(mb_x, mb_x_len, mb_input, mb_y_len)\n",
    "\n",
    "            mb_out_mask = torch.arange(mb_y_len.max().item(), device=device)[None, :] < mb_y_len[:, None]\n",
    "            mb_out_mask = mb_out_mask.float()\n",
    "\n",
    "            loss = loss_fn(mb_pred, mb_output, mb_out_mask)\n",
    "\n",
    "            num_words = torch.sum(mb_y_len).item()\n",
    "            total_loss += loss.item() * num_words\n",
    "            total_num_words += num_words\n",
    "    loss = total_loss / total_num_words\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_seq2seq_model(model, train_data, device, loss_fn, optimizer, model_dir, epochs=20):\n",
    "    best_loss = 1e3\n",
    "    train_data, dev_data = train_test_split(train_data, test_size=0.1, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_num_words = 0.\n",
    "        total_loss = 0.\n",
    "        for it, (mb_x, mb_x_len, mb_y, mb_y_len) in enumerate(train_data):\n",
    "            mb_x = torch.from_numpy(mb_x).to(device).long()\n",
    "            mb_x_len = torch.from_numpy(mb_x_len).to(device).long()\n",
    "            mb_input = torch.from_numpy(mb_y[:, :-1]).to(device).long()\n",
    "            mb_output = torch.from_numpy(mb_y[:, 1:]).to(device).long()\n",
    "            mb_y_len = torch.from_numpy(mb_y_len - 1).to(device).long()\n",
    "            mb_y_len[mb_y_len <= 0] = 1\n",
    "\n",
    "            mb_pred, attn = model(mb_x, mb_x_len, mb_input, mb_y_len)\n",
    "\n",
    "            mb_out_mask = torch.arange(mb_y_len.max().item(), device=device)[None, :] < mb_y_len[:, None]\n",
    "            mb_out_mask = mb_out_mask.float()\n",
    "\n",
    "            loss = loss_fn(mb_pred, mb_output, mb_out_mask)\n",
    "\n",
    "            num_words = torch.sum(mb_y_len).item()\n",
    "            total_loss += loss.item() * num_words\n",
    "            total_num_words += num_words\n",
    "\n",
    "            # update optimizer\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.)\n",
    "            optimizer.step()\n",
    "\n",
    "            if it % 100 == 0:\n",
    "                logger.info(\"Epoch :{}/{}, iteration :{}/{} loss:{:.4f}\".format(epoch, epochs, it, len(train_data),\n",
    "                                                                                loss.item()))\n",
    "        cur_loss = total_loss / total_num_words\n",
    "        logger.info(\"Epoch :{}/{}, training loss:{:.4f}\".format(epoch, epochs, cur_loss))\n",
    "        if epoch % 1 == 0:\n",
    "            if dev_data:\n",
    "                eval_loss = evaluate_seq2seq_model(model, dev_data, device, loss_fn)\n",
    "                logger.info('Epoch:{}, dev loss:{:.4f}'.format(epoch, eval_loss))\n",
    "                cur_loss = eval_loss\n",
    "            # find best model\n",
    "            is_best = cur_loss < best_loss\n",
    "            best_loss = min(cur_loss, best_loss)\n",
    "            if is_best:\n",
    "                model_path = os.path.join(model_dir, 'seq2seq.pth')\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                logger.info('Epoch:{}, save new bert model:{}'.format(epoch, model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2dd74a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(arch, train_path, batch_size, embed_size, hidden_size, dropout, epochs,\n",
    "          model_dir, max_length, use_segment, model_name_or_path):\n",
    "    logger.info(\"device: {}\".format(device))\n",
    "    arch = arch.lower()\n",
    "    logger.debug(f'use {arch} model.')\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    if arch in ['seq2seq', 'convseq2seq']:\n",
    "        src_vocab_path = os.path.join(model_dir, 'vocab_source.txt')\n",
    "        trg_vocab_path = os.path.join(model_dir, 'vocab_target.txt')\n",
    "\n",
    "        source_texts, target_texts = create_dataset(train_path, split_on_space=True)\n",
    "        logger.debug(\"source_texts:\",source_texts)\n",
    "        #src_2_ids = read_vocab(source_texts)\n",
    "        #trg_2_ids = read_vocab(target_texts)\n",
    "        #print(src_2_ids)\n",
    "        #save_word_dict(src_2_ids, src_vocab_path)\n",
    "        #save_word_dict(trg_2_ids, trg_vocab_path)\n",
    "\n",
    "        src_2_ids = load_word_dict(src_vocab_path)\n",
    "        trg_2_ids = load_word_dict(trg_vocab_path)\n",
    "        id_2_srcs = {v: k for k, v in src_2_ids.items()}\n",
    "        id_2_trgs = {v: k for k, v in trg_2_ids.items()}\n",
    "        train_src, train_trg = one_hot(source_texts, target_texts, src_2_ids, trg_2_ids, sort_by_len=True)\n",
    "\n",
    "        logger.debug(f'src: {[id_2_srcs[i] for i in train_src[0]]}')\n",
    "        logger.debug(f'trg: {[id_2_trgs[i] for i in train_trg[0]]}')\n",
    "\n",
    "        train_data = gen_examples(train_src, train_trg, batch_size, max_length)\n",
    "\n",
    "        if arch == 'seq2seq':\n",
    "            # Normal seq2seq\n",
    "            model = Seq2Seq(encoder_vocab_size=len(src_2_ids),\n",
    "                            decoder_vocab_size=len(trg_2_ids),\n",
    "                            embed_size=embed_size,\n",
    "                            enc_hidden_size=hidden_size,\n",
    "                            dec_hidden_size=hidden_size,\n",
    "                            dropout=dropout).to(device)\n",
    "            logger.info(model)\n",
    "            loss_fn = LanguageModelCriterion().to(device)\n",
    "            optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "            train_seq2seq_model(model, train_data, device, loss_fn, optimizer, model_dir, epochs=epochs)\n",
    "        else:\n",
    "            # Conv seq2seq model\n",
    "            trg_pad_idx = trg_2_ids[PAD_TOKEN]\n",
    "            model = ConvSeq2Seq(encoder_vocab_size=len(src_2_ids),\n",
    "                                decoder_vocab_size=len(trg_2_ids),\n",
    "                                embed_size=embed_size,\n",
    "                                enc_hidden_size=hidden_size,\n",
    "                                dec_hidden_size=hidden_size,\n",
    "                                dropout=dropout,\n",
    "                                trg_pad_idx=trg_pad_idx,\n",
    "                                device=device,\n",
    "                                max_length=max_length).to(device)\n",
    "            logger.info(model)\n",
    "            loss_fn = nn.CrossEntropyLoss(ignore_index=trg_pad_idx)\n",
    "            optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "            train_convseq2seq_model(model, train_data, device, loss_fn, optimizer, model_dir, epochs=epochs)\n",
    "    elif arch == 'bertseq2seq':\n",
    "        # Bert Seq2seq model\n",
    "        model_args = {\n",
    "            \"reprocess_input_data\": True,\n",
    "            \"overwrite_output_dir\": True,\n",
    "            \"max_seq_length\": max_length if max_length else 128,\n",
    "            \"train_batch_size\": batch_size if batch_size else 8,\n",
    "            \"num_train_epochs\": epochs if epochs else 10,\n",
    "            \"save_eval_checkpoints\": False,\n",
    "            \"save_model_every_epoch\": False,\n",
    "            \"silent\": False,\n",
    "            \"evaluate_generated_text\": True,\n",
    "            \"evaluate_during_training\": True,\n",
    "            \"evaluate_during_training_verbose\": True,\n",
    "            \"best_model_dir\": os.path.join(model_dir, 'best_model'),\n",
    "            \"use_multiprocessing\": False,\n",
    "            \"save_best_model\": True,\n",
    "            \"max_length\": max_length if max_length else 128,  # The maximum length of the sequence to be generated.\n",
    "            \"output_dir\": model_dir if model_dir else \"./output/bertseq2seq/\",\n",
    "        }\n",
    "\n",
    "        use_cuda = True if torch.cuda.is_available() else False\n",
    "        # encoder_type=None, encoder_name=None, decoder_name=None\n",
    "        # encoder_name=\"bert-base-chinese\"\n",
    "        model = Seq2SeqModel(\"bert\", model_name_or_path, model_name_or_path, args=model_args, use_cuda=use_cuda)\n",
    "\n",
    "        logger.info('start train bertseq2seq ...')\n",
    "        data = load_bert_data(train_path, use_segment)\n",
    "        logger.info(f'load data done, data size: {len(data)}')\n",
    "        logger.debug(f'data samples: {data[:10]}')\n",
    "        train_data, dev_data = train_test_split(data, test_size=0.1, shuffle=False)\n",
    "\n",
    "        train_df = pd.DataFrame(train_data, columns=['input_text', 'target_text'])\n",
    "        dev_df = pd.DataFrame(dev_data, columns=['input_text', 'target_text'])\n",
    "\n",
    "        def count_matches(labels, preds):\n",
    "            logger.debug(f\"labels: {labels[:10]}\")\n",
    "            logger.debug(f\"preds: {preds[:10]}\")\n",
    "            match = sum([1 if label == pred else 0 for label, pred in zip(labels, preds)])\n",
    "            logger.debug(f\"match: {match}\")\n",
    "            return match\n",
    "\n",
    "        model.train_model(train_df, eval_data=dev_df, matches=count_matches)\n",
    "    else:\n",
    "        logger.error('error arch: {}'.format(arch))\n",
    "        raise ValueError(\"Model arch choose error. Must use one of seq2seq model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6793d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 22:12:28.687 | INFO     | __main__:train:3 - device: cuda\n",
      "2022-09-16 22:12:28.689 | DEBUG    | __main__:train:5 - use seq2seq model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save line size:41487 to output/train.txt\n",
      "save line size:4610 to output/test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 22:12:30.454 | DEBUG    | __main__:train:12 - source_texts:\n",
      "2022-09-16 22:12:32.792 | DEBUG    | __main__:train:25 - src: ['<sos>', 'ASN', 'GLN']\n",
      "2022-09-16 22:12:32.793 | DEBUG    | __main__:train:26 - trg: ['<sos>', 'ASN', 'GLN']\n",
      "2022-09-16 22:12:34.419 | INFO     | __main__:train:38 - Seq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (embed): Embedding(24, 128)\n",
      "    (rnn): GRU(128, 128, batch_first=True, bidirectional=True)\n",
      "    (dropout): Dropout(p=0.25, inplace=False)\n",
      "    (fc): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embed): Embedding(24, 128)\n",
      "    (attention): Attention(\n",
      "      (linear_in): Linear(in_features=256, out_features=128, bias=False)\n",
      "      (linear_out): Linear(in_features=384, out_features=128, bias=True)\n",
      "    )\n",
      "    (rnn): GRU(128, 128, batch_first=True)\n",
      "    (out): Linear(in_features=128, out_features=24, bias=True)\n",
      "    (dropout): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      ")\n",
      "2022-09-16 22:12:34.840 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :0/1167 loss:3.1845\n",
      "2022-09-16 22:12:36.770 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :100/1167 loss:0.9643\n",
      "2022-09-16 22:12:38.680 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :200/1167 loss:0.2535\n",
      "2022-09-16 22:12:40.665 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :300/1167 loss:0.3831\n",
      "2022-09-16 22:12:42.615 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :400/1167 loss:0.1585\n",
      "2022-09-16 22:12:44.556 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :500/1167 loss:0.0840\n",
      "2022-09-16 22:12:46.573 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :600/1167 loss:0.0569\n",
      "2022-09-16 22:12:48.481 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :700/1167 loss:0.0550\n",
      "2022-09-16 22:12:50.407 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :800/1167 loss:0.0382\n",
      "2022-09-16 22:12:52.331 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :900/1167 loss:0.0313\n",
      "2022-09-16 22:12:54.251 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :1000/1167 loss:0.0538\n",
      "2022-09-16 22:12:56.200 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :1100/1167 loss:0.0402\n",
      "2022-09-16 22:12:57.473 | INFO     | __main__:train_seq2seq_model:65 - Epoch :0/100, training loss:0.3031\n",
      "2022-09-16 22:12:58.241 | INFO     | __main__:train_seq2seq_model:69 - Epoch:0, dev loss:0.0266\n",
      "2022-09-16 22:12:58.247 | INFO     | __main__:train_seq2seq_model:77 - Epoch:0, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-16 22:12:58.260 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :0/1167 loss:0.2916\n",
      "2022-09-16 22:13:00.161 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :100/1167 loss:0.0577\n",
      "2022-09-16 22:13:02.074 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :200/1167 loss:0.0255\n",
      "2022-09-16 22:13:04.102 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :300/1167 loss:0.1433\n",
      "2022-09-16 22:13:06.068 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :400/1167 loss:0.0516\n",
      "2022-09-16 22:13:08.038 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :500/1167 loss:0.0338\n",
      "2022-09-16 22:13:10.073 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :600/1167 loss:0.0180\n",
      "2022-09-16 22:13:12.017 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :700/1167 loss:0.0171\n",
      "2022-09-16 22:13:13.995 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :800/1167 loss:0.0303\n",
      "2022-09-16 22:13:15.978 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :900/1167 loss:0.0158\n",
      "2022-09-16 22:13:18.068 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :1000/1167 loss:0.0393\n",
      "2022-09-16 22:13:20.142 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :1100/1167 loss:0.0225\n",
      "2022-09-16 22:13:21.446 | INFO     | __main__:train_seq2seq_model:65 - Epoch :1/100, training loss:0.0298\n",
      "2022-09-16 22:13:22.259 | INFO     | __main__:train_seq2seq_model:69 - Epoch:1, dev loss:0.0194\n",
      "2022-09-16 22:13:22.264 | INFO     | __main__:train_seq2seq_model:77 - Epoch:1, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-16 22:13:22.275 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :0/1167 loss:0.1964\n",
      "2022-09-16 22:13:24.193 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :100/1167 loss:0.0359\n",
      "2022-09-16 22:13:26.124 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :200/1167 loss:0.0180\n",
      "2022-09-16 22:13:28.137 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :300/1167 loss:0.1086\n",
      "2022-09-16 22:13:30.134 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :400/1167 loss:0.0408\n",
      "2022-09-16 22:13:32.112 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :500/1167 loss:0.0265\n",
      "2022-09-16 22:13:34.181 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :600/1167 loss:0.0127\n",
      "2022-09-16 22:13:36.137 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :700/1167 loss:0.0185\n",
      "2022-09-16 22:13:38.102 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :800/1167 loss:0.0225\n",
      "2022-09-16 22:13:40.089 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :900/1167 loss:0.0071\n",
      "2022-09-16 22:13:42.032 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :1000/1167 loss:0.0196\n",
      "2022-09-16 22:13:44.014 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :1100/1167 loss:0.0142\n",
      "2022-09-16 22:13:45.292 | INFO     | __main__:train_seq2seq_model:65 - Epoch :2/100, training loss:0.0230\n",
      "2022-09-16 22:13:46.057 | INFO     | __main__:train_seq2seq_model:69 - Epoch:2, dev loss:0.0165\n",
      "2022-09-16 22:13:46.062 | INFO     | __main__:train_seq2seq_model:77 - Epoch:2, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-16 22:13:46.073 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :0/1167 loss:0.1619\n",
      "2022-09-16 22:13:47.985 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :100/1167 loss:0.0306\n",
      "2022-09-16 22:13:49.891 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :200/1167 loss:0.0199\n",
      "2022-09-16 22:13:51.872 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :300/1167 loss:0.1017\n",
      "2022-09-16 22:13:53.851 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :400/1167 loss:0.0452\n",
      "2022-09-16 22:13:55.808 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :500/1167 loss:0.0227\n",
      "2022-09-16 22:13:57.827 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :600/1167 loss:0.0075\n",
      "2022-09-16 22:13:59.735 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :700/1167 loss:0.0120\n",
      "2022-09-16 22:14:01.661 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :800/1167 loss:0.0232\n",
      "2022-09-16 22:14:03.589 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :900/1167 loss:0.0303\n",
      "2022-09-16 22:14:05.536 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :1000/1167 loss:0.0161\n",
      "2022-09-16 22:14:07.503 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :1100/1167 loss:0.0126\n",
      "2022-09-16 22:14:08.782 | INFO     | __main__:train_seq2seq_model:65 - Epoch :3/100, training loss:0.0226\n",
      "2022-09-16 22:14:09.554 | INFO     | __main__:train_seq2seq_model:69 - Epoch:3, dev loss:0.0160\n",
      "2022-09-16 22:14:09.559 | INFO     | __main__:train_seq2seq_model:77 - Epoch:3, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-16 22:14:09.569 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :0/1167 loss:0.1733\n",
      "2022-09-16 22:14:11.476 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :100/1167 loss:0.0452\n",
      "2022-09-16 22:14:13.387 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :200/1167 loss:0.0202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 22:14:15.377 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :300/1167 loss:0.0943\n",
      "2022-09-16 22:14:17.331 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :400/1167 loss:0.0412\n",
      "2022-09-16 22:14:19.291 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :500/1167 loss:0.0126\n",
      "2022-09-16 22:14:21.328 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :600/1167 loss:0.0147\n",
      "2022-09-16 22:14:23.261 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :700/1167 loss:0.0099\n",
      "2022-09-16 22:14:25.352 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :800/1167 loss:0.0118\n",
      "2022-09-16 22:14:27.354 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :900/1167 loss:0.0077\n",
      "2022-09-16 22:14:29.362 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :1000/1167 loss:0.0232\n",
      "2022-09-16 22:14:31.371 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :1100/1167 loss:0.0205\n",
      "2022-09-16 22:14:32.696 | INFO     | __main__:train_seq2seq_model:65 - Epoch :4/100, training loss:0.0198\n",
      "2022-09-16 22:14:33.483 | INFO     | __main__:train_seq2seq_model:69 - Epoch:4, dev loss:0.0168\n",
      "2022-09-16 22:14:33.493 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :0/1167 loss:0.1620\n",
      "2022-09-16 22:14:35.449 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :100/1167 loss:0.0227\n",
      "2022-09-16 22:14:37.386 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :200/1167 loss:0.0106\n",
      "2022-09-16 22:14:39.390 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :300/1167 loss:0.0984\n",
      "2022-09-16 22:14:41.367 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :400/1167 loss:0.0361\n",
      "2022-09-16 22:14:43.325 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :500/1167 loss:0.0398\n",
      "2022-09-16 22:14:45.356 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :600/1167 loss:0.0077\n",
      "2022-09-16 22:14:47.273 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :700/1167 loss:0.0102\n",
      "2022-09-16 22:14:49.322 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :800/1167 loss:0.0112\n",
      "2022-09-16 22:14:51.299 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :900/1167 loss:0.0071\n",
      "2022-09-16 22:14:53.274 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :1000/1167 loss:0.0183\n",
      "2022-09-16 22:14:55.264 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :1100/1167 loss:0.0137\n",
      "2022-09-16 22:14:56.544 | INFO     | __main__:train_seq2seq_model:65 - Epoch :5/100, training loss:0.0187\n",
      "2022-09-16 22:14:57.395 | INFO     | __main__:train_seq2seq_model:69 - Epoch:5, dev loss:0.0149\n",
      "2022-09-16 22:14:57.401 | INFO     | __main__:train_seq2seq_model:77 - Epoch:5, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-16 22:14:57.412 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :0/1167 loss:0.1451\n",
      "2022-09-16 22:14:59.374 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :100/1167 loss:0.0207\n",
      "2022-09-16 22:15:01.291 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :200/1167 loss:0.0182\n",
      "2022-09-16 22:15:03.317 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :300/1167 loss:0.1021\n",
      "2022-09-16 22:15:05.267 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :400/1167 loss:0.0390\n",
      "2022-09-16 22:15:07.192 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :500/1167 loss:0.0314\n",
      "2022-09-16 22:15:09.179 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :600/1167 loss:0.0167\n",
      "2022-09-16 22:15:11.052 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :700/1167 loss:0.0108\n",
      "2022-09-16 22:15:12.942 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :800/1167 loss:0.0194\n",
      "2022-09-16 22:15:14.830 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :900/1167 loss:0.0049\n",
      "2022-09-16 22:15:16.712 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :1000/1167 loss:0.0127\n",
      "2022-09-16 22:15:18.631 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :1100/1167 loss:0.0131\n",
      "2022-09-16 22:15:19.881 | INFO     | __main__:train_seq2seq_model:65 - Epoch :6/100, training loss:0.0186\n",
      "2022-09-16 22:15:20.637 | INFO     | __main__:train_seq2seq_model:69 - Epoch:6, dev loss:0.0161\n",
      "2022-09-16 22:15:20.647 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :0/1167 loss:0.1539\n",
      "2022-09-16 22:15:22.508 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :100/1167 loss:0.0234\n",
      "2022-09-16 22:15:24.384 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :200/1167 loss:0.0136\n",
      "2022-09-16 22:15:26.331 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :300/1167 loss:0.0931\n",
      "2022-09-16 22:15:28.249 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :400/1167 loss:0.0527\n",
      "2022-09-16 22:15:30.152 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :500/1167 loss:0.0289\n",
      "2022-09-16 22:15:32.135 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :600/1167 loss:0.0207\n",
      "2022-09-16 22:15:34.005 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :700/1167 loss:0.0095\n",
      "2022-09-16 22:15:35.893 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :800/1167 loss:0.0145\n",
      "2022-09-16 22:15:37.782 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :900/1167 loss:0.0123\n",
      "2022-09-16 22:15:39.669 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :1000/1167 loss:0.0306\n",
      "2022-09-16 22:15:41.585 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :1100/1167 loss:0.0117\n",
      "2022-09-16 22:15:42.837 | INFO     | __main__:train_seq2seq_model:65 - Epoch :7/100, training loss:0.0179\n",
      "2022-09-16 22:15:43.583 | INFO     | __main__:train_seq2seq_model:69 - Epoch:7, dev loss:0.0157\n",
      "2022-09-16 22:15:43.593 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :0/1167 loss:0.1579\n",
      "2022-09-16 22:15:45.453 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :100/1167 loss:0.0211\n",
      "2022-09-16 22:15:47.327 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :200/1167 loss:0.0062\n",
      "2022-09-16 22:15:49.278 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :300/1167 loss:0.0967\n",
      "2022-09-16 22:15:51.197 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :400/1167 loss:0.0378\n",
      "2022-09-16 22:15:53.101 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :500/1167 loss:0.0124\n",
      "2022-09-16 22:15:55.079 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :600/1167 loss:0.0202\n",
      "2022-09-16 22:15:56.947 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :700/1167 loss:0.0058\n",
      "2022-09-16 22:15:58.835 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :800/1167 loss:0.0157\n",
      "2022-09-16 22:16:00.722 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :900/1167 loss:0.0061\n",
      "2022-09-16 22:16:02.611 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :1000/1167 loss:0.0148\n",
      "2022-09-16 22:16:04.533 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :1100/1167 loss:0.0117\n",
      "2022-09-16 22:16:05.785 | INFO     | __main__:train_seq2seq_model:65 - Epoch :8/100, training loss:0.0167\n",
      "2022-09-16 22:16:06.537 | INFO     | __main__:train_seq2seq_model:69 - Epoch:8, dev loss:0.0154\n",
      "2022-09-16 22:16:06.547 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :0/1167 loss:0.1621\n",
      "2022-09-16 22:16:08.407 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :100/1167 loss:0.0286\n",
      "2022-09-16 22:16:10.285 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :200/1167 loss:0.0075\n",
      "2022-09-16 22:16:12.241 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :300/1167 loss:0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 22:16:14.153 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :400/1167 loss:0.0427\n",
      "2022-09-16 22:16:16.056 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :500/1167 loss:0.0136\n",
      "2022-09-16 22:16:18.033 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :600/1167 loss:0.0085\n",
      "2022-09-16 22:16:19.905 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :700/1167 loss:0.0148\n",
      "2022-09-16 22:16:21.793 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :800/1167 loss:0.0069\n",
      "2022-09-16 22:16:23.679 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :900/1167 loss:0.0041\n",
      "2022-09-16 22:16:25.562 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :1000/1167 loss:0.0181\n",
      "2022-09-16 22:16:27.481 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :1100/1167 loss:0.0107\n",
      "2022-09-16 22:16:28.733 | INFO     | __main__:train_seq2seq_model:65 - Epoch :9/100, training loss:0.0173\n",
      "2022-09-16 22:16:29.494 | INFO     | __main__:train_seq2seq_model:69 - Epoch:9, dev loss:0.0152\n",
      "2022-09-16 22:16:29.504 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :0/1167 loss:0.1712\n",
      "2022-09-16 22:16:31.363 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :100/1167 loss:0.0412\n",
      "2022-09-16 22:16:33.237 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :200/1167 loss:0.0062\n",
      "2022-09-16 22:16:35.187 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :300/1167 loss:0.0921\n",
      "2022-09-16 22:16:37.099 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :400/1167 loss:0.0363\n",
      "2022-09-16 22:16:39.006 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :500/1167 loss:0.0223\n",
      "2022-09-16 22:16:40.985 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :600/1167 loss:0.0110\n",
      "2022-09-16 22:16:42.856 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :700/1167 loss:0.0051\n",
      "2022-09-16 22:16:44.745 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :800/1167 loss:0.0217\n",
      "2022-09-16 22:16:46.630 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :900/1167 loss:0.0098\n",
      "2022-09-16 22:16:48.509 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :1000/1167 loss:0.0248\n",
      "2022-09-16 22:16:50.425 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :1100/1167 loss:0.0096\n",
      "2022-09-16 22:16:51.673 | INFO     | __main__:train_seq2seq_model:65 - Epoch :10/100, training loss:0.0159\n",
      "2022-09-16 22:16:52.420 | INFO     | __main__:train_seq2seq_model:69 - Epoch:10, dev loss:0.0136\n",
      "2022-09-16 22:16:52.425 | INFO     | __main__:train_seq2seq_model:77 - Epoch:10, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-16 22:16:52.435 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :0/1167 loss:0.1532\n",
      "2022-09-16 22:16:54.296 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :100/1167 loss:0.0264\n",
      "2022-09-16 22:16:56.172 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :200/1167 loss:0.0092\n",
      "2022-09-16 22:16:58.118 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :300/1167 loss:0.0950\n",
      "2022-09-16 22:17:00.035 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :400/1167 loss:0.0375\n",
      "2022-09-16 22:17:01.936 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :500/1167 loss:0.0290\n",
      "2022-09-16 22:17:03.912 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :600/1167 loss:0.0082\n",
      "2022-09-16 22:17:05.788 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :700/1167 loss:0.0057\n",
      "2022-09-16 22:17:07.675 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :800/1167 loss:0.0068\n",
      "2022-09-16 22:17:09.559 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :900/1167 loss:0.0028\n",
      "2022-09-16 22:17:11.458 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :1000/1167 loss:0.0144\n",
      "2022-09-16 22:17:13.369 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :1100/1167 loss:0.0106\n",
      "2022-09-16 22:17:14.622 | INFO     | __main__:train_seq2seq_model:65 - Epoch :11/100, training loss:0.0161\n",
      "2022-09-16 22:17:15.373 | INFO     | __main__:train_seq2seq_model:69 - Epoch:11, dev loss:0.0166\n",
      "2022-09-16 22:17:15.384 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :0/1167 loss:0.1615\n",
      "2022-09-16 22:17:17.241 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :100/1167 loss:0.0326\n",
      "2022-09-16 22:17:19.115 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :200/1167 loss:0.0125\n",
      "2022-09-16 22:17:21.063 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :300/1167 loss:0.0957\n",
      "2022-09-16 22:17:22.977 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :400/1167 loss:0.0384\n",
      "2022-09-16 22:17:24.881 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :500/1167 loss:0.0250\n",
      "2022-09-16 22:17:26.856 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :600/1167 loss:0.0091\n",
      "2022-09-16 22:17:28.725 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :700/1167 loss:0.0063\n",
      "2022-09-16 22:17:30.615 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :800/1167 loss:0.0097\n",
      "2022-09-16 22:17:32.497 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :900/1167 loss:0.0029\n",
      "2022-09-16 22:17:34.381 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :1000/1167 loss:0.0178\n",
      "2022-09-16 22:17:36.292 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :1100/1167 loss:0.0085\n",
      "2022-09-16 22:17:37.546 | INFO     | __main__:train_seq2seq_model:65 - Epoch :12/100, training loss:0.0159\n",
      "2022-09-16 22:17:38.297 | INFO     | __main__:train_seq2seq_model:69 - Epoch:12, dev loss:0.0133\n",
      "2022-09-16 22:17:38.301 | INFO     | __main__:train_seq2seq_model:77 - Epoch:12, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-16 22:17:38.312 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :0/1167 loss:0.1454\n",
      "2022-09-16 22:17:40.172 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :100/1167 loss:0.0196\n",
      "2022-09-16 22:17:42.045 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :200/1167 loss:0.0099\n",
      "2022-09-16 22:17:43.990 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :300/1167 loss:0.0887\n",
      "2022-09-16 22:17:45.903 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :400/1167 loss:0.0390\n",
      "2022-09-16 22:17:47.803 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :500/1167 loss:0.0243\n",
      "2022-09-16 22:17:49.780 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :600/1167 loss:0.0071\n",
      "2022-09-16 22:17:51.649 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :700/1167 loss:0.0059\n",
      "2022-09-16 22:17:53.532 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :800/1167 loss:0.0081\n",
      "2022-09-16 22:17:55.417 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :900/1167 loss:0.0061\n",
      "2022-09-16 22:17:57.304 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :1000/1167 loss:0.0178\n",
      "2022-09-16 22:17:59.219 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :1100/1167 loss:0.0080\n",
      "2022-09-16 22:18:00.470 | INFO     | __main__:train_seq2seq_model:65 - Epoch :13/100, training loss:0.0154\n",
      "2022-09-16 22:18:01.224 | INFO     | __main__:train_seq2seq_model:69 - Epoch:13, dev loss:0.0136\n",
      "2022-09-16 22:18:01.234 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :0/1167 loss:0.1483\n",
      "2022-09-16 22:18:03.092 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :100/1167 loss:0.0272\n",
      "2022-09-16 22:18:04.969 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :200/1167 loss:0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 22:18:06.917 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :300/1167 loss:0.0944\n",
      "2022-09-16 22:18:08.832 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :400/1167 loss:0.0386\n",
      "2022-09-16 22:18:10.734 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :500/1167 loss:0.0112\n",
      "2022-09-16 22:18:12.709 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :600/1167 loss:0.0030\n",
      "2022-09-16 22:18:14.577 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :700/1167 loss:0.0077\n",
      "2022-09-16 22:18:16.461 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :800/1167 loss:0.0059\n",
      "2022-09-16 22:18:18.346 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :900/1167 loss:0.0086\n",
      "2022-09-16 22:18:20.226 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :1000/1167 loss:0.0189\n",
      "2022-09-16 22:18:22.138 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :1100/1167 loss:0.0098\n",
      "2022-09-16 22:18:23.393 | INFO     | __main__:train_seq2seq_model:65 - Epoch :14/100, training loss:0.0143\n",
      "2022-09-16 22:18:24.143 | INFO     | __main__:train_seq2seq_model:69 - Epoch:14, dev loss:0.0169\n",
      "2022-09-16 22:18:24.154 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :0/1167 loss:0.1619\n",
      "2022-09-16 22:18:26.015 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :100/1167 loss:0.0173\n",
      "2022-09-16 22:18:27.887 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :200/1167 loss:0.0120\n",
      "2022-09-16 22:18:29.836 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :300/1167 loss:0.0895\n",
      "2022-09-16 22:18:31.748 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :400/1167 loss:0.0336\n",
      "2022-09-16 22:18:33.646 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :500/1167 loss:0.0111\n",
      "2022-09-16 22:18:35.626 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :600/1167 loss:0.0107\n",
      "2022-09-16 22:18:37.493 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :700/1167 loss:0.0068\n",
      "2022-09-16 22:18:39.380 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :800/1167 loss:0.0057\n",
      "2022-09-16 22:18:41.265 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :900/1167 loss:0.0048\n",
      "2022-09-16 22:18:43.145 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :1000/1167 loss:0.0117\n",
      "2022-09-16 22:18:45.066 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :1100/1167 loss:0.0075\n",
      "2022-09-16 22:18:46.314 | INFO     | __main__:train_seq2seq_model:65 - Epoch :15/100, training loss:0.0147\n",
      "2022-09-16 22:18:47.067 | INFO     | __main__:train_seq2seq_model:69 - Epoch:15, dev loss:0.0132\n",
      "2022-09-16 22:18:47.072 | INFO     | __main__:train_seq2seq_model:77 - Epoch:15, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-16 22:18:47.083 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :0/1167 loss:0.1459\n",
      "2022-09-16 22:18:48.941 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :100/1167 loss:0.0173\n",
      "2022-09-16 22:18:50.817 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :200/1167 loss:0.0024\n",
      "2022-09-16 22:18:52.764 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :300/1167 loss:0.0956\n",
      "2022-09-16 22:18:54.680 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :400/1167 loss:0.0389\n",
      "2022-09-16 22:18:56.581 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :500/1167 loss:0.0114\n",
      "2022-09-16 22:18:58.559 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :600/1167 loss:0.0026\n",
      "2022-09-16 22:19:00.429 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :700/1167 loss:0.0069\n",
      "2022-09-16 22:19:02.316 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :800/1167 loss:0.0069\n",
      "2022-09-16 22:19:04.198 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :900/1167 loss:0.0051\n",
      "2022-09-16 22:19:06.085 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :1000/1167 loss:0.0138\n",
      "2022-09-16 22:19:07.999 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :1100/1167 loss:0.0094\n",
      "2022-09-16 22:19:09.248 | INFO     | __main__:train_seq2seq_model:65 - Epoch :16/100, training loss:0.0136\n",
      "2022-09-16 22:19:10.001 | INFO     | __main__:train_seq2seq_model:69 - Epoch:16, dev loss:0.0139\n",
      "2022-09-16 22:19:10.011 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :0/1167 loss:0.1401\n",
      "2022-09-16 22:19:11.869 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :100/1167 loss:0.0151\n",
      "2022-09-16 22:19:13.741 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :200/1167 loss:0.0075\n",
      "2022-09-16 22:19:15.689 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :300/1167 loss:0.0844\n",
      "2022-09-16 22:19:17.602 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :400/1167 loss:0.0334\n",
      "2022-09-16 22:19:19.525 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :500/1167 loss:0.0103\n",
      "2022-09-16 22:19:21.527 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :600/1167 loss:0.0041\n",
      "2022-09-16 22:19:23.398 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :700/1167 loss:0.0094\n",
      "2022-09-16 22:19:25.287 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :800/1167 loss:0.0102\n",
      "2022-09-16 22:19:27.180 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :900/1167 loss:0.0050\n",
      "2022-09-16 22:19:29.064 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :1000/1167 loss:0.0172\n",
      "2022-09-16 22:19:30.984 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :1100/1167 loss:0.0068\n",
      "2022-09-16 22:19:32.234 | INFO     | __main__:train_seq2seq_model:65 - Epoch :17/100, training loss:0.0140\n",
      "2022-09-16 22:19:32.986 | INFO     | __main__:train_seq2seq_model:69 - Epoch:17, dev loss:0.0149\n",
      "2022-09-16 22:19:32.997 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :0/1167 loss:0.1591\n",
      "2022-09-16 22:19:34.863 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :100/1167 loss:0.0244\n",
      "2022-09-16 22:19:36.744 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :200/1167 loss:0.0050\n",
      "2022-09-16 22:19:38.692 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :300/1167 loss:0.0943\n",
      "2022-09-16 22:19:40.630 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :400/1167 loss:0.0390\n",
      "2022-09-16 22:19:42.571 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :500/1167 loss:0.0153\n",
      "2022-09-16 22:19:44.555 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :600/1167 loss:0.0052\n",
      "2022-09-16 22:19:46.426 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :700/1167 loss:0.0102\n",
      "2022-09-16 22:19:48.316 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :800/1167 loss:0.0110\n",
      "2022-09-16 22:19:50.205 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :900/1167 loss:0.0046\n",
      "2022-09-16 22:19:52.090 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :1000/1167 loss:0.0133\n",
      "2022-09-16 22:19:54.007 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :1100/1167 loss:0.0103\n",
      "2022-09-16 22:19:55.270 | INFO     | __main__:train_seq2seq_model:65 - Epoch :18/100, training loss:0.0142\n",
      "2022-09-16 22:19:56.019 | INFO     | __main__:train_seq2seq_model:69 - Epoch:18, dev loss:0.0130\n",
      "2022-09-16 22:19:56.023 | INFO     | __main__:train_seq2seq_model:77 - Epoch:18, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-16 22:19:56.034 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :0/1167 loss:0.1467\n",
      "2022-09-16 22:19:57.897 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :100/1167 loss:0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 22:19:59.774 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :200/1167 loss:0.0105\n",
      "2022-09-16 22:20:01.724 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :300/1167 loss:0.0989\n",
      "2022-09-16 22:20:03.635 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :400/1167 loss:0.0496\n",
      "2022-09-16 22:20:05.540 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :500/1167 loss:0.0191\n",
      "2022-09-16 22:20:07.520 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :600/1167 loss:0.0037\n",
      "2022-09-16 22:20:09.389 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :700/1167 loss:0.0043\n",
      "2022-09-16 22:20:11.277 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :800/1167 loss:0.0059\n",
      "2022-09-16 22:20:13.162 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :900/1167 loss:0.0025\n",
      "2022-09-16 22:20:15.049 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :1000/1167 loss:0.0116\n",
      "2022-09-16 22:20:16.966 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :1100/1167 loss:0.0094\n",
      "2022-09-16 22:20:18.215 | INFO     | __main__:train_seq2seq_model:65 - Epoch :19/100, training loss:0.0137\n",
      "2022-09-16 22:20:18.964 | INFO     | __main__:train_seq2seq_model:69 - Epoch:19, dev loss:0.0137\n",
      "2022-09-16 22:20:18.974 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :0/1167 loss:0.1458\n",
      "2022-09-16 22:20:20.835 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :100/1167 loss:0.0222\n",
      "2022-09-16 22:20:22.708 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :200/1167 loss:0.0045\n",
      "2022-09-16 22:20:24.660 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :300/1167 loss:0.0853\n",
      "2022-09-16 22:20:26.571 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :400/1167 loss:0.0346\n",
      "2022-09-16 22:20:28.470 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :500/1167 loss:0.0116\n",
      "2022-09-16 22:20:30.452 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :600/1167 loss:0.0085\n",
      "2022-09-16 22:20:32.323 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :700/1167 loss:0.0037\n",
      "2022-09-16 22:20:34.219 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :800/1167 loss:0.0102\n",
      "2022-09-16 22:20:36.111 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :900/1167 loss:0.0045\n",
      "2022-09-16 22:20:37.999 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :1000/1167 loss:0.0134\n",
      "2022-09-16 22:20:39.915 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :1100/1167 loss:0.0076\n",
      "2022-09-16 22:20:41.165 | INFO     | __main__:train_seq2seq_model:65 - Epoch :20/100, training loss:0.0135\n",
      "2022-09-16 22:20:41.915 | INFO     | __main__:train_seq2seq_model:69 - Epoch:20, dev loss:0.0125\n",
      "2022-09-16 22:20:41.920 | INFO     | __main__:train_seq2seq_model:77 - Epoch:20, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-16 22:20:41.930 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :0/1167 loss:0.1287\n",
      "2022-09-16 22:20:43.795 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :100/1167 loss:0.0262\n",
      "2022-09-16 22:20:45.668 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :200/1167 loss:0.0020\n",
      "2022-09-16 22:20:47.619 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :300/1167 loss:0.0892\n",
      "2022-09-16 22:20:49.538 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :400/1167 loss:0.0330\n",
      "2022-09-16 22:20:51.440 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :500/1167 loss:0.0102\n",
      "2022-09-16 22:20:53.418 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :600/1167 loss:0.0101\n",
      "2022-09-16 22:20:55.289 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :700/1167 loss:0.0060\n",
      "2022-09-16 22:20:57.175 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :800/1167 loss:0.0083\n",
      "2022-09-16 22:20:59.057 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :900/1167 loss:0.0102\n",
      "2022-09-16 22:21:00.943 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :1000/1167 loss:0.0197\n",
      "2022-09-16 22:21:02.857 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :1100/1167 loss:0.0154\n",
      "2022-09-16 22:21:04.109 | INFO     | __main__:train_seq2seq_model:65 - Epoch :21/100, training loss:0.0140\n",
      "2022-09-16 22:21:04.860 | INFO     | __main__:train_seq2seq_model:69 - Epoch:21, dev loss:0.0135\n",
      "2022-09-16 22:21:04.870 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :0/1167 loss:0.1378\n",
      "2022-09-16 22:21:06.730 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :100/1167 loss:0.0271\n",
      "2022-09-16 22:21:08.605 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :200/1167 loss:0.0038\n",
      "2022-09-16 22:21:10.554 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :300/1167 loss:0.0902\n",
      "2022-09-16 22:21:12.470 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :400/1167 loss:0.0410\n",
      "2022-09-16 22:21:14.368 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :500/1167 loss:0.0107\n",
      "2022-09-16 22:21:16.342 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :600/1167 loss:0.0108\n",
      "2022-09-16 22:21:18.213 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :700/1167 loss:0.0041\n",
      "2022-09-16 22:21:20.102 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :800/1167 loss:0.0083\n",
      "2022-09-16 22:21:21.988 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :900/1167 loss:0.0042\n",
      "2022-09-16 22:21:23.870 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :1000/1167 loss:0.0103\n",
      "2022-09-16 22:21:25.785 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :1100/1167 loss:0.0061\n",
      "2022-09-16 22:21:27.037 | INFO     | __main__:train_seq2seq_model:65 - Epoch :22/100, training loss:0.0133\n",
      "2022-09-16 22:21:27.784 | INFO     | __main__:train_seq2seq_model:69 - Epoch:22, dev loss:0.0133\n",
      "2022-09-16 22:21:27.795 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :0/1167 loss:0.1316\n",
      "2022-09-16 22:21:29.659 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :100/1167 loss:0.0181\n",
      "2022-09-16 22:21:31.537 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :200/1167 loss:0.0047\n",
      "2022-09-16 22:21:33.485 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :300/1167 loss:0.0913\n",
      "2022-09-16 22:21:35.399 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :400/1167 loss:0.0400\n",
      "2022-09-16 22:21:37.298 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :500/1167 loss:0.0094\n",
      "2022-09-16 22:21:39.277 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :600/1167 loss:0.0041\n",
      "2022-09-16 22:21:41.171 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :700/1167 loss:0.0044\n",
      "2022-09-16 22:21:43.056 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :800/1167 loss:0.0231\n",
      "2022-09-16 22:21:44.941 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :900/1167 loss:0.0028\n",
      "2022-09-16 22:21:46.826 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :1000/1167 loss:0.0169\n",
      "2022-09-16 22:21:48.740 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :1100/1167 loss:0.0103\n",
      "2022-09-16 22:21:49.994 | INFO     | __main__:train_seq2seq_model:65 - Epoch :23/100, training loss:0.0137\n",
      "2022-09-16 22:21:50.746 | INFO     | __main__:train_seq2seq_model:69 - Epoch:23, dev loss:0.0131\n",
      "2022-09-16 22:21:50.757 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :0/1167 loss:0.1304\n",
      "2022-09-16 22:21:52.617 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :100/1167 loss:0.0295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 22:21:54.495 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :200/1167 loss:0.0019\n",
      "2022-09-16 22:21:56.445 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :300/1167 loss:0.0933\n",
      "2022-09-16 22:21:58.360 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :400/1167 loss:0.0388\n",
      "2022-09-16 22:22:00.262 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :500/1167 loss:0.0101\n",
      "2022-09-16 22:22:02.237 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :600/1167 loss:0.0083\n",
      "2022-09-16 22:22:04.114 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :700/1167 loss:0.0044\n",
      "2022-09-16 22:22:06.000 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :800/1167 loss:0.0097\n",
      "2022-09-16 22:22:07.885 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :900/1167 loss:0.0025\n",
      "2022-09-16 22:22:09.769 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :1000/1167 loss:0.0140\n",
      "2022-09-16 22:22:11.682 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :1100/1167 loss:0.0072\n",
      "2022-09-16 22:22:12.934 | INFO     | __main__:train_seq2seq_model:65 - Epoch :24/100, training loss:0.0134\n",
      "2022-09-16 22:22:13.684 | INFO     | __main__:train_seq2seq_model:69 - Epoch:24, dev loss:0.0147\n",
      "2022-09-16 22:22:13.695 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :0/1167 loss:0.1283\n",
      "2022-09-16 22:22:15.553 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :100/1167 loss:0.0176\n",
      "2022-09-16 22:22:17.427 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :200/1167 loss:0.0051\n",
      "2022-09-16 22:22:19.374 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :300/1167 loss:0.0937\n",
      "2022-09-16 22:22:21.292 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :400/1167 loss:0.0337\n",
      "2022-09-16 22:22:23.193 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :500/1167 loss:0.0182\n",
      "2022-09-16 22:22:25.171 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :600/1167 loss:0.0095\n",
      "2022-09-16 22:22:27.045 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :700/1167 loss:0.0040\n",
      "2022-09-16 22:22:28.950 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :800/1167 loss:0.0066\n",
      "2022-09-16 22:22:30.912 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :900/1167 loss:0.0027\n",
      "2022-09-16 22:22:32.819 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :1000/1167 loss:0.0102\n",
      "2022-09-16 22:22:34.737 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :1100/1167 loss:0.0092\n",
      "2022-09-16 22:22:35.990 | INFO     | __main__:train_seq2seq_model:65 - Epoch :25/100, training loss:0.0132\n",
      "2022-09-16 22:22:36.744 | INFO     | __main__:train_seq2seq_model:69 - Epoch:25, dev loss:0.0135\n",
      "2022-09-16 22:22:36.755 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :0/1167 loss:0.1240\n",
      "2022-09-16 22:22:38.615 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :100/1167 loss:0.0181\n",
      "2022-09-16 22:22:40.492 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :200/1167 loss:0.0020\n",
      "2022-09-16 22:22:42.442 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :300/1167 loss:0.0859\n",
      "2022-09-16 22:22:44.359 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :400/1167 loss:0.0362\n",
      "2022-09-16 22:22:46.259 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :500/1167 loss:0.0180\n",
      "2022-09-16 22:22:48.232 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :600/1167 loss:0.0074\n",
      "2022-09-16 22:22:50.101 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :700/1167 loss:0.0047\n",
      "2022-09-16 22:22:51.987 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :800/1167 loss:0.0056\n",
      "2022-09-16 22:22:53.871 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :900/1167 loss:0.0071\n",
      "2022-09-16 22:22:55.754 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :1000/1167 loss:0.0169\n",
      "2022-09-16 22:22:57.668 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :1100/1167 loss:0.0108\n",
      "2022-09-16 22:22:58.917 | INFO     | __main__:train_seq2seq_model:65 - Epoch :26/100, training loss:0.0131\n",
      "2022-09-16 22:22:59.668 | INFO     | __main__:train_seq2seq_model:69 - Epoch:26, dev loss:0.0140\n",
      "2022-09-16 22:22:59.678 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :0/1167 loss:0.1280\n",
      "2022-09-16 22:23:01.540 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :100/1167 loss:0.0219\n",
      "2022-09-16 22:23:03.417 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :200/1167 loss:0.0024\n",
      "2022-09-16 22:23:05.367 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :300/1167 loss:0.0893\n",
      "2022-09-16 22:23:07.278 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :400/1167 loss:0.0329\n",
      "2022-09-16 22:23:09.181 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :500/1167 loss:0.0192\n",
      "2022-09-16 22:23:11.162 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :600/1167 loss:0.0051\n",
      "2022-09-16 22:23:13.033 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :700/1167 loss:0.0039\n",
      "2022-09-16 22:23:14.918 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :800/1167 loss:0.0132\n",
      "2022-09-16 22:23:16.804 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :900/1167 loss:0.0025\n",
      "2022-09-16 22:23:18.685 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :1000/1167 loss:0.0142\n",
      "2022-09-16 22:23:20.609 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :1100/1167 loss:0.0058\n",
      "2022-09-16 22:23:21.859 | INFO     | __main__:train_seq2seq_model:65 - Epoch :27/100, training loss:0.0135\n",
      "2022-09-16 22:23:22.616 | INFO     | __main__:train_seq2seq_model:69 - Epoch:27, dev loss:0.0146\n",
      "2022-09-16 22:23:22.627 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :0/1167 loss:0.1264\n",
      "2022-09-16 22:23:24.487 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :100/1167 loss:0.0247\n",
      "2022-09-16 22:23:26.361 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :200/1167 loss:0.0052\n",
      "2022-09-16 22:23:28.306 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :300/1167 loss:0.0893\n",
      "2022-09-16 22:23:30.225 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :400/1167 loss:0.0380\n",
      "2022-09-16 22:23:32.128 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :500/1167 loss:0.0096\n",
      "2022-09-16 22:23:34.103 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :600/1167 loss:0.0078\n",
      "2022-09-16 22:23:35.976 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :700/1167 loss:0.0039\n",
      "2022-09-16 22:23:37.862 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :800/1167 loss:0.0054\n",
      "2022-09-16 22:23:39.746 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :900/1167 loss:0.0024\n",
      "2022-09-16 22:23:41.628 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :1000/1167 loss:0.0146\n",
      "2022-09-16 22:23:43.539 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :1100/1167 loss:0.0048\n",
      "2022-09-16 22:23:44.792 | INFO     | __main__:train_seq2seq_model:65 - Epoch :28/100, training loss:0.0130\n",
      "2022-09-16 22:23:45.541 | INFO     | __main__:train_seq2seq_model:69 - Epoch:28, dev loss:0.0131\n",
      "2022-09-16 22:23:45.552 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :0/1167 loss:0.1326\n",
      "2022-09-16 22:23:47.409 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :100/1167 loss:0.0248\n",
      "2022-09-16 22:23:49.284 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :200/1167 loss:0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 22:23:51.233 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :300/1167 loss:0.0907\n",
      "2022-09-16 22:23:53.149 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :400/1167 loss:0.0399\n",
      "2022-09-16 22:23:55.052 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :500/1167 loss:0.0106\n",
      "2022-09-16 22:23:57.028 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :600/1167 loss:0.0024\n",
      "2022-09-16 22:23:58.894 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :700/1167 loss:0.0098\n",
      "2022-09-16 22:24:00.781 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :800/1167 loss:0.0082\n",
      "2022-09-16 22:24:02.666 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :900/1167 loss:0.0066\n",
      "2022-09-16 22:24:04.549 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :1000/1167 loss:0.0159\n",
      "2022-09-16 22:24:06.463 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :1100/1167 loss:0.0099\n",
      "2022-09-16 22:24:07.713 | INFO     | __main__:train_seq2seq_model:65 - Epoch :29/100, training loss:0.0126\n",
      "2022-09-16 22:24:08.460 | INFO     | __main__:train_seq2seq_model:69 - Epoch:29, dev loss:0.0135\n",
      "2022-09-16 22:24:08.470 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :0/1167 loss:0.1159\n",
      "2022-09-16 22:24:10.330 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :100/1167 loss:0.0162\n",
      "2022-09-16 22:24:12.205 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :200/1167 loss:0.0118\n",
      "2022-09-16 22:24:14.152 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :300/1167 loss:0.0851\n",
      "2022-09-16 22:24:16.066 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :400/1167 loss:0.0350\n",
      "2022-09-16 22:24:17.963 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :500/1167 loss:0.0098\n",
      "2022-09-16 22:24:19.943 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :600/1167 loss:0.0090\n",
      "2022-09-16 22:24:21.814 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :700/1167 loss:0.0042\n",
      "2022-09-16 22:24:23.701 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :800/1167 loss:0.0050\n",
      "2022-09-16 22:24:25.589 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :900/1167 loss:0.0111\n",
      "2022-09-16 22:24:27.474 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :1000/1167 loss:0.0105\n",
      "2022-09-16 22:24:29.391 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :1100/1167 loss:0.0060\n",
      "2022-09-16 22:24:30.643 | INFO     | __main__:train_seq2seq_model:65 - Epoch :30/100, training loss:0.0134\n",
      "2022-09-16 22:24:31.389 | INFO     | __main__:train_seq2seq_model:69 - Epoch:30, dev loss:0.0130\n",
      "2022-09-16 22:24:31.400 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :0/1167 loss:0.1235\n",
      "2022-09-16 22:24:33.254 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :100/1167 loss:0.0218\n",
      "2022-09-16 22:24:35.130 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :200/1167 loss:0.0071\n",
      "2022-09-16 22:24:37.076 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :300/1167 loss:0.0885\n",
      "2022-09-16 22:24:38.992 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :400/1167 loss:0.0340\n",
      "2022-09-16 22:24:40.890 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :500/1167 loss:0.0096\n",
      "2022-09-16 22:24:42.867 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :600/1167 loss:0.0056\n",
      "2022-09-16 22:24:44.738 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :700/1167 loss:0.0076\n",
      "2022-09-16 22:24:46.621 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :800/1167 loss:0.0052\n",
      "2022-09-16 22:24:48.504 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :900/1167 loss:0.0051\n",
      "2022-09-16 22:24:50.389 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :1000/1167 loss:0.0125\n",
      "2022-09-16 22:24:52.301 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :1100/1167 loss:0.0085\n",
      "2022-09-16 22:24:53.549 | INFO     | __main__:train_seq2seq_model:65 - Epoch :31/100, training loss:0.0123\n",
      "2022-09-16 22:24:54.305 | INFO     | __main__:train_seq2seq_model:69 - Epoch:31, dev loss:0.0120\n",
      "2022-09-16 22:24:54.310 | INFO     | __main__:train_seq2seq_model:77 - Epoch:31, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-16 22:24:54.321 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :0/1167 loss:0.1170\n",
      "2022-09-16 22:24:56.181 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :100/1167 loss:0.0191\n",
      "2022-09-16 22:24:58.056 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :200/1167 loss:0.0047\n",
      "2022-09-16 22:25:00.002 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :300/1167 loss:0.0942\n",
      "2022-09-16 22:25:01.914 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :400/1167 loss:0.0332\n",
      "2022-09-16 22:25:03.810 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :500/1167 loss:0.0115\n",
      "2022-09-16 22:25:05.788 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :600/1167 loss:0.0041\n",
      "2022-09-16 22:25:07.657 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :700/1167 loss:0.0044\n",
      "2022-09-16 22:25:09.542 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :800/1167 loss:0.0101\n",
      "2022-09-16 22:25:11.427 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :900/1167 loss:0.0025\n",
      "2022-09-16 22:25:13.309 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :1000/1167 loss:0.0188\n",
      "2022-09-16 22:25:15.223 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :1100/1167 loss:0.0092\n",
      "2022-09-16 22:25:16.474 | INFO     | __main__:train_seq2seq_model:65 - Epoch :32/100, training loss:0.0126\n",
      "2022-09-16 22:25:17.221 | INFO     | __main__:train_seq2seq_model:69 - Epoch:32, dev loss:0.0130\n",
      "2022-09-16 22:25:17.231 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :0/1167 loss:0.1113\n",
      "2022-09-16 22:25:19.087 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :100/1167 loss:0.0147\n",
      "2022-09-16 22:25:20.959 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :200/1167 loss:0.0068\n",
      "2022-09-16 22:25:22.905 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :300/1167 loss:0.0956\n",
      "2022-09-16 22:25:24.823 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :400/1167 loss:0.0403\n",
      "2022-09-16 22:25:26.720 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :500/1167 loss:0.0085\n",
      "2022-09-16 22:25:28.698 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :600/1167 loss:0.0070\n",
      "2022-09-16 22:25:30.572 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :700/1167 loss:0.0072\n",
      "2022-09-16 22:25:32.459 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :800/1167 loss:0.0107\n",
      "2022-09-16 22:25:34.342 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :900/1167 loss:0.0039\n",
      "2022-09-16 22:25:36.220 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :1000/1167 loss:0.0136\n",
      "2022-09-16 22:25:38.141 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :1100/1167 loss:0.0028\n",
      "2022-09-16 22:25:39.393 | INFO     | __main__:train_seq2seq_model:65 - Epoch :33/100, training loss:0.0127\n",
      "2022-09-16 22:25:40.146 | INFO     | __main__:train_seq2seq_model:69 - Epoch:33, dev loss:0.0129\n",
      "2022-09-16 22:25:40.156 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :0/1167 loss:0.1232\n",
      "2022-09-16 22:25:42.013 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :100/1167 loss:0.0154\n",
      "2022-09-16 22:25:43.888 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :200/1167 loss:0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 22:25:45.841 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :300/1167 loss:0.0765\n",
      "2022-09-16 22:25:47.753 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :400/1167 loss:0.0414\n",
      "2022-09-16 22:25:49.655 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :500/1167 loss:0.0091\n",
      "2022-09-16 22:25:51.634 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :600/1167 loss:0.0082\n",
      "2022-09-16 22:25:53.501 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :700/1167 loss:0.0044\n",
      "2022-09-16 22:25:55.384 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :800/1167 loss:0.0060\n",
      "2022-09-16 22:25:57.266 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :900/1167 loss:0.0052\n",
      "2022-09-16 22:25:59.147 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :1000/1167 loss:0.0193\n",
      "2022-09-16 22:26:01.064 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :1100/1167 loss:0.0030\n",
      "2022-09-16 22:26:02.315 | INFO     | __main__:train_seq2seq_model:65 - Epoch :34/100, training loss:0.0122\n",
      "2022-09-16 22:26:03.066 | INFO     | __main__:train_seq2seq_model:69 - Epoch:34, dev loss:0.0131\n",
      "2022-09-16 22:26:03.077 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :0/1167 loss:0.1111\n",
      "2022-09-16 22:26:04.938 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :100/1167 loss:0.0164\n",
      "2022-09-16 22:26:06.811 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :200/1167 loss:0.0037\n",
      "2022-09-16 22:26:08.759 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :300/1167 loss:0.0901\n",
      "2022-09-16 22:26:10.675 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :400/1167 loss:0.0648\n",
      "2022-09-16 22:26:12.576 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :500/1167 loss:0.0096\n",
      "2022-09-16 22:26:14.555 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :600/1167 loss:0.0080\n",
      "2022-09-16 22:26:16.425 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :700/1167 loss:0.0080\n",
      "2022-09-16 22:26:18.309 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :800/1167 loss:0.0102\n",
      "2022-09-16 22:26:20.195 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :900/1167 loss:0.0077\n",
      "2022-09-16 22:26:22.079 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :1000/1167 loss:0.0099\n",
      "2022-09-16 22:26:23.990 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :1100/1167 loss:0.0031\n",
      "2022-09-16 22:26:25.242 | INFO     | __main__:train_seq2seq_model:65 - Epoch :35/100, training loss:0.0133\n",
      "2022-09-16 22:26:25.994 | INFO     | __main__:train_seq2seq_model:69 - Epoch:35, dev loss:0.0134\n",
      "2022-09-16 22:26:26.004 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :0/1167 loss:0.1054\n",
      "2022-09-16 22:26:27.860 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :100/1167 loss:0.0194\n",
      "2022-09-16 22:26:29.732 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :200/1167 loss:0.0113\n",
      "2022-09-16 22:26:31.680 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :300/1167 loss:0.0804\n",
      "2022-09-16 22:26:33.592 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :400/1167 loss:0.0413\n",
      "2022-09-16 22:26:35.494 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :500/1167 loss:0.0098\n",
      "2022-09-16 22:26:37.470 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :600/1167 loss:0.0069\n",
      "2022-09-16 22:26:39.339 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :700/1167 loss:0.0041\n",
      "2022-09-16 22:26:41.223 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :800/1167 loss:0.0053\n",
      "2022-09-16 22:26:43.105 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :900/1167 loss:0.0052\n",
      "2022-09-16 22:26:44.988 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :1000/1167 loss:0.0151\n",
      "2022-09-16 22:26:46.902 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :1100/1167 loss:0.0110\n",
      "2022-09-16 22:26:48.150 | INFO     | __main__:train_seq2seq_model:65 - Epoch :36/100, training loss:0.0122\n",
      "2022-09-16 22:26:48.897 | INFO     | __main__:train_seq2seq_model:69 - Epoch:36, dev loss:0.0136\n",
      "2022-09-16 22:26:48.908 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :0/1167 loss:0.1068\n",
      "2022-09-16 22:26:50.769 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :100/1167 loss:0.0189\n",
      "2022-09-16 22:26:52.640 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :200/1167 loss:0.0040\n",
      "2022-09-16 22:26:54.594 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :300/1167 loss:0.0887\n",
      "2022-09-16 22:26:56.506 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :400/1167 loss:0.0458\n",
      "2022-09-16 22:26:58.403 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :500/1167 loss:0.0192\n",
      "2022-09-16 22:27:00.382 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :600/1167 loss:0.0023\n",
      "2022-09-16 22:27:02.253 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :700/1167 loss:0.0046\n",
      "2022-09-16 22:27:04.140 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :800/1167 loss:0.0134\n",
      "2022-09-16 22:27:06.026 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :900/1167 loss:0.0144\n",
      "2022-09-16 22:27:07.905 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :1000/1167 loss:0.0199\n",
      "2022-09-16 22:27:09.819 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :1100/1167 loss:0.0050\n",
      "2022-09-16 22:27:11.069 | INFO     | __main__:train_seq2seq_model:65 - Epoch :37/100, training loss:0.0136\n",
      "2022-09-16 22:27:11.826 | INFO     | __main__:train_seq2seq_model:69 - Epoch:37, dev loss:0.0132\n",
      "2022-09-16 22:27:11.836 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :0/1167 loss:0.1089\n",
      "2022-09-16 22:27:13.694 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :100/1167 loss:0.0210\n",
      "2022-09-16 22:27:15.568 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :200/1167 loss:0.0077\n",
      "2022-09-16 22:27:17.516 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :300/1167 loss:0.0911\n",
      "2022-09-16 22:27:19.434 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :400/1167 loss:0.0466\n",
      "2022-09-16 22:27:21.333 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :500/1167 loss:0.0096\n",
      "2022-09-16 22:27:23.310 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :600/1167 loss:0.0108\n",
      "2022-09-16 22:27:25.181 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :700/1167 loss:0.0059\n",
      "2022-09-16 22:27:27.066 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :800/1167 loss:0.0057\n",
      "2022-09-16 22:27:28.948 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :900/1167 loss:0.0017\n",
      "2022-09-16 22:27:30.830 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :1000/1167 loss:0.0105\n",
      "2022-09-16 22:27:32.745 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :1100/1167 loss:0.0049\n",
      "2022-09-16 22:27:33.996 | INFO     | __main__:train_seq2seq_model:65 - Epoch :38/100, training loss:0.0120\n",
      "2022-09-16 22:27:34.746 | INFO     | __main__:train_seq2seq_model:69 - Epoch:38, dev loss:0.0123\n",
      "2022-09-16 22:27:34.756 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :0/1167 loss:0.1079\n",
      "2022-09-16 22:27:36.617 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :100/1167 loss:0.0198\n",
      "2022-09-16 22:27:38.490 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :200/1167 loss:0.0022\n",
      "2022-09-16 22:27:40.437 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :300/1167 loss:0.0913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 22:27:42.348 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :400/1167 loss:0.0417\n",
      "2022-09-16 22:27:44.248 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :500/1167 loss:0.0084\n",
      "2022-09-16 22:27:46.227 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :600/1167 loss:0.0093\n",
      "2022-09-16 22:27:48.094 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :700/1167 loss:0.0075\n",
      "2022-09-16 22:27:49.980 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :800/1167 loss:0.0082\n",
      "2022-09-16 22:27:51.868 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :900/1167 loss:0.0021\n",
      "2022-09-16 22:27:53.750 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :1000/1167 loss:0.0101\n",
      "2022-09-16 22:27:55.667 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :1100/1167 loss:0.0126\n",
      "2022-09-16 22:27:56.918 | INFO     | __main__:train_seq2seq_model:65 - Epoch :39/100, training loss:0.0124\n",
      "2022-09-16 22:27:57.667 | INFO     | __main__:train_seq2seq_model:69 - Epoch:39, dev loss:0.0138\n",
      "2022-09-16 22:27:57.677 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :0/1167 loss:0.1109\n",
      "2022-09-16 22:27:59.535 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :100/1167 loss:0.0274\n",
      "2022-09-16 22:28:01.409 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :200/1167 loss:0.0048\n",
      "2022-09-16 22:28:03.358 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :300/1167 loss:0.0826\n",
      "2022-09-16 22:28:05.274 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :400/1167 loss:0.0349\n",
      "2022-09-16 22:28:07.175 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :500/1167 loss:0.0079\n",
      "2022-09-16 22:28:09.153 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :600/1167 loss:0.0061\n",
      "2022-09-16 22:28:11.021 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :700/1167 loss:0.0044\n",
      "2022-09-16 22:28:12.902 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :800/1167 loss:0.0053\n",
      "2022-09-16 22:28:14.785 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :900/1167 loss:0.0034\n",
      "2022-09-16 22:28:16.668 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :1000/1167 loss:0.0104\n",
      "2022-09-16 22:28:18.583 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :1100/1167 loss:0.0065\n",
      "2022-09-16 22:28:19.856 | INFO     | __main__:train_seq2seq_model:65 - Epoch :40/100, training loss:0.0124\n",
      "2022-09-16 22:28:20.603 | INFO     | __main__:train_seq2seq_model:69 - Epoch:40, dev loss:0.0133\n",
      "2022-09-16 22:28:20.613 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :0/1167 loss:0.1003\n",
      "2022-09-16 22:28:22.475 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :100/1167 loss:0.0266\n",
      "2022-09-16 22:28:24.351 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :200/1167 loss:0.0041\n",
      "2022-09-16 22:28:26.301 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :300/1167 loss:0.0911\n",
      "2022-09-16 22:28:28.213 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :400/1167 loss:0.0400\n",
      "2022-09-16 22:28:30.113 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :500/1167 loss:0.0078\n",
      "2022-09-16 22:28:32.088 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :600/1167 loss:0.0075\n",
      "2022-09-16 22:28:33.961 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :700/1167 loss:0.0037\n",
      "2022-09-16 22:28:35.847 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :800/1167 loss:0.0065\n",
      "2022-09-16 22:28:37.731 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :900/1167 loss:0.0025\n",
      "2022-09-16 22:28:39.613 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :1000/1167 loss:0.0128\n",
      "2022-09-16 22:28:41.524 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :1100/1167 loss:0.0149\n",
      "2022-09-16 22:28:42.773 | INFO     | __main__:train_seq2seq_model:65 - Epoch :41/100, training loss:0.0129\n",
      "2022-09-16 22:28:43.522 | INFO     | __main__:train_seq2seq_model:69 - Epoch:41, dev loss:0.0136\n",
      "2022-09-16 22:28:43.533 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :0/1167 loss:0.1087\n",
      "2022-09-16 22:28:45.392 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :100/1167 loss:0.0179\n",
      "2022-09-16 22:28:47.266 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :200/1167 loss:0.0020\n",
      "2022-09-16 22:28:49.212 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :300/1167 loss:0.0880\n",
      "2022-09-16 22:28:51.130 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :400/1167 loss:0.0319\n",
      "2022-09-16 22:28:53.028 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :500/1167 loss:0.0077\n",
      "2022-09-16 22:28:55.003 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :600/1167 loss:0.0064\n",
      "2022-09-16 22:28:56.873 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :700/1167 loss:0.0039\n",
      "2022-09-16 22:28:58.759 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :800/1167 loss:0.0054\n",
      "2022-09-16 22:29:00.646 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :900/1167 loss:0.0045\n",
      "2022-09-16 22:29:02.526 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :1000/1167 loss:0.0116\n",
      "2022-09-16 22:29:04.440 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :1100/1167 loss:0.0063\n",
      "2022-09-16 22:29:05.691 | INFO     | __main__:train_seq2seq_model:65 - Epoch :42/100, training loss:0.0122\n",
      "2022-09-16 22:29:06.440 | INFO     | __main__:train_seq2seq_model:69 - Epoch:42, dev loss:0.0140\n",
      "2022-09-16 22:29:06.450 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :0/1167 loss:0.1104\n",
      "2022-09-16 22:29:08.310 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :100/1167 loss:0.0214\n",
      "2022-09-16 22:29:10.181 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :200/1167 loss:0.0028\n",
      "2022-09-16 22:29:12.130 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :300/1167 loss:0.0726\n",
      "2022-09-16 22:29:14.042 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :400/1167 loss:0.0490\n",
      "2022-09-16 22:29:15.940 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :500/1167 loss:0.0077\n",
      "2022-09-16 22:29:17.914 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :600/1167 loss:0.0070\n",
      "2022-09-16 22:29:19.789 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :700/1167 loss:0.0094\n",
      "2022-09-16 22:29:21.675 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :800/1167 loss:0.0054\n",
      "2022-09-16 22:29:23.558 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :900/1167 loss:0.0023\n",
      "2022-09-16 22:29:25.440 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :1000/1167 loss:0.0098\n",
      "2022-09-16 22:29:27.356 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :1100/1167 loss:0.0033\n",
      "2022-09-16 22:29:28.608 | INFO     | __main__:train_seq2seq_model:65 - Epoch :43/100, training loss:0.0124\n",
      "2022-09-16 22:29:29.353 | INFO     | __main__:train_seq2seq_model:69 - Epoch:43, dev loss:0.0152\n",
      "2022-09-16 22:29:29.364 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :0/1167 loss:0.0929\n",
      "2022-09-16 22:29:31.223 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :100/1167 loss:0.0204\n",
      "2022-09-16 22:29:33.098 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :200/1167 loss:0.0039\n",
      "2022-09-16 22:29:35.051 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :300/1167 loss:0.0753\n",
      "2022-09-16 22:29:36.966 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :400/1167 loss:0.0381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 22:29:38.867 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :500/1167 loss:0.0078\n",
      "2022-09-16 22:29:40.846 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :600/1167 loss:0.0037\n",
      "2022-09-16 22:29:42.718 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :700/1167 loss:0.0058\n",
      "2022-09-16 22:29:44.603 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :800/1167 loss:0.0067\n",
      "2022-09-16 22:29:46.488 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :900/1167 loss:0.0022\n",
      "2022-09-16 22:29:48.369 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :1000/1167 loss:0.0099\n",
      "2022-09-16 22:29:50.287 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :1100/1167 loss:0.0081\n",
      "2022-09-16 22:29:51.537 | INFO     | __main__:train_seq2seq_model:65 - Epoch :44/100, training loss:0.0124\n",
      "2022-09-16 22:29:52.286 | INFO     | __main__:train_seq2seq_model:69 - Epoch:44, dev loss:0.0135\n",
      "2022-09-16 22:29:52.296 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :0/1167 loss:0.0914\n",
      "2022-09-16 22:29:54.154 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :100/1167 loss:0.0181\n",
      "2022-09-16 22:29:56.032 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :200/1167 loss:0.0059\n",
      "2022-09-16 22:29:57.978 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :300/1167 loss:0.0714\n",
      "2022-09-16 22:29:59.899 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :400/1167 loss:0.0354\n",
      "2022-09-16 22:30:01.803 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :500/1167 loss:0.0081\n",
      "2022-09-16 22:30:03.785 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :600/1167 loss:0.0171\n",
      "2022-09-16 22:30:05.658 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :700/1167 loss:0.0033\n",
      "2022-09-16 22:30:07.543 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :800/1167 loss:0.0045\n",
      "2022-09-16 22:30:09.425 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :900/1167 loss:0.0025\n",
      "2022-09-16 22:30:11.305 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :1000/1167 loss:0.0162\n",
      "2022-09-16 22:30:13.218 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :1100/1167 loss:0.0028\n",
      "2022-09-16 22:30:14.466 | INFO     | __main__:train_seq2seq_model:65 - Epoch :45/100, training loss:0.0118\n",
      "2022-09-16 22:30:15.216 | INFO     | __main__:train_seq2seq_model:69 - Epoch:45, dev loss:0.0133\n",
      "2022-09-16 22:30:15.226 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :0/1167 loss:0.0926\n",
      "2022-09-16 22:30:17.087 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :100/1167 loss:0.0157\n",
      "2022-09-16 22:30:18.960 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :200/1167 loss:0.0057\n",
      "2022-09-16 22:30:20.911 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :300/1167 loss:0.0769\n",
      "2022-09-16 22:30:22.823 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :400/1167 loss:0.0396\n",
      "2022-09-16 22:30:24.722 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :500/1167 loss:0.0069\n",
      "2022-09-16 22:30:26.700 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :600/1167 loss:0.0031\n",
      "2022-09-16 22:30:28.571 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :700/1167 loss:0.0050\n",
      "2022-09-16 22:30:30.457 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :800/1167 loss:0.0151\n",
      "2022-09-16 22:30:32.340 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :900/1167 loss:0.0058\n",
      "2022-09-16 22:30:34.224 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :1000/1167 loss:0.0186\n",
      "2022-09-16 22:30:36.143 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :1100/1167 loss:0.0105\n",
      "2022-09-16 22:30:37.396 | INFO     | __main__:train_seq2seq_model:65 - Epoch :46/100, training loss:0.0118\n",
      "2022-09-16 22:30:38.142 | INFO     | __main__:train_seq2seq_model:69 - Epoch:46, dev loss:0.0133\n",
      "2022-09-16 22:30:38.152 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :0/1167 loss:0.0829\n",
      "2022-09-16 22:30:40.013 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :100/1167 loss:0.0174\n",
      "2022-09-16 22:30:41.888 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :200/1167 loss:0.0020\n",
      "2022-09-16 22:30:43.834 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :300/1167 loss:0.0733\n",
      "2022-09-16 22:30:45.748 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :400/1167 loss:0.0346\n",
      "2022-09-16 22:30:47.647 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :500/1167 loss:0.0076\n",
      "2022-09-16 22:30:49.623 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :600/1167 loss:0.0053\n",
      "2022-09-16 22:30:51.492 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :700/1167 loss:0.0067\n",
      "2022-09-16 22:30:53.379 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :800/1167 loss:0.0046\n",
      "2022-09-16 22:30:55.262 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :900/1167 loss:0.0020\n",
      "2022-09-16 22:30:57.147 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :1000/1167 loss:0.0095\n",
      "2022-09-16 22:30:59.058 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :1100/1167 loss:0.0030\n",
      "2022-09-16 22:31:00.309 | INFO     | __main__:train_seq2seq_model:65 - Epoch :47/100, training loss:0.0118\n",
      "2022-09-16 22:31:01.055 | INFO     | __main__:train_seq2seq_model:69 - Epoch:47, dev loss:0.0129\n",
      "2022-09-16 22:31:01.066 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :0/1167 loss:0.1016\n",
      "2022-09-16 22:31:02.925 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :100/1167 loss:0.0168\n",
      "2022-09-16 22:31:04.799 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :200/1167 loss:0.0019\n",
      "2022-09-16 22:31:06.745 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :300/1167 loss:0.0897\n",
      "2022-09-16 22:31:08.654 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :400/1167 loss:0.0415\n",
      "2022-09-16 22:31:10.555 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :500/1167 loss:0.0066\n",
      "2022-09-16 22:31:12.529 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :600/1167 loss:0.0060\n",
      "2022-09-16 22:31:14.397 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :700/1167 loss:0.0039\n",
      "2022-09-16 22:31:16.282 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :800/1167 loss:0.0051\n",
      "2022-09-16 22:31:18.169 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :900/1167 loss:0.0021\n",
      "2022-09-16 22:31:20.051 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :1000/1167 loss:0.0112\n",
      "2022-09-16 22:31:21.966 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :1100/1167 loss:0.0026\n",
      "2022-09-16 22:31:23.217 | INFO     | __main__:train_seq2seq_model:65 - Epoch :48/100, training loss:0.0123\n",
      "2022-09-16 22:31:23.964 | INFO     | __main__:train_seq2seq_model:69 - Epoch:48, dev loss:0.0141\n",
      "2022-09-16 22:31:23.974 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :0/1167 loss:0.0925\n",
      "2022-09-16 22:31:25.837 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :100/1167 loss:0.0200\n",
      "2022-09-16 22:31:27.712 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :200/1167 loss:0.0121\n",
      "2022-09-16 22:31:29.659 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :300/1167 loss:0.0729\n",
      "2022-09-16 22:31:31.574 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :400/1167 loss:0.0324\n",
      "2022-09-16 22:31:33.472 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :500/1167 loss:0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 22:31:35.451 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :600/1167 loss:0.0067\n",
      "2022-09-16 22:31:37.318 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :700/1167 loss:0.0040\n",
      "2022-09-16 22:31:39.202 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :800/1167 loss:0.0152\n",
      "2022-09-16 22:31:41.088 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :900/1167 loss:0.0021\n",
      "2022-09-16 22:31:42.973 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :1000/1167 loss:0.0161\n",
      "2022-09-16 22:31:44.885 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :1100/1167 loss:0.0044\n",
      "2022-09-16 22:31:46.138 | INFO     | __main__:train_seq2seq_model:65 - Epoch :49/100, training loss:0.0123\n",
      "2022-09-16 22:31:46.884 | INFO     | __main__:train_seq2seq_model:69 - Epoch:49, dev loss:0.0132\n",
      "2022-09-16 22:31:46.894 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :0/1167 loss:0.0840\n",
      "2022-09-16 22:31:48.756 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :100/1167 loss:0.0148\n",
      "2022-09-16 22:31:50.629 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :200/1167 loss:0.0051\n",
      "2022-09-16 22:31:52.575 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :300/1167 loss:0.0803\n",
      "2022-09-16 22:31:54.491 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :400/1167 loss:0.0359\n",
      "2022-09-16 22:31:56.391 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :500/1167 loss:0.0054\n",
      "2022-09-16 22:31:58.370 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :600/1167 loss:0.0027\n",
      "2022-09-16 22:32:00.241 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :700/1167 loss:0.0033\n",
      "2022-09-16 22:32:02.127 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :800/1167 loss:0.0160\n",
      "2022-09-16 22:32:04.015 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :900/1167 loss:0.0024\n",
      "2022-09-16 22:32:05.898 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :1000/1167 loss:0.0098\n",
      "2022-09-16 22:32:07.808 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :1100/1167 loss:0.0030\n",
      "2022-09-16 22:32:09.056 | INFO     | __main__:train_seq2seq_model:65 - Epoch :50/100, training loss:0.0121\n",
      "2022-09-16 22:32:09.804 | INFO     | __main__:train_seq2seq_model:69 - Epoch:50, dev loss:0.0150\n",
      "2022-09-16 22:32:09.814 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :0/1167 loss:0.0957\n",
      "2022-09-16 22:32:11.675 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :100/1167 loss:0.0228\n",
      "2022-09-16 22:32:13.548 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :200/1167 loss:0.0087\n",
      "2022-09-16 22:32:15.501 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :300/1167 loss:0.0785\n",
      "2022-09-16 22:32:17.417 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :400/1167 loss:0.0320\n",
      "2022-09-16 22:32:19.317 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :500/1167 loss:0.0063\n",
      "2022-09-16 22:32:21.294 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :600/1167 loss:0.0021\n",
      "2022-09-16 22:32:23.167 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :700/1167 loss:0.0094\n",
      "2022-09-16 22:32:25.054 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :800/1167 loss:0.0052\n",
      "2022-09-16 22:32:26.940 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :900/1167 loss:0.0023\n",
      "2022-09-16 22:32:28.820 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :1000/1167 loss:0.0132\n",
      "2022-09-16 22:32:30.736 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :1100/1167 loss:0.0088\n",
      "2022-09-16 22:32:31.987 | INFO     | __main__:train_seq2seq_model:65 - Epoch :51/100, training loss:0.0119\n",
      "2022-09-16 22:32:32.737 | INFO     | __main__:train_seq2seq_model:69 - Epoch:51, dev loss:0.0131\n",
      "2022-09-16 22:32:32.748 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :0/1167 loss:0.0826\n",
      "2022-09-16 22:32:34.605 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :100/1167 loss:0.0147\n",
      "2022-09-16 22:32:36.485 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :200/1167 loss:0.0020\n",
      "2022-09-16 22:32:38.430 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :300/1167 loss:0.0792\n",
      "2022-09-16 22:32:40.343 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :400/1167 loss:0.0379\n",
      "2022-09-16 22:32:42.240 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :500/1167 loss:0.0057\n",
      "2022-09-16 22:32:44.217 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :600/1167 loss:0.0049\n",
      "2022-09-16 22:32:46.086 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :700/1167 loss:0.0077\n",
      "2022-09-16 22:32:47.974 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :800/1167 loss:0.0050\n",
      "2022-09-16 22:32:49.862 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :900/1167 loss:0.0020\n",
      "2022-09-16 22:32:51.743 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :1000/1167 loss:0.0099\n",
      "2022-09-16 22:32:53.654 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :1100/1167 loss:0.0058\n",
      "2022-09-16 22:32:54.907 | INFO     | __main__:train_seq2seq_model:65 - Epoch :52/100, training loss:0.0115\n",
      "2022-09-16 22:32:55.654 | INFO     | __main__:train_seq2seq_model:69 - Epoch:52, dev loss:0.0137\n",
      "2022-09-16 22:32:55.665 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :0/1167 loss:0.0783\n",
      "2022-09-16 22:32:57.520 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :100/1167 loss:0.0182\n",
      "2022-09-16 22:32:59.392 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :200/1167 loss:0.0077\n",
      "2022-09-16 22:33:01.340 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :300/1167 loss:0.0657\n",
      "2022-09-16 22:33:03.254 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :400/1167 loss:0.0337\n",
      "2022-09-16 22:33:05.153 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :500/1167 loss:0.0078\n",
      "2022-09-16 22:33:07.127 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :600/1167 loss:0.0146\n",
      "2022-09-16 22:33:08.996 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :700/1167 loss:0.0096\n",
      "2022-09-16 22:33:10.885 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :800/1167 loss:0.0083\n",
      "2022-09-16 22:33:12.771 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :900/1167 loss:0.0016\n",
      "2022-09-16 22:33:14.655 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :1000/1167 loss:0.0097\n",
      "2022-09-16 22:33:16.567 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :1100/1167 loss:0.0026\n",
      "2022-09-16 22:33:17.817 | INFO     | __main__:train_seq2seq_model:65 - Epoch :53/100, training loss:0.0117\n",
      "2022-09-16 22:33:18.567 | INFO     | __main__:train_seq2seq_model:69 - Epoch:53, dev loss:0.0136\n",
      "2022-09-16 22:33:18.577 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :0/1167 loss:0.0751\n",
      "2022-09-16 22:33:20.451 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :100/1167 loss:0.0232\n",
      "2022-09-16 22:33:22.326 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :200/1167 loss:0.0051\n",
      "2022-09-16 22:33:24.272 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :300/1167 loss:0.0659\n",
      "2022-09-16 22:33:26.184 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :400/1167 loss:0.0392\n",
      "2022-09-16 22:33:28.087 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :500/1167 loss:0.0057\n",
      "2022-09-16 22:33:30.065 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :600/1167 loss:0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 22:33:31.933 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :700/1167 loss:0.0039\n",
      "2022-09-16 22:33:33.821 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :800/1167 loss:0.0106\n",
      "2022-09-16 22:33:35.708 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :900/1167 loss:0.0047\n",
      "2022-09-16 22:33:37.590 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :1000/1167 loss:0.0134\n",
      "2022-09-16 22:33:39.502 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :1100/1167 loss:0.0105\n",
      "2022-09-16 22:33:40.750 | INFO     | __main__:train_seq2seq_model:65 - Epoch :54/100, training loss:0.0115\n",
      "2022-09-16 22:33:41.498 | INFO     | __main__:train_seq2seq_model:69 - Epoch:54, dev loss:0.0130\n",
      "2022-09-16 22:33:41.508 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :0/1167 loss:0.0788\n",
      "2022-09-16 22:33:43.366 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :100/1167 loss:0.0175\n",
      "2022-09-16 22:33:45.237 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :200/1167 loss:0.0017\n",
      "2022-09-16 22:33:47.185 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :300/1167 loss:0.0644\n",
      "2022-09-16 22:33:49.098 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :400/1167 loss:0.0399\n",
      "2022-09-16 22:33:50.999 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :500/1167 loss:0.0065\n",
      "2022-09-16 22:33:52.974 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :600/1167 loss:0.0104\n",
      "2022-09-16 22:33:54.846 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :700/1167 loss:0.0047\n",
      "2022-09-16 22:33:56.733 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :800/1167 loss:0.0047\n",
      "2022-09-16 22:33:58.618 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :900/1167 loss:0.0015\n",
      "2022-09-16 22:34:00.500 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :1000/1167 loss:0.0101\n",
      "2022-09-16 22:34:02.415 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :1100/1167 loss:0.0102\n",
      "2022-09-16 22:34:03.665 | INFO     | __main__:train_seq2seq_model:65 - Epoch :55/100, training loss:0.0114\n",
      "2022-09-16 22:34:04.416 | INFO     | __main__:train_seq2seq_model:69 - Epoch:55, dev loss:0.0139\n",
      "2022-09-16 22:34:04.425 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :0/1167 loss:0.0773\n",
      "2022-09-16 22:34:06.283 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :100/1167 loss:0.0133\n",
      "2022-09-16 22:34:08.156 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :200/1167 loss:0.0053\n",
      "2022-09-16 22:34:10.102 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :300/1167 loss:0.0635\n",
      "2022-09-16 22:34:12.016 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :400/1167 loss:0.0345\n",
      "2022-09-16 22:34:13.914 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :500/1167 loss:0.0052\n",
      "2022-09-16 22:34:15.891 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :600/1167 loss:0.0085\n",
      "2022-09-16 22:34:17.760 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :700/1167 loss:0.0043\n",
      "2022-09-16 22:34:19.647 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :800/1167 loss:0.0046\n",
      "2022-09-16 22:34:21.532 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :900/1167 loss:0.0052\n",
      "2022-09-16 22:34:23.415 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :1000/1167 loss:0.0100\n",
      "2022-09-16 22:34:25.329 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :1100/1167 loss:0.0055\n",
      "2022-09-16 22:34:26.580 | INFO     | __main__:train_seq2seq_model:65 - Epoch :56/100, training loss:0.0118\n",
      "2022-09-16 22:34:27.349 | INFO     | __main__:train_seq2seq_model:69 - Epoch:56, dev loss:0.0148\n",
      "2022-09-16 22:34:27.359 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :0/1167 loss:0.0693\n",
      "2022-09-16 22:34:29.246 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :100/1167 loss:0.0234\n",
      "2022-09-16 22:34:31.120 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :200/1167 loss:0.0046\n",
      "2022-09-16 22:34:33.065 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :300/1167 loss:0.0749\n",
      "2022-09-16 22:34:34.975 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :400/1167 loss:0.0343\n",
      "2022-09-16 22:34:36.880 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :500/1167 loss:0.0068\n",
      "2022-09-16 22:34:38.853 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :600/1167 loss:0.0087\n",
      "2022-09-16 22:34:40.721 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :700/1167 loss:0.0070\n",
      "2022-09-16 22:34:42.610 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :800/1167 loss:0.0043\n",
      "2022-09-16 22:34:44.495 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :900/1167 loss:0.0016\n",
      "2022-09-16 22:34:46.376 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :1000/1167 loss:0.0104\n",
      "2022-09-16 22:34:48.287 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :1100/1167 loss:0.0064\n",
      "2022-09-16 22:34:49.535 | INFO     | __main__:train_seq2seq_model:65 - Epoch :57/100, training loss:0.0118\n",
      "2022-09-16 22:34:50.289 | INFO     | __main__:train_seq2seq_model:69 - Epoch:57, dev loss:0.0133\n",
      "2022-09-16 22:34:50.299 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :0/1167 loss:0.0712\n",
      "2022-09-16 22:34:52.162 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :100/1167 loss:0.0188\n",
      "2022-09-16 22:34:54.035 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :200/1167 loss:0.0020\n",
      "2022-09-16 22:34:55.983 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :300/1167 loss:0.0787\n",
      "2022-09-16 22:34:57.900 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :400/1167 loss:0.0436\n",
      "2022-09-16 22:34:59.799 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :500/1167 loss:0.0229\n",
      "2022-09-16 22:35:01.777 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :600/1167 loss:0.0047\n",
      "2022-09-16 22:35:03.644 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :700/1167 loss:0.0059\n",
      "2022-09-16 22:35:05.529 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :800/1167 loss:0.0048\n",
      "2022-09-16 22:35:07.414 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :900/1167 loss:0.0015\n",
      "2022-09-16 22:35:09.295 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :1000/1167 loss:0.0121\n",
      "2022-09-16 22:35:11.210 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :1100/1167 loss:0.0046\n",
      "2022-09-16 22:35:12.458 | INFO     | __main__:train_seq2seq_model:65 - Epoch :58/100, training loss:0.0118\n",
      "2022-09-16 22:35:13.206 | INFO     | __main__:train_seq2seq_model:69 - Epoch:58, dev loss:0.0135\n",
      "2022-09-16 22:35:13.216 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :0/1167 loss:0.0810\n",
      "2022-09-16 22:35:15.076 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :100/1167 loss:0.0212\n",
      "2022-09-16 22:35:16.951 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :200/1167 loss:0.0021\n",
      "2022-09-16 22:35:18.901 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :300/1167 loss:0.0613\n",
      "2022-09-16 22:35:20.816 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :400/1167 loss:0.0393\n",
      "2022-09-16 22:35:22.718 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :500/1167 loss:0.0144\n",
      "2022-09-16 22:35:24.694 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :600/1167 loss:0.0069\n",
      "2022-09-16 22:35:26.564 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :700/1167 loss:0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 22:35:28.451 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :800/1167 loss:0.0047\n",
      "2022-09-16 22:35:30.334 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :900/1167 loss:0.0043\n",
      "2022-09-16 22:35:32.215 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :1000/1167 loss:0.0102\n",
      "2022-09-16 22:35:34.132 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :1100/1167 loss:0.0031\n",
      "2022-09-16 22:35:35.386 | INFO     | __main__:train_seq2seq_model:65 - Epoch :59/100, training loss:0.0116\n",
      "2022-09-16 22:35:36.132 | INFO     | __main__:train_seq2seq_model:69 - Epoch:59, dev loss:0.0144\n",
      "2022-09-16 22:35:36.142 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :0/1167 loss:0.0712\n",
      "2022-09-16 22:35:38.008 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :100/1167 loss:0.0197\n",
      "2022-09-16 22:35:39.884 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :200/1167 loss:0.0021\n",
      "2022-09-16 22:35:41.832 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :300/1167 loss:0.0680\n",
      "2022-09-16 22:35:43.746 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :400/1167 loss:0.0314\n",
      "2022-09-16 22:35:45.644 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :500/1167 loss:0.0051\n",
      "2022-09-16 22:35:47.621 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :600/1167 loss:0.0048\n",
      "2022-09-16 22:35:49.492 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :700/1167 loss:0.0042\n",
      "2022-09-16 22:35:51.378 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :800/1167 loss:0.0083\n",
      "2022-09-16 22:35:53.261 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :900/1167 loss:0.0016\n",
      "2022-09-16 22:35:55.142 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :1000/1167 loss:0.0116\n",
      "2022-09-16 22:35:57.055 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :1100/1167 loss:0.0109\n",
      "2022-09-16 22:35:58.309 | INFO     | __main__:train_seq2seq_model:65 - Epoch :60/100, training loss:0.0116\n",
      "2022-09-16 22:35:59.056 | INFO     | __main__:train_seq2seq_model:69 - Epoch:60, dev loss:0.0135\n",
      "2022-09-16 22:35:59.066 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :0/1167 loss:0.0583\n",
      "2022-09-16 22:36:00.924 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :100/1167 loss:0.0219\n",
      "2022-09-16 22:36:02.796 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :200/1167 loss:0.0050\n",
      "2022-09-16 22:36:04.746 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :300/1167 loss:0.0581\n",
      "2022-09-16 22:36:06.659 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :400/1167 loss:0.0398\n",
      "2022-09-16 22:36:08.559 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :500/1167 loss:0.0043\n",
      "2022-09-16 22:36:10.540 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :600/1167 loss:0.0073\n",
      "2022-09-16 22:36:12.416 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :700/1167 loss:0.0093\n",
      "2022-09-16 22:36:14.299 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :800/1167 loss:0.0048\n",
      "2022-09-16 22:36:16.184 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :900/1167 loss:0.0016\n",
      "2022-09-16 22:36:18.070 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :1000/1167 loss:0.0125\n",
      "2022-09-16 22:36:19.997 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :1100/1167 loss:0.0059\n",
      "2022-09-16 22:36:21.248 | INFO     | __main__:train_seq2seq_model:65 - Epoch :61/100, training loss:0.0115\n",
      "2022-09-16 22:36:21.996 | INFO     | __main__:train_seq2seq_model:69 - Epoch:61, dev loss:0.0140\n",
      "2022-09-16 22:36:22.006 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :0/1167 loss:0.0782\n",
      "2022-09-16 22:36:23.865 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :100/1167 loss:0.0146\n",
      "2022-09-16 22:36:25.740 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :200/1167 loss:0.0028\n",
      "2022-09-16 22:36:27.690 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :300/1167 loss:0.0646\n",
      "2022-09-16 22:36:29.602 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :400/1167 loss:0.0328\n",
      "2022-09-16 22:36:31.502 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :500/1167 loss:0.0042\n",
      "2022-09-16 22:36:33.477 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :600/1167 loss:0.0056\n",
      "2022-09-16 22:36:35.346 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :700/1167 loss:0.0040\n",
      "2022-09-16 22:36:37.233 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :800/1167 loss:0.0071\n",
      "2022-09-16 22:36:39.119 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :900/1167 loss:0.0045\n",
      "2022-09-16 22:36:41.004 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :1000/1167 loss:0.0097\n",
      "2022-09-16 22:36:42.918 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :1100/1167 loss:0.0141\n",
      "2022-09-16 22:36:44.167 | INFO     | __main__:train_seq2seq_model:65 - Epoch :62/100, training loss:0.0113\n",
      "2022-09-16 22:36:44.917 | INFO     | __main__:train_seq2seq_model:69 - Epoch:62, dev loss:0.0134\n",
      "2022-09-16 22:36:44.927 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :0/1167 loss:0.0599\n",
      "2022-09-16 22:36:46.787 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :100/1167 loss:0.0207\n",
      "2022-09-16 22:36:48.660 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :200/1167 loss:0.0072\n",
      "2022-09-16 22:36:50.609 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :300/1167 loss:0.0565\n",
      "2022-09-16 22:36:52.523 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :400/1167 loss:0.0330\n",
      "2022-09-16 22:36:54.421 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :500/1167 loss:0.0045\n",
      "2022-09-16 22:36:56.400 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :600/1167 loss:0.0103\n",
      "2022-09-16 22:36:58.270 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :700/1167 loss:0.0047\n",
      "2022-09-16 22:37:00.158 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :800/1167 loss:0.0050\n",
      "2022-09-16 22:37:02.044 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :900/1167 loss:0.0028\n",
      "2022-09-16 22:37:03.929 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :1000/1167 loss:0.0099\n",
      "2022-09-16 22:37:05.845 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :1100/1167 loss:0.0151\n",
      "2022-09-16 22:37:07.096 | INFO     | __main__:train_seq2seq_model:65 - Epoch :63/100, training loss:0.0116\n",
      "2022-09-16 22:37:07.843 | INFO     | __main__:train_seq2seq_model:69 - Epoch:63, dev loss:0.0138\n",
      "2022-09-16 22:37:07.854 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :0/1167 loss:0.0641\n",
      "2022-09-16 22:37:09.716 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :100/1167 loss:0.0190\n",
      "2022-09-16 22:37:11.588 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :200/1167 loss:0.0052\n",
      "2022-09-16 22:37:13.533 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :300/1167 loss:0.0631\n",
      "2022-09-16 22:37:15.446 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :400/1167 loss:0.0308\n",
      "2022-09-16 22:37:17.346 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :500/1167 loss:0.0060\n",
      "2022-09-16 22:37:19.323 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :600/1167 loss:0.0045\n",
      "2022-09-16 22:37:21.196 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :700/1167 loss:0.0039\n",
      "2022-09-16 22:37:23.084 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :800/1167 loss:0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 22:37:24.972 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :900/1167 loss:0.0018\n",
      "2022-09-16 22:37:26.859 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :1000/1167 loss:0.0141\n",
      "2022-09-16 22:37:28.776 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :1100/1167 loss:0.0082\n",
      "2022-09-16 22:37:30.028 | INFO     | __main__:train_seq2seq_model:65 - Epoch :64/100, training loss:0.0111\n",
      "2022-09-16 22:37:30.777 | INFO     | __main__:train_seq2seq_model:69 - Epoch:64, dev loss:0.0139\n",
      "2022-09-16 22:37:30.787 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :0/1167 loss:0.0629\n",
      "2022-09-16 22:37:32.678 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :100/1167 loss:0.0193\n",
      "2022-09-16 22:37:34.558 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :200/1167 loss:0.0036\n",
      "2022-09-16 22:37:36.507 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :300/1167 loss:0.0548\n",
      "2022-09-16 22:37:38.422 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :400/1167 loss:0.0384\n",
      "2022-09-16 22:37:40.321 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :500/1167 loss:0.0051\n",
      "2022-09-16 22:37:42.294 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :600/1167 loss:0.0075\n",
      "2022-09-16 22:37:44.167 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :700/1167 loss:0.0039\n",
      "2022-09-16 22:37:46.054 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :800/1167 loss:0.0198\n",
      "2022-09-16 22:37:47.936 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :900/1167 loss:0.0018\n",
      "2022-09-16 22:37:49.819 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :1000/1167 loss:0.0103\n",
      "2022-09-16 22:37:51.734 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :1100/1167 loss:0.0051\n",
      "2022-09-16 22:37:52.986 | INFO     | __main__:train_seq2seq_model:65 - Epoch :65/100, training loss:0.0109\n",
      "2022-09-16 22:37:53.732 | INFO     | __main__:train_seq2seq_model:69 - Epoch:65, dev loss:0.0136\n",
      "2022-09-16 22:37:53.742 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :0/1167 loss:0.0642\n",
      "2022-09-16 22:37:55.600 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :100/1167 loss:0.0163\n",
      "2022-09-16 22:37:57.476 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :200/1167 loss:0.0020\n",
      "2022-09-16 22:37:59.425 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :300/1167 loss:0.0527\n",
      "2022-09-16 22:38:01.337 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :400/1167 loss:0.0320\n",
      "2022-09-16 22:38:03.240 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :500/1167 loss:0.0056\n",
      "2022-09-16 22:38:05.216 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :600/1167 loss:0.0060\n",
      "2022-09-16 22:38:07.090 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :700/1167 loss:0.0061\n",
      "2022-09-16 22:38:08.974 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :800/1167 loss:0.0048\n",
      "2022-09-16 22:38:10.858 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :900/1167 loss:0.0019\n",
      "2022-09-16 22:38:12.740 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :1000/1167 loss:0.0096\n",
      "2022-09-16 22:38:14.655 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :1100/1167 loss:0.0056\n",
      "2022-09-16 22:38:15.904 | INFO     | __main__:train_seq2seq_model:65 - Epoch :66/100, training loss:0.0112\n",
      "2022-09-16 22:38:16.658 | INFO     | __main__:train_seq2seq_model:69 - Epoch:66, dev loss:0.0147\n",
      "2022-09-16 22:38:16.669 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :0/1167 loss:0.0676\n",
      "2022-09-16 22:38:18.531 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :100/1167 loss:0.0170\n",
      "2022-09-16 22:38:20.434 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :200/1167 loss:0.0019\n",
      "2022-09-16 22:38:22.387 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :300/1167 loss:0.0578\n",
      "2022-09-16 22:38:24.301 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :400/1167 loss:0.0344\n",
      "2022-09-16 22:38:26.203 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :500/1167 loss:0.0044\n",
      "2022-09-16 22:38:28.179 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :600/1167 loss:0.0042\n",
      "2022-09-16 22:38:30.051 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :700/1167 loss:0.0078\n",
      "2022-09-16 22:38:31.937 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :800/1167 loss:0.0096\n",
      "2022-09-16 22:38:33.821 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :900/1167 loss:0.0075\n",
      "2022-09-16 22:38:35.709 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :1000/1167 loss:0.0096\n",
      "2022-09-16 22:38:37.624 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :1100/1167 loss:0.0054\n",
      "2022-09-16 22:38:38.872 | INFO     | __main__:train_seq2seq_model:65 - Epoch :67/100, training loss:0.0117\n",
      "2022-09-16 22:38:39.621 | INFO     | __main__:train_seq2seq_model:69 - Epoch:67, dev loss:0.0139\n",
      "2022-09-16 22:38:39.631 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :0/1167 loss:0.0664\n",
      "2022-09-16 22:38:41.495 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :100/1167 loss:0.0198\n",
      "2022-09-16 22:38:43.369 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :200/1167 loss:0.0018\n",
      "2022-09-16 22:38:45.319 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :300/1167 loss:0.0712\n",
      "2022-09-16 22:38:47.232 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :400/1167 loss:0.0319\n",
      "2022-09-16 22:38:49.139 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :500/1167 loss:0.0047\n",
      "2022-09-16 22:38:51.116 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :600/1167 loss:0.0039\n",
      "2022-09-16 22:38:52.988 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :700/1167 loss:0.0036\n",
      "2022-09-16 22:38:54.876 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :800/1167 loss:0.0044\n",
      "2022-09-16 22:38:56.760 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :900/1167 loss:0.0020\n",
      "2022-09-16 22:38:58.646 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :1000/1167 loss:0.0120\n",
      "2022-09-16 22:39:00.562 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :1100/1167 loss:0.0047\n",
      "2022-09-16 22:39:01.812 | INFO     | __main__:train_seq2seq_model:65 - Epoch :68/100, training loss:0.0111\n",
      "2022-09-16 22:39:02.573 | INFO     | __main__:train_seq2seq_model:69 - Epoch:68, dev loss:0.0142\n",
      "2022-09-16 22:39:02.583 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :0/1167 loss:0.0655\n",
      "2022-09-16 22:39:04.446 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :100/1167 loss:0.0201\n",
      "2022-09-16 22:39:06.322 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :200/1167 loss:0.0083\n",
      "2022-09-16 22:39:08.271 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :300/1167 loss:0.0671\n",
      "2022-09-16 22:39:10.183 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :400/1167 loss:0.0323\n",
      "2022-09-16 22:39:12.082 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :500/1167 loss:0.0045\n",
      "2022-09-16 22:39:14.058 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :600/1167 loss:0.0090\n",
      "2022-09-16 22:39:15.929 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :700/1167 loss:0.0034\n",
      "2022-09-16 22:39:17.813 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :800/1167 loss:0.0049\n",
      "2022-09-16 22:39:19.703 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :900/1167 loss:0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 22:39:21.583 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :1000/1167 loss:0.0105\n",
      "2022-09-16 22:39:23.497 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :1100/1167 loss:0.0057\n",
      "2022-09-16 22:39:24.748 | INFO     | __main__:train_seq2seq_model:65 - Epoch :69/100, training loss:0.0108\n",
      "2022-09-16 22:39:25.502 | INFO     | __main__:train_seq2seq_model:69 - Epoch:69, dev loss:0.0138\n",
      "2022-09-16 22:39:25.512 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :0/1167 loss:0.0559\n",
      "2022-09-16 22:39:27.372 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :100/1167 loss:0.0224\n",
      "2022-09-16 22:39:29.244 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :200/1167 loss:0.0018\n",
      "2022-09-16 22:39:31.190 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :300/1167 loss:0.0647\n",
      "2022-09-16 22:39:33.102 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :400/1167 loss:0.0440\n",
      "2022-09-16 22:39:35.011 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :500/1167 loss:0.0040\n",
      "2022-09-16 22:39:36.988 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :600/1167 loss:0.0060\n",
      "2022-09-16 22:39:38.856 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :700/1167 loss:0.0093\n",
      "2022-09-16 22:39:40.742 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :800/1167 loss:0.0056\n",
      "2022-09-16 22:39:42.626 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :900/1167 loss:0.0021\n",
      "2022-09-16 22:39:44.510 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :1000/1167 loss:0.0118\n",
      "2022-09-16 22:39:46.420 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :1100/1167 loss:0.0059\n",
      "2022-09-16 22:39:47.671 | INFO     | __main__:train_seq2seq_model:65 - Epoch :70/100, training loss:0.0118\n",
      "2022-09-16 22:39:48.419 | INFO     | __main__:train_seq2seq_model:69 - Epoch:70, dev loss:0.0145\n",
      "2022-09-16 22:39:48.429 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :0/1167 loss:0.0646\n",
      "2022-09-16 22:39:50.292 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :100/1167 loss:0.0199\n",
      "2022-09-16 22:39:52.166 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :200/1167 loss:0.0024\n",
      "2022-09-16 22:39:54.114 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :300/1167 loss:0.0583\n",
      "2022-09-16 22:39:56.029 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :400/1167 loss:0.0364\n",
      "2022-09-16 22:39:57.930 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :500/1167 loss:0.0179\n",
      "2022-09-16 22:39:59.908 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :600/1167 loss:0.0097\n",
      "2022-09-16 22:40:01.780 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :700/1167 loss:0.0056\n",
      "2022-09-16 22:40:03.673 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :800/1167 loss:0.0045\n",
      "2022-09-16 22:40:05.561 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :900/1167 loss:0.0019\n",
      "2022-09-16 22:40:07.447 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :1000/1167 loss:0.0105\n",
      "2022-09-16 22:40:09.360 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :1100/1167 loss:0.0117\n",
      "2022-09-16 22:40:10.610 | INFO     | __main__:train_seq2seq_model:65 - Epoch :71/100, training loss:0.0114\n",
      "2022-09-16 22:40:11.359 | INFO     | __main__:train_seq2seq_model:69 - Epoch:71, dev loss:0.0136\n",
      "2022-09-16 22:40:11.369 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :0/1167 loss:0.0534\n",
      "2022-09-16 22:40:13.224 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :100/1167 loss:0.0228\n",
      "2022-09-16 22:40:15.097 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :200/1167 loss:0.0038\n",
      "2022-09-16 22:40:17.044 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :300/1167 loss:0.0527\n",
      "2022-09-16 22:40:18.957 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :400/1167 loss:0.0413\n",
      "2022-09-16 22:40:20.860 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :500/1167 loss:0.0415\n",
      "2022-09-16 22:40:22.834 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :600/1167 loss:0.0045\n",
      "2022-09-16 22:40:24.703 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :700/1167 loss:0.0039\n",
      "2022-09-16 22:40:26.588 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :800/1167 loss:0.0048\n",
      "2022-09-16 22:40:28.471 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :900/1167 loss:0.0050\n",
      "2022-09-16 22:40:30.354 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :1000/1167 loss:0.0104\n",
      "2022-09-16 22:40:32.269 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :1100/1167 loss:0.0089\n",
      "2022-09-16 22:40:33.517 | INFO     | __main__:train_seq2seq_model:65 - Epoch :72/100, training loss:0.0107\n",
      "2022-09-16 22:40:34.276 | INFO     | __main__:train_seq2seq_model:69 - Epoch:72, dev loss:0.0143\n",
      "2022-09-16 22:40:34.286 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :0/1167 loss:0.0442\n",
      "2022-09-16 22:40:36.148 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :100/1167 loss:0.0250\n",
      "2022-09-16 22:40:38.024 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :200/1167 loss:0.0052\n",
      "2022-09-16 22:40:39.971 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :300/1167 loss:0.0558\n",
      "2022-09-16 22:40:41.882 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :400/1167 loss:0.0289\n",
      "2022-09-16 22:40:43.782 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :500/1167 loss:0.0221\n",
      "2022-09-16 22:40:45.759 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :600/1167 loss:0.0099\n",
      "2022-09-16 22:40:47.627 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :700/1167 loss:0.0088\n",
      "2022-09-16 22:40:49.516 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :800/1167 loss:0.0041\n",
      "2022-09-16 22:40:51.402 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :900/1167 loss:0.0145\n",
      "2022-09-16 22:40:53.282 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :1000/1167 loss:0.0129\n",
      "2022-09-16 22:40:55.200 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :1100/1167 loss:0.0081\n",
      "2022-09-16 22:40:56.452 | INFO     | __main__:train_seq2seq_model:65 - Epoch :73/100, training loss:0.0111\n",
      "2022-09-16 22:40:57.202 | INFO     | __main__:train_seq2seq_model:69 - Epoch:73, dev loss:0.0135\n",
      "2022-09-16 22:40:57.212 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :0/1167 loss:0.0501\n",
      "2022-09-16 22:40:59.071 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :100/1167 loss:0.0251\n",
      "2022-09-16 22:41:00.945 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :200/1167 loss:0.0076\n",
      "2022-09-16 22:41:02.892 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :300/1167 loss:0.0702\n",
      "2022-09-16 22:41:04.804 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :400/1167 loss:0.0331\n",
      "2022-09-16 22:41:06.705 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :500/1167 loss:0.0175\n",
      "2022-09-16 22:41:08.680 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :600/1167 loss:0.0035\n",
      "2022-09-16 22:41:10.549 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :700/1167 loss:0.0143\n",
      "2022-09-16 22:41:12.435 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :800/1167 loss:0.0051\n",
      "2022-09-16 22:41:14.318 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :900/1167 loss:0.0018\n",
      "2022-09-16 22:41:16.199 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :1000/1167 loss:0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 22:41:18.110 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :1100/1167 loss:0.0060\n",
      "2022-09-16 22:41:19.357 | INFO     | __main__:train_seq2seq_model:65 - Epoch :74/100, training loss:0.0109\n",
      "2022-09-16 22:41:20.115 | INFO     | __main__:train_seq2seq_model:69 - Epoch:74, dev loss:0.0135\n",
      "2022-09-16 22:41:20.126 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :0/1167 loss:0.0495\n",
      "2022-09-16 22:41:21.989 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :100/1167 loss:0.0164\n",
      "2022-09-16 22:41:23.865 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :200/1167 loss:0.0019\n",
      "2022-09-16 22:41:25.812 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :300/1167 loss:0.0559\n",
      "2022-09-16 22:41:27.726 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :400/1167 loss:0.0296\n",
      "2022-09-16 22:41:29.630 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :500/1167 loss:0.0077\n",
      "2022-09-16 22:41:31.605 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :600/1167 loss:0.0055\n",
      "2022-09-16 22:41:33.472 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :700/1167 loss:0.0045\n",
      "2022-09-16 22:41:35.358 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :800/1167 loss:0.0101\n",
      "2022-09-16 22:41:37.239 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :900/1167 loss:0.0079\n",
      "2022-09-16 22:41:39.120 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :1000/1167 loss:0.0129\n",
      "2022-09-16 22:41:41.036 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :1100/1167 loss:0.0122\n",
      "2022-09-16 22:41:42.286 | INFO     | __main__:train_seq2seq_model:65 - Epoch :75/100, training loss:0.0113\n",
      "2022-09-16 22:41:43.033 | INFO     | __main__:train_seq2seq_model:69 - Epoch:75, dev loss:0.0147\n",
      "2022-09-16 22:41:43.044 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :0/1167 loss:0.0462\n",
      "2022-09-16 22:41:44.902 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :100/1167 loss:0.0208\n",
      "2022-09-16 22:41:46.777 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :200/1167 loss:0.0089\n",
      "2022-09-16 22:41:48.723 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :300/1167 loss:0.0576\n",
      "2022-09-16 22:41:50.638 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :400/1167 loss:0.0316\n",
      "2022-09-16 22:41:52.540 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :500/1167 loss:0.0054\n",
      "2022-09-16 22:41:54.519 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :600/1167 loss:0.0101\n",
      "2022-09-16 22:41:56.388 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :700/1167 loss:0.0035\n",
      "2022-09-16 22:41:58.275 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :800/1167 loss:0.0042\n",
      "2022-09-16 22:42:00.163 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :900/1167 loss:0.0032\n",
      "2022-09-16 22:42:02.044 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :1000/1167 loss:0.0097\n",
      "2022-09-16 22:42:03.962 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :1100/1167 loss:0.0049\n",
      "2022-09-16 22:42:05.214 | INFO     | __main__:train_seq2seq_model:65 - Epoch :76/100, training loss:0.0109\n",
      "2022-09-16 22:42:05.961 | INFO     | __main__:train_seq2seq_model:69 - Epoch:76, dev loss:0.0140\n",
      "2022-09-16 22:42:05.971 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :0/1167 loss:0.0447\n",
      "2022-09-16 22:42:07.828 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :100/1167 loss:0.0141\n",
      "2022-09-16 22:42:09.704 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :200/1167 loss:0.0022\n",
      "2022-09-16 22:42:11.653 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :300/1167 loss:0.0548\n",
      "2022-09-16 22:42:13.565 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :400/1167 loss:0.0326\n",
      "2022-09-16 22:42:15.464 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :500/1167 loss:0.0040\n",
      "2022-09-16 22:42:17.443 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :600/1167 loss:0.0125\n",
      "2022-09-16 22:42:19.313 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :700/1167 loss:0.0038\n",
      "2022-09-16 22:42:21.201 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :800/1167 loss:0.0144\n",
      "2022-09-16 22:42:23.086 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :900/1167 loss:0.0036\n",
      "2022-09-16 22:42:24.969 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :1000/1167 loss:0.0110\n",
      "2022-09-16 22:42:26.884 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :1100/1167 loss:0.0071\n",
      "2022-09-16 22:42:28.134 | INFO     | __main__:train_seq2seq_model:65 - Epoch :77/100, training loss:0.0115\n",
      "2022-09-16 22:42:28.882 | INFO     | __main__:train_seq2seq_model:69 - Epoch:77, dev loss:0.0141\n",
      "2022-09-16 22:42:28.892 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :0/1167 loss:0.0590\n",
      "2022-09-16 22:42:30.752 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :100/1167 loss:0.0198\n",
      "2022-09-16 22:42:32.627 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :200/1167 loss:0.0019\n",
      "2022-09-16 22:42:34.574 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :300/1167 loss:0.0636\n",
      "2022-09-16 22:42:36.486 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :400/1167 loss:0.0311\n",
      "2022-09-16 22:42:38.389 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :500/1167 loss:0.0054\n",
      "2022-09-16 22:42:40.364 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :600/1167 loss:0.0108\n",
      "2022-09-16 22:42:42.233 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :700/1167 loss:0.0087\n",
      "2022-09-16 22:42:44.118 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :800/1167 loss:0.0096\n",
      "2022-09-16 22:42:46.005 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :900/1167 loss:0.0023\n",
      "2022-09-16 22:42:47.888 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :1000/1167 loss:0.0112\n",
      "2022-09-16 22:42:49.801 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :1100/1167 loss:0.0080\n",
      "2022-09-16 22:42:51.053 | INFO     | __main__:train_seq2seq_model:65 - Epoch :78/100, training loss:0.0111\n",
      "2022-09-16 22:42:51.804 | INFO     | __main__:train_seq2seq_model:69 - Epoch:78, dev loss:0.0132\n",
      "2022-09-16 22:42:51.815 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :0/1167 loss:0.0478\n",
      "2022-09-16 22:42:53.671 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :100/1167 loss:0.0158\n",
      "2022-09-16 22:42:55.544 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :200/1167 loss:0.0071\n",
      "2022-09-16 22:42:57.491 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :300/1167 loss:0.0456\n",
      "2022-09-16 22:42:59.408 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :400/1167 loss:0.0355\n",
      "2022-09-16 22:43:01.308 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :500/1167 loss:0.0038\n",
      "2022-09-16 22:43:03.288 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :600/1167 loss:0.0048\n",
      "2022-09-16 22:43:05.164 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :700/1167 loss:0.0052\n",
      "2022-09-16 22:43:07.051 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :800/1167 loss:0.0058\n",
      "2022-09-16 22:43:08.935 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :900/1167 loss:0.0018\n",
      "2022-09-16 22:43:10.821 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :1000/1167 loss:0.0186\n",
      "2022-09-16 22:43:12.736 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :1100/1167 loss:0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 22:43:13.988 | INFO     | __main__:train_seq2seq_model:65 - Epoch :79/100, training loss:0.0111\n",
      "2022-09-16 22:43:14.736 | INFO     | __main__:train_seq2seq_model:69 - Epoch:79, dev loss:0.0135\n",
      "2022-09-16 22:43:14.747 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :0/1167 loss:0.0557\n",
      "2022-09-16 22:43:16.607 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :100/1167 loss:0.0174\n",
      "2022-09-16 22:43:18.482 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :200/1167 loss:0.0021\n",
      "2022-09-16 22:43:20.440 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :300/1167 loss:0.0556\n",
      "2022-09-16 22:43:22.356 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :400/1167 loss:0.0370\n",
      "2022-09-16 22:43:24.261 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :500/1167 loss:0.0040\n",
      "2022-09-16 22:43:26.241 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :600/1167 loss:0.0043\n",
      "2022-09-16 22:43:28.113 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :700/1167 loss:0.0043\n",
      "2022-09-16 22:43:29.999 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :800/1167 loss:0.0054\n",
      "2022-09-16 22:43:31.885 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :900/1167 loss:0.0036\n",
      "2022-09-16 22:43:33.766 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :1000/1167 loss:0.0160\n",
      "2022-09-16 22:43:35.680 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :1100/1167 loss:0.0087\n",
      "2022-09-16 22:43:36.933 | INFO     | __main__:train_seq2seq_model:65 - Epoch :80/100, training loss:0.0109\n",
      "2022-09-16 22:43:37.679 | INFO     | __main__:train_seq2seq_model:69 - Epoch:80, dev loss:0.0135\n",
      "2022-09-16 22:43:37.689 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :0/1167 loss:0.0419\n",
      "2022-09-16 22:43:39.549 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :100/1167 loss:0.0151\n",
      "2022-09-16 22:43:41.423 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :200/1167 loss:0.0081\n",
      "2022-09-16 22:43:43.373 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :300/1167 loss:0.0452\n",
      "2022-09-16 22:43:45.287 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :400/1167 loss:0.0357\n",
      "2022-09-16 22:43:47.188 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :500/1167 loss:0.0036\n",
      "2022-09-16 22:43:49.164 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :600/1167 loss:0.0071\n",
      "2022-09-16 22:43:51.038 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :700/1167 loss:0.0037\n",
      "2022-09-16 22:43:52.922 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :800/1167 loss:0.0041\n",
      "2022-09-16 22:43:54.806 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :900/1167 loss:0.0014\n",
      "2022-09-16 22:43:56.690 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :1000/1167 loss:0.0125\n",
      "2022-09-16 22:43:58.605 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :1100/1167 loss:0.0074\n",
      "2022-09-16 22:43:59.856 | INFO     | __main__:train_seq2seq_model:65 - Epoch :81/100, training loss:0.0104\n",
      "2022-09-16 22:44:00.602 | INFO     | __main__:train_seq2seq_model:69 - Epoch:81, dev loss:0.0133\n",
      "2022-09-16 22:44:00.612 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :0/1167 loss:0.0438\n",
      "2022-09-16 22:44:02.474 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :100/1167 loss:0.0187\n",
      "2022-09-16 22:44:04.353 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :200/1167 loss:0.0018\n",
      "2022-09-16 22:44:06.299 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :300/1167 loss:0.0513\n",
      "2022-09-16 22:44:08.215 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :400/1167 loss:0.0323\n",
      "2022-09-16 22:44:10.116 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :500/1167 loss:0.0034\n",
      "2022-09-16 22:44:12.091 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :600/1167 loss:0.0053\n",
      "2022-09-16 22:44:13.958 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :700/1167 loss:0.0034\n",
      "2022-09-16 22:44:15.845 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :800/1167 loss:0.0041\n",
      "2022-09-16 22:44:17.730 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :900/1167 loss:0.0018\n",
      "2022-09-16 22:44:19.613 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :1000/1167 loss:0.0163\n",
      "2022-09-16 22:44:21.529 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :1100/1167 loss:0.0047\n",
      "2022-09-16 22:44:22.782 | INFO     | __main__:train_seq2seq_model:65 - Epoch :82/100, training loss:0.0104\n",
      "2022-09-16 22:44:23.529 | INFO     | __main__:train_seq2seq_model:69 - Epoch:82, dev loss:0.0140\n",
      "2022-09-16 22:44:23.539 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :0/1167 loss:0.0415\n",
      "2022-09-16 22:44:25.397 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :100/1167 loss:0.0231\n",
      "2022-09-16 22:44:27.268 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :200/1167 loss:0.0045\n",
      "2022-09-16 22:44:29.215 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :300/1167 loss:0.0562\n",
      "2022-09-16 22:44:31.131 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :400/1167 loss:0.0324\n",
      "2022-09-16 22:44:33.030 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :500/1167 loss:0.0055\n",
      "2022-09-16 22:44:35.006 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :600/1167 loss:0.0027\n",
      "2022-09-16 22:44:36.873 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :700/1167 loss:0.0034\n",
      "2022-09-16 22:44:38.758 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :800/1167 loss:0.0042\n",
      "2022-09-16 22:44:40.642 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :900/1167 loss:0.0014\n",
      "2022-09-16 22:44:42.526 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :1000/1167 loss:0.0097\n",
      "2022-09-16 22:44:44.442 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :1100/1167 loss:0.0056\n",
      "2022-09-16 22:44:45.693 | INFO     | __main__:train_seq2seq_model:65 - Epoch :83/100, training loss:0.0108\n",
      "2022-09-16 22:44:46.445 | INFO     | __main__:train_seq2seq_model:69 - Epoch:83, dev loss:0.0144\n",
      "2022-09-16 22:44:46.455 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :0/1167 loss:0.0475\n",
      "2022-09-16 22:44:48.315 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :100/1167 loss:0.0188\n",
      "2022-09-16 22:44:50.189 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :200/1167 loss:0.0041\n",
      "2022-09-16 22:44:52.139 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :300/1167 loss:0.0511\n",
      "2022-09-16 22:44:54.051 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :400/1167 loss:0.0295\n",
      "2022-09-16 22:44:55.954 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :500/1167 loss:0.0039\n",
      "2022-09-16 22:44:57.928 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :600/1167 loss:0.0232\n",
      "2022-09-16 22:44:59.802 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :700/1167 loss:0.0064\n",
      "2022-09-16 22:45:01.697 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :800/1167 loss:0.0088\n",
      "2022-09-16 22:45:03.579 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :900/1167 loss:0.0022\n",
      "2022-09-16 22:45:05.461 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :1000/1167 loss:0.0125\n",
      "2022-09-16 22:45:07.375 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :1100/1167 loss:0.0094\n",
      "2022-09-16 22:45:08.626 | INFO     | __main__:train_seq2seq_model:65 - Epoch :84/100, training loss:0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 22:45:09.381 | INFO     | __main__:train_seq2seq_model:69 - Epoch:84, dev loss:0.0158\n",
      "2022-09-16 22:45:09.391 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :0/1167 loss:0.0522\n",
      "2022-09-16 22:45:11.249 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :100/1167 loss:0.0200\n",
      "2022-09-16 22:45:13.121 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :200/1167 loss:0.0019\n",
      "2022-09-16 22:45:15.067 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :300/1167 loss:0.0469\n",
      "2022-09-16 22:45:16.978 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :400/1167 loss:0.0405\n",
      "2022-09-16 22:45:18.882 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :500/1167 loss:0.0051\n",
      "2022-09-16 22:45:20.859 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :600/1167 loss:0.0069\n",
      "2022-09-16 22:45:22.728 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :700/1167 loss:0.0068\n",
      "2022-09-16 22:45:24.615 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :800/1167 loss:0.0042\n",
      "2022-09-16 22:45:26.500 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :900/1167 loss:0.0041\n",
      "2022-09-16 22:45:28.384 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :1000/1167 loss:0.0135\n",
      "2022-09-16 22:45:30.299 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :1100/1167 loss:0.0081\n",
      "2022-09-16 22:45:31.549 | INFO     | __main__:train_seq2seq_model:65 - Epoch :85/100, training loss:0.0119\n",
      "2022-09-16 22:45:32.307 | INFO     | __main__:train_seq2seq_model:69 - Epoch:85, dev loss:0.0145\n",
      "2022-09-16 22:45:32.317 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :0/1167 loss:0.0415\n",
      "2022-09-16 22:45:34.176 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :100/1167 loss:0.0164\n",
      "2022-09-16 22:45:36.050 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :200/1167 loss:0.0017\n",
      "2022-09-16 22:45:38.003 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :300/1167 loss:0.0433\n",
      "2022-09-16 22:45:39.915 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :400/1167 loss:0.0344\n",
      "2022-09-16 22:45:41.819 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :500/1167 loss:0.0032\n",
      "2022-09-16 22:45:43.796 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :600/1167 loss:0.0050\n",
      "2022-09-16 22:45:45.666 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :700/1167 loss:0.0098\n",
      "2022-09-16 22:45:47.553 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :800/1167 loss:0.0042\n",
      "2022-09-16 22:45:49.436 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :900/1167 loss:0.0015\n",
      "2022-09-16 22:45:51.316 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :1000/1167 loss:0.0101\n",
      "2022-09-16 22:45:53.231 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :1100/1167 loss:0.0095\n",
      "2022-09-16 22:45:54.483 | INFO     | __main__:train_seq2seq_model:65 - Epoch :86/100, training loss:0.0107\n",
      "2022-09-16 22:45:55.244 | INFO     | __main__:train_seq2seq_model:69 - Epoch:86, dev loss:0.0140\n",
      "2022-09-16 22:45:55.254 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :0/1167 loss:0.0366\n",
      "2022-09-16 22:45:57.113 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :100/1167 loss:0.0172\n",
      "2022-09-16 22:45:58.981 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :200/1167 loss:0.0054\n",
      "2022-09-16 22:46:00.927 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :300/1167 loss:0.0493\n",
      "2022-09-16 22:46:02.842 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :400/1167 loss:0.0348\n",
      "2022-09-16 22:46:04.745 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :500/1167 loss:0.0022\n",
      "2022-09-16 22:46:06.722 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :600/1167 loss:0.0061\n",
      "2022-09-16 22:46:08.590 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :700/1167 loss:0.0100\n",
      "2022-09-16 22:46:10.476 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :800/1167 loss:0.0041\n",
      "2022-09-16 22:46:12.362 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :900/1167 loss:0.0053\n",
      "2022-09-16 22:46:14.243 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :1000/1167 loss:0.0101\n",
      "2022-09-16 22:46:16.157 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :1100/1167 loss:0.0028\n",
      "2022-09-16 22:46:17.407 | INFO     | __main__:train_seq2seq_model:65 - Epoch :87/100, training loss:0.0104\n",
      "2022-09-16 22:46:18.154 | INFO     | __main__:train_seq2seq_model:69 - Epoch:87, dev loss:0.0140\n",
      "2022-09-16 22:46:18.165 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :0/1167 loss:0.0379\n",
      "2022-09-16 22:46:20.022 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :100/1167 loss:0.0139\n",
      "2022-09-16 22:46:21.899 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :200/1167 loss:0.0035\n",
      "2022-09-16 22:46:23.847 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :300/1167 loss:0.0528\n",
      "2022-09-16 22:46:25.762 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :400/1167 loss:0.0468\n",
      "2022-09-16 22:46:27.662 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :500/1167 loss:0.0028\n",
      "2022-09-16 22:46:29.636 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :600/1167 loss:0.0071\n",
      "2022-09-16 22:46:31.507 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :700/1167 loss:0.0061\n",
      "2022-09-16 22:46:33.395 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :800/1167 loss:0.0046\n",
      "2022-09-16 22:46:35.281 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :900/1167 loss:0.0021\n",
      "2022-09-16 22:46:37.163 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :1000/1167 loss:0.0124\n",
      "2022-09-16 22:46:39.077 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :1100/1167 loss:0.0107\n",
      "2022-09-16 22:46:40.329 | INFO     | __main__:train_seq2seq_model:65 - Epoch :88/100, training loss:0.0111\n",
      "2022-09-16 22:46:41.077 | INFO     | __main__:train_seq2seq_model:69 - Epoch:88, dev loss:0.0147\n",
      "2022-09-16 22:46:41.087 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :0/1167 loss:0.0432\n",
      "2022-09-16 22:46:42.946 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :100/1167 loss:0.0166\n",
      "2022-09-16 22:46:44.819 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :200/1167 loss:0.0036\n",
      "2022-09-16 22:46:46.768 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :300/1167 loss:0.0468\n",
      "2022-09-16 22:46:48.680 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :400/1167 loss:0.0327\n",
      "2022-09-16 22:46:50.584 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :500/1167 loss:0.0032\n",
      "2022-09-16 22:46:52.560 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :600/1167 loss:0.0043\n",
      "2022-09-16 22:46:54.439 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :700/1167 loss:0.0031\n",
      "2022-09-16 22:46:56.324 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :800/1167 loss:0.0038\n",
      "2022-09-16 22:46:58.207 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :900/1167 loss:0.0017\n",
      "2022-09-16 22:47:00.088 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :1000/1167 loss:0.0112\n",
      "2022-09-16 22:47:02.003 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :1100/1167 loss:0.0087\n",
      "2022-09-16 22:47:03.253 | INFO     | __main__:train_seq2seq_model:65 - Epoch :89/100, training loss:0.0109\n",
      "2022-09-16 22:47:04.006 | INFO     | __main__:train_seq2seq_model:69 - Epoch:89, dev loss:0.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 22:47:04.016 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :0/1167 loss:0.0335\n",
      "2022-09-16 22:47:05.877 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :100/1167 loss:0.0171\n",
      "2022-09-16 22:47:07.751 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :200/1167 loss:0.0045\n",
      "2022-09-16 22:47:09.700 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :300/1167 loss:0.0390\n",
      "2022-09-16 22:47:11.614 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :400/1167 loss:0.0407\n",
      "2022-09-16 22:47:13.515 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :500/1167 loss:0.0036\n",
      "2022-09-16 22:47:15.491 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :600/1167 loss:0.0059\n",
      "2022-09-16 22:47:17.363 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :700/1167 loss:0.0031\n",
      "2022-09-16 22:47:19.250 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :800/1167 loss:0.0048\n",
      "2022-09-16 22:47:21.138 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :900/1167 loss:0.0020\n",
      "2022-09-16 22:47:23.020 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :1000/1167 loss:0.0101\n",
      "2022-09-16 22:47:24.936 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :1100/1167 loss:0.0134\n",
      "2022-09-16 22:47:26.186 | INFO     | __main__:train_seq2seq_model:65 - Epoch :90/100, training loss:0.0107\n",
      "2022-09-16 22:47:26.941 | INFO     | __main__:train_seq2seq_model:69 - Epoch:90, dev loss:0.0146\n",
      "2022-09-16 22:47:26.952 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :0/1167 loss:0.0436\n",
      "2022-09-16 22:47:28.813 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :100/1167 loss:0.0152\n",
      "2022-09-16 22:47:30.685 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :200/1167 loss:0.0017\n",
      "2022-09-16 22:47:32.633 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :300/1167 loss:0.0432\n",
      "2022-09-16 22:47:34.550 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :400/1167 loss:0.0314\n",
      "2022-09-16 22:47:36.450 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :500/1167 loss:0.0026\n",
      "2022-09-16 22:47:38.428 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :600/1167 loss:0.0080\n",
      "2022-09-16 22:47:40.298 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :700/1167 loss:0.0044\n",
      "2022-09-16 22:47:42.183 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :800/1167 loss:0.0039\n",
      "2022-09-16 22:47:44.066 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :900/1167 loss:0.0017\n",
      "2022-09-16 22:47:45.947 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :1000/1167 loss:0.0109\n",
      "2022-09-16 22:47:47.859 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :1100/1167 loss:0.0156\n",
      "2022-09-16 22:47:49.107 | INFO     | __main__:train_seq2seq_model:65 - Epoch :91/100, training loss:0.0109\n",
      "2022-09-16 22:47:49.854 | INFO     | __main__:train_seq2seq_model:69 - Epoch:91, dev loss:0.0149\n",
      "2022-09-16 22:47:49.865 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :0/1167 loss:0.0362\n",
      "2022-09-16 22:47:51.724 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :100/1167 loss:0.0162\n",
      "2022-09-16 22:47:53.601 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :200/1167 loss:0.0016\n",
      "2022-09-16 22:47:55.551 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :300/1167 loss:0.0423\n",
      "2022-09-16 22:47:57.465 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :400/1167 loss:0.0344\n",
      "2022-09-16 22:47:59.365 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :500/1167 loss:0.0031\n",
      "2022-09-16 22:48:01.339 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :600/1167 loss:0.0104\n",
      "2022-09-16 22:48:03.209 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :700/1167 loss:0.0064\n",
      "2022-09-16 22:48:05.097 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :800/1167 loss:0.0040\n",
      "2022-09-16 22:48:06.985 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :900/1167 loss:0.0019\n",
      "2022-09-16 22:48:08.871 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :1000/1167 loss:0.0127\n",
      "2022-09-16 22:48:10.788 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :1100/1167 loss:0.0089\n",
      "2022-09-16 22:48:12.037 | INFO     | __main__:train_seq2seq_model:65 - Epoch :92/100, training loss:0.0108\n",
      "2022-09-16 22:48:12.783 | INFO     | __main__:train_seq2seq_model:69 - Epoch:92, dev loss:0.0143\n",
      "2022-09-16 22:48:12.793 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :0/1167 loss:0.0375\n",
      "2022-09-16 22:48:14.652 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :100/1167 loss:0.0123\n",
      "2022-09-16 22:48:16.527 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :200/1167 loss:0.0016\n",
      "2022-09-16 22:48:18.498 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :300/1167 loss:0.0592\n",
      "2022-09-16 22:48:20.438 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :400/1167 loss:0.0363\n",
      "2022-09-16 22:48:22.379 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :500/1167 loss:0.0051\n",
      "2022-09-16 22:48:24.359 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :600/1167 loss:0.0040\n",
      "2022-09-16 22:48:26.229 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :700/1167 loss:0.0071\n",
      "2022-09-16 22:48:28.114 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :800/1167 loss:0.0102\n",
      "2022-09-16 22:48:30.000 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :900/1167 loss:0.0043\n",
      "2022-09-16 22:48:31.884 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :1000/1167 loss:0.0144\n",
      "2022-09-16 22:48:33.796 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :1100/1167 loss:0.0064\n",
      "2022-09-16 22:48:35.046 | INFO     | __main__:train_seq2seq_model:65 - Epoch :93/100, training loss:0.0105\n",
      "2022-09-16 22:48:35.795 | INFO     | __main__:train_seq2seq_model:69 - Epoch:93, dev loss:0.0142\n",
      "2022-09-16 22:48:35.806 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :0/1167 loss:0.0412\n",
      "2022-09-16 22:48:37.666 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :100/1167 loss:0.0132\n",
      "2022-09-16 22:48:39.539 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :200/1167 loss:0.0061\n",
      "2022-09-16 22:48:41.488 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :300/1167 loss:0.0496\n",
      "2022-09-16 22:48:43.402 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :400/1167 loss:0.0307\n",
      "2022-09-16 22:48:45.301 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :500/1167 loss:0.0080\n",
      "2022-09-16 22:48:47.275 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :600/1167 loss:0.0067\n",
      "2022-09-16 22:48:49.143 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :700/1167 loss:0.0054\n",
      "2022-09-16 22:48:51.030 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :800/1167 loss:0.0075\n",
      "2022-09-16 22:48:52.915 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :900/1167 loss:0.0015\n",
      "2022-09-16 22:48:54.797 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :1000/1167 loss:0.0098\n",
      "2022-09-16 22:48:56.710 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :1100/1167 loss:0.0040\n",
      "2022-09-16 22:48:57.957 | INFO     | __main__:train_seq2seq_model:65 - Epoch :94/100, training loss:0.0105\n",
      "2022-09-16 22:48:58.703 | INFO     | __main__:train_seq2seq_model:69 - Epoch:94, dev loss:0.0139\n",
      "2022-09-16 22:48:58.714 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :0/1167 loss:0.0396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 22:49:00.575 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :100/1167 loss:0.0150\n",
      "2022-09-16 22:49:02.446 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :200/1167 loss:0.0018\n",
      "2022-09-16 22:49:04.393 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :300/1167 loss:0.0356\n",
      "2022-09-16 22:49:06.307 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :400/1167 loss:0.0321\n",
      "2022-09-16 22:49:08.208 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :500/1167 loss:0.0024\n",
      "2022-09-16 22:49:10.180 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :600/1167 loss:0.0032\n",
      "2022-09-16 22:49:12.052 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :700/1167 loss:0.0032\n",
      "2022-09-16 22:49:13.942 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :800/1167 loss:0.0036\n",
      "2022-09-16 22:49:15.825 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :900/1167 loss:0.0045\n",
      "2022-09-16 22:49:17.707 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :1000/1167 loss:0.0102\n",
      "2022-09-16 22:49:19.626 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :1100/1167 loss:0.0054\n",
      "2022-09-16 22:49:20.877 | INFO     | __main__:train_seq2seq_model:65 - Epoch :95/100, training loss:0.0102\n",
      "2022-09-16 22:49:21.623 | INFO     | __main__:train_seq2seq_model:69 - Epoch:95, dev loss:0.0135\n",
      "2022-09-16 22:49:21.633 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :0/1167 loss:0.0392\n",
      "2022-09-16 22:49:23.496 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :100/1167 loss:0.0144\n",
      "2022-09-16 22:49:25.369 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :200/1167 loss:0.0018\n",
      "2022-09-16 22:49:27.334 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :300/1167 loss:0.0502\n",
      "2022-09-16 22:49:29.252 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :400/1167 loss:0.0355\n",
      "2022-09-16 22:49:31.209 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :500/1167 loss:0.0035\n",
      "2022-09-16 22:49:33.212 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :600/1167 loss:0.0043\n",
      "2022-09-16 22:49:35.089 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :700/1167 loss:0.0026\n",
      "2022-09-16 22:49:36.979 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :800/1167 loss:0.0047\n",
      "2022-09-16 22:49:38.870 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :900/1167 loss:0.0027\n",
      "2022-09-16 22:49:40.756 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :1000/1167 loss:0.0131\n",
      "2022-09-16 22:49:42.673 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :1100/1167 loss:0.0073\n",
      "2022-09-16 22:49:43.927 | INFO     | __main__:train_seq2seq_model:65 - Epoch :96/100, training loss:0.0103\n",
      "2022-09-16 22:49:44.682 | INFO     | __main__:train_seq2seq_model:69 - Epoch:96, dev loss:0.0142\n",
      "2022-09-16 22:49:44.692 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :0/1167 loss:0.0574\n",
      "2022-09-16 22:49:46.553 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :100/1167 loss:0.0160\n",
      "2022-09-16 22:49:48.429 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :200/1167 loss:0.0014\n",
      "2022-09-16 22:49:50.382 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :300/1167 loss:0.0450\n",
      "2022-09-16 22:49:52.300 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :400/1167 loss:0.0340\n",
      "2022-09-16 22:49:54.218 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :500/1167 loss:0.0045\n",
      "2022-09-16 22:49:56.205 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :600/1167 loss:0.0021\n",
      "2022-09-16 22:49:58.079 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :700/1167 loss:0.0090\n",
      "2022-09-16 22:49:59.970 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :800/1167 loss:0.0035\n",
      "2022-09-16 22:50:01.875 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :900/1167 loss:0.0027\n",
      "2022-09-16 22:50:03.767 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :1000/1167 loss:0.0090\n",
      "2022-09-16 22:50:05.684 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :1100/1167 loss:0.0093\n",
      "2022-09-16 22:50:06.938 | INFO     | __main__:train_seq2seq_model:65 - Epoch :97/100, training loss:0.0107\n",
      "2022-09-16 22:50:07.698 | INFO     | __main__:train_seq2seq_model:69 - Epoch:97, dev loss:0.0141\n",
      "2022-09-16 22:50:07.709 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :0/1167 loss:0.0500\n",
      "2022-09-16 22:50:09.572 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :100/1167 loss:0.0161\n",
      "2022-09-16 22:50:11.449 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :200/1167 loss:0.0018\n",
      "2022-09-16 22:50:13.402 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :300/1167 loss:0.0426\n",
      "2022-09-16 22:50:15.318 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :400/1167 loss:0.0360\n",
      "2022-09-16 22:50:17.221 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :500/1167 loss:0.0023\n",
      "2022-09-16 22:50:19.202 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :600/1167 loss:0.0056\n",
      "2022-09-16 22:50:21.076 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :700/1167 loss:0.0047\n",
      "2022-09-16 22:50:22.966 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :800/1167 loss:0.0036\n",
      "2022-09-16 22:50:24.853 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :900/1167 loss:0.0012\n",
      "2022-09-16 22:50:26.740 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :1000/1167 loss:0.0177\n",
      "2022-09-16 22:50:28.658 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :1100/1167 loss:0.0072\n",
      "2022-09-16 22:50:29.910 | INFO     | __main__:train_seq2seq_model:65 - Epoch :98/100, training loss:0.0106\n",
      "2022-09-16 22:50:30.669 | INFO     | __main__:train_seq2seq_model:69 - Epoch:98, dev loss:0.0140\n",
      "2022-09-16 22:50:30.680 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :0/1167 loss:0.0470\n",
      "2022-09-16 22:50:32.543 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :100/1167 loss:0.0134\n",
      "2022-09-16 22:50:34.419 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :200/1167 loss:0.0039\n",
      "2022-09-16 22:50:36.371 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :300/1167 loss:0.0399\n",
      "2022-09-16 22:50:38.292 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :400/1167 loss:0.0333\n",
      "2022-09-16 22:50:40.198 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :500/1167 loss:0.0030\n",
      "2022-09-16 22:50:42.176 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :600/1167 loss:0.0059\n",
      "2022-09-16 22:50:44.052 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :700/1167 loss:0.0034\n",
      "2022-09-16 22:50:45.941 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :800/1167 loss:0.0038\n",
      "2022-09-16 22:50:47.829 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :900/1167 loss:0.0052\n",
      "2022-09-16 22:50:49.717 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :1000/1167 loss:0.0177\n",
      "2022-09-16 22:50:51.633 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :1100/1167 loss:0.0060\n",
      "2022-09-16 22:50:52.888 | INFO     | __main__:train_seq2seq_model:65 - Epoch :99/100, training loss:0.0106\n",
      "2022-09-16 22:50:53.640 | INFO     | __main__:train_seq2seq_model:69 - Epoch:99, dev loss:0.0159\n"
     ]
    }
   ],
   "source": [
    "if args.do_preprocess:\n",
    "    # Preprocess\n",
    "    data_list = []\n",
    "    os.makedirs(args.model_dir, exist_ok=True)\n",
    "    '''\n",
    "    if args.dataset == 'sighan':\n",
    "        data_list.extend(get_data_file(args.raw_train_path, args.use_segment, args.segment_type))\n",
    "    else:\n",
    "        data_list.extend(parse_xml_file(args.raw_train_path, args.use_segment, args.segment_type))\n",
    "    '''\n",
    "    data_list.extend(get_data_file(\"../pycorrector/data/RNA/train\", args.use_segment, args.segment_type))\n",
    "    if data_list:\n",
    "        save_corpus_data(data_list, args.train_path, args.test_path)\n",
    "# Train model with train data file\n",
    "train(args.arch,\n",
    "        args.train_path,\n",
    "        args.batch_size,\n",
    "        args.embed_size,\n",
    "        args.hidden_size,\n",
    "        args.dropout,\n",
    "        args.epochs,\n",
    "        args.model_dir,\n",
    "        args.max_length,\n",
    "        args.use_segment,\n",
    "        args.model_name_or_path,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b04c116d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46096,\n",
       " 46095,\n",
       " 46089,\n",
       " 46080,\n",
       " 46079,\n",
       " 46076,\n",
       " 46070,\n",
       " 46068,\n",
       " 46067,\n",
       " 46062,\n",
       " 46060,\n",
       " 46058,\n",
       " 46050,\n",
       " 46045,\n",
       " 46043,\n",
       " 46042,\n",
       " 46041,\n",
       " 46040,\n",
       " 46032,\n",
       " 46021,\n",
       " 46009,\n",
       " 46008,\n",
       " 46004,\n",
       " 46003,\n",
       " 46001,\n",
       " 45999]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_data_file(\"../pycorrector/data/RNA/train\", args.use_segment, args.segment_type)\n",
    "res = []\n",
    "for i in range(len(data)-1,len(data)-100,-1):\n",
    "    a,b = data[i]\n",
    "    if a != b:\n",
    "        res.append(i)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9747223",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MET PHE ASN SER TYR GLU GLY CYS GLY ASP LEU THR ILE PHE VAL ALA VAL ALA LEU ASN LYS VAL ILE GLY HIS LYS ASN GLN ILE PRO TRP PRO HIS ILE THR HIS ASP PHE ARG PHE LEU ARG ASN GLY THR THR TYR ILE PRO PRO GLU VAL LEU SER LYS ASN PRO ASP ILE GLN ASN VAL VAL ILE PHE GLY ARG LYS THR TYR GLU SER ILE PRO LYS ALA SER LEU PRO LEU LYS ASN ARG ILE ASN VAL ILE LEU SER ARG THR VAL LYS GLU VAL PRO GLY CYS LEU VAL TYR GLU ASP LEU SER THR ALA ILE ARG ASP LEU ARG ALA ASN VAL PRO HIS ASN LYS ILE PHE ILE LEU GLY GLY SER PHE LEU TYR LYS GLU VAL LEU ASP ASN GLY LEU CYS ASP LYS ILE TYR LEU THR ARG LEU ASN LYS GLU TYR PRO GLY ASP THR TYR PHE PRO ASP ILE PRO ASP THR PHE GLU ILE THR ALA ILE SER PRO THR PHE SER THR ASP PHE VAL SER TYR ASP PHE VAL ILE TYR GLU ARG LYS ASP CYS LYS THR VAL PHE PRO ASP PRO PRO PHE ASP GLN LEU LEU MET THR GLY THR ASP ILE SER VAL PRO LYS PRO LYS TYR VAL ALA CYS PRO GLY VAL ARG ILE ARG ASN HIS GLU GLU PHE GLN TYR LEU ASP ILE LEU ALA ASP VAL LEU SER HIS GLY VAL LEU LYS PRO ASN ARG THR GLY THR ASP ALA TYR SER LYS PHE GLY TYR GLN MET ARG PHE ASP LEU SER ARG SER PHE PRO LEU LEU THR THR LYS LYS VAL ALA LEU ARG SER ILE ILE GLU GLU LEU LEU TRP PHE ILE LYS GLY SER THR ASN GLY ASN ASP LEU LEU ALA LYS ASN VAL ARG ILE TRP GLU LEU ASN GLY ARG ARG ASP PHE LEU ASP LYS ASN GLY PHE THR ASP ARG GLU GLU HIS ASP LEU GLY PRO ILE TYR GLY PHE GLN TRP ARG HIS PHE GLY ALA GLU TYR LEU ASP MET HIS ALA ASP TYR THR GLY LYS GLY ILE ASP GLN LEU ALA GLU ILE ILE ASN ARG ILE LYS THR ASN PRO ASN ASP ARG ARG LEU ILE VAL CYS SER TRP ASN VAL SER ASP LEU LYS LYS MET ALA LEU PRO PRO CYS HIS CYS PHE PHE GLN PHE TYR VAL SER ASP ASN LYS LEU SER CYS MET MET HIS GLN ARG SER CYS ASP LEU GLY LEU GLY VAL PRO PHE ASN ILE ALA SER TYR SER ILE LEU THR ALA MET VAL ALA GLN VAL CYS GLY LEU GLY LEU GLY GLU PHE VAL HIS ASN LEU ALA ASP ALA HIS ILE TYR VAL ASP HIS VAL ASP ALA VAL THR THR GLN ILE ALA ARG ILE PRO HIS PRO PHE PRO ARG LEU ARG LEU ASN PRO ASP ILE ARG ASN ILE GLU ASP PHE THR ILE ASP ASP ILE VAL VAL GLU ASP TYR VAL SER HIS PRO PRO ILE PRO MET ALA MET SER ALA',\n",
       " 'PRO ILE GLU VAL LEU THR GLY GLY HIS SER VAL SER ALA PRO GLN GLU ASN ARG ILE TYR VAL MET ASP SER VAL PHE MET HIS LEU THR GLU SER ARG VAL HIS VAL TYR ASP TYR THR ASN GLY LYS PHE LEU GLY MET VAL PRO THR ALA PHE ASN GLY HIS VAL GLN VAL SER ASN ASP GLY LYS LYS ILE TYR THR MET THR THR TYR HIS GLU ARG ILE THR ARG GLY LYS ARG SER ASP VAL VAL GLU VAL TRP ASP ALA ASP LYS LEU THR PHE GLU LYS GLU ILE SER LEU PRO PRO LYS ARG VAL GLN GLY LEU ASN TYR ASP GLY LEU PHE ARG GLN THR THR ASP GLY LYS PHE ILE VAL LEU GLN ASN ALA SER PRO ALA THR SER ILE GLY ILE VAL ASP VAL ALA LYS GLY ASP TYR VAL GLU ASP VAL THR ALA ALA ALA GLY CYS TRP SER VAL ILE PRO GLN PRO ASN ARG PRO ARG SER PHE MET THR ILE CYS GLY ASP GLY GLY LEU LEU THR ILE ASN LEU GLY GLU ASP GLY LYS VAL ALA SER GLN SER ARG SER LYS GLN MET PHE SER VAL LYS ASP ASP PRO ILE PHE ILE ALA PRO ALA LEU ASP LYS ASP LYS ALA HIS PHE VAL SER TYR TYR GLY ASN VAL TYR SER ALA ASP PHE SER GLY ASP GLU VAL LYS VAL ASP GLY PRO TRP SER LEU LEU ASN ASP GLU ASP LYS ALA LYS ASN TRP VAL PRO GLY GLY TYR ASN LEU VAL GLY LEU HIS ARG ALA SER GLY ARG MET TYR VAL PHE MET HIS PRO ASP GLY LYS GLU GLY THR HIS LYS PHE PRO ALA ALA GLU ILE TRP VAL MET ASP THR LYS THR LYS GLN ARG VAL ALA ARG ILE PRO GLY ARG ASP ALA LEU SER MET THR ILE ASP GLN GLN ARG ASN LEU MET LEU THR LEU ASP GLY GLY ASN VAL ASN VAL TYR ASP ILE SER GLN PRO GLU PRO LYS LEU LEU ARG THR ILE GLU GLY ALA ALA GLU ALA SER LEU GLN VAL GLN PHE HIS PRO VAL GLY GLY THR']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " [data[i][1] for i in res[:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28819632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 23:07:08.922 | DEBUG    | __main__:__init__:22 - Device: cuda\n",
      "2022-09-16 23:07:08.923 | DEBUG    | __main__:__init__:23 - Use seq2seq model.\n",
      "2022-09-16 23:07:08.933 | DEBUG    | __main__:__init__:38 - Load model from output/RNA/seq2seq.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "input  : MET SER ASN SER TYR GLU GLY CYS GLY ASP LEU THR ILE PHE VAL ALA VAL ALA LEU ASN LYS VAL ILE GLY HIS LYS ASN GLN ILE PRO TRP PRO HIS ILE THR HIS ASP PHE ARG PHE LEU ARG ASN GLY THR THR TYR ILE PRO PRO GLU VAL LEU SER LYS ASN PRO ASP ILE GLN ASN VAL VAL ILE PHE GLY ARG LYS THR TYR GLU SER ILE PRO LYS ALA SER LEU PRO LEU LYS ASN ARG ILE ASN VAL ILE LEU SER ARG THR VAL LYS GLU VAL PRO GLY CYS LEU VAL TYR GLU ASP LEU SER THR ALA ILE ARG ASP LEU ARG ALA ASN VAL PRO HIS ASN LYS ILE PHE ILE LEU GLY GLY SER PHE LEU TYR LYS GLU VAL LEU ASP ASN GLY LEU CYS ASP LYS ILE TYR LEU THR ARG LEU ASN LYS GLU TYR PRO GLY ASP THR TYR PHE PRO ASP ILE PRO ASP THR PHE GLU ILE THR ALA ILE SER PRO THR PHE SER THR ASP PHE VAL SER TYR ASP PHE VAL ILE TYR GLU ARG LYS ASP CYS LYS THR VAL PHE PRO ASP PRO PRO PHE ASP GLN LEU LEU MET THR GLY THR ASP ILE SER VAL PRO LYS PRO LYS TYR VAL ALA CYS PRO GLY VAL ARG ILE ARG ASN HIS GLU GLU PHE GLN TYR LEU ASP ILE LEU ALA ASP VAL LEU SER HIS GLY VAL LEU LYS PRO ASN ARG THR GLY THR ASP ALA TYR SER LYS PHE GLY TYR GLN MET ARG PHE ASP LEU SER ARG SER PHE PRO LEU LEU THR THR LYS LYS VAL ALA LEU ARG SER ILE ILE GLU GLU LEU LEU TRP PHE ILE LYS GLY SER THR ASN GLY ASN ASP LEU LEU ALA LYS ASN VAL ARG ILE TRP GLU LEU ASN GLY ARG ARG ASP PHE LEU ASP LYS ASN GLY PHE THR ASP ARG GLU GLU HIS ASP LEU GLY PRO ILE TYR GLY PHE GLN TRP ARG HIS PHE GLY ALA GLU TYR LEU ASP MET HIS ALA ASP TYR THR GLY LYS GLY ILE ASP GLN LEU ALA GLU ILE ILE ASN ARG ILE LYS THR ASN PRO ASN ASP ARG ARG LEU ILE VAL CYS SER TRP ASN VAL SER ASP LEU LYS LYS MET ALA LEU PRO PRO CYS HIS CYS PHE PHE GLN PHE TYR VAL SER ASP ASN LYS LEU SER CYS MET MET HIS GLN ARG SER CYS ASP LEU GLY LEU GLY VAL PRO PHE ASN ILE ALA SER TYR SER ILE LEU THR ALA MET VAL ALA GLN VAL CYS GLY LEU GLY LEU GLY GLU PHE VAL HIS ASN LEU ALA ASP ALA HIS ILE TYR VAL ASP HIS VAL ASP ALA VAL THR THR GLN ILE ALA ARG ILE PRO HIS PRO PHE PRO ARG LEU ARG LEU ASN PRO ASP ILE ARG ASN ILE GLU ASP PHE THR ILE ASP ASP ILE VAL VAL GLU ASP TYR VAL SER HIS PRO PRO ILE PRO MET ALA MET SER ALA\n",
      "predict: MET SER ASN SER TYR GLU GLY CYS GLY ASP LEU THR ILE PHE VAL ALA VAL ALA LEU ASN LYS VAL ILE GLY HIS LYS ASN GLN ILE PRO TRP PRO HIS ILE THR HIS ASP PHE ARG PHE LEU ARG ASN GLY THR THR TYR ILE PRO PRO GLU VAL LEU SER LYS ASN PRO ASP ILE GLN ASN VAL VAL ILE PHE GLY ARG LYS THR TYR GLU SER ILE PRO LYS ALA SER LEU PRO LEU LYS ASN ARG ILE ASN VAL ILE LEU SER ARG THR VAL LYS GLU VAL PRO GLY CYS LEU VAL TYR GLU ASP LEU SER THR ALA ILE ARG ASP LEU ARG ALA ASN VAL PRO HIS ASN LYS ILE PHE ILE LEU GLY GLY SER PHE LEU []\n",
      "\n",
      "input  : PRO ARG GLU VAL LEU THR GLY GLY HIS SER VAL SER ALA PRO GLN GLU ASN ARG ILE TYR VAL MET ASP SER VAL PHE MET HIS LEU THR GLU SER ARG VAL HIS VAL TYR ASP TYR THR ASN GLY LYS PHE LEU GLY MET VAL PRO THR ALA PHE ASN GLY HIS VAL GLN VAL SER ASN ASP GLY LYS LYS ILE TYR THR MET THR THR TYR HIS GLU ARG ILE THR ARG GLY LYS ARG SER ASP VAL VAL GLU VAL TRP ASP ALA ASP LYS LEU THR PHE GLU LYS GLU ILE SER LEU PRO PRO LYS ARG VAL GLN GLY LEU ASN TYR ASP GLY LEU PHE ARG GLN THR THR ASP GLY LYS PHE ILE VAL LEU GLN ASN ALA SER PRO ALA THR SER ILE GLY ILE VAL ASP VAL ALA LYS GLY ASP TYR VAL GLU ASP VAL THR ALA ALA ALA GLY CYS TRP SER VAL ILE PRO GLN PRO ASN ARG PRO ARG SER PHE MET THR ILE CYS GLY ASP GLY GLY LEU LEU THR ILE ASN LEU GLY GLU ASP GLY LYS VAL ALA SER GLN SER ARG SER LYS GLN MET PHE SER VAL LYS ASP ASP PRO ILE PHE ILE ALA PRO ALA LEU ASP LYS ASP LYS ALA HIS PHE VAL SER TYR TYR GLY ASN VAL TYR SER ALA ASP PHE SER GLY ASP GLU VAL LYS VAL ASP GLY PRO TRP SER LEU LEU ASN ASP GLU ASP LYS ALA LYS ASN TRP VAL PRO GLY GLY TYR ASN LEU VAL GLY LEU HIS ARG ALA SER GLY ARG MET TYR VAL PHE MET HIS PRO ASP GLY LYS GLU GLY THR HIS LYS PHE PRO ALA ALA GLU ILE TRP VAL MET ASP THR LYS THR LYS GLN ARG VAL ALA ARG ILE PRO GLY ARG ASP ALA LEU SER MET THR ILE ASP GLN GLN ARG ASN LEU MET LEU THR LEU ASP GLY GLY ASN VAL ASN VAL TYR ASP ILE SER GLN PRO GLU PRO LYS LEU LEU ARG THR ILE GLU GLY ALA ALA GLU ALA SER LEU GLN VAL GLN PHE HIS PRO VAL GLY GLY THR\n",
      "predict: PRO ARG GLU VAL LEU THR GLY GLY HIS SER VAL SER ALA PRO GLN GLU ASN ARG ILE TYR VAL MET ASP SER VAL PHE MET HIS LEU THR GLU SER ARG VAL HIS VAL TYR ASP TYR THR ASN GLY LYS PHE LEU GLY MET VAL PRO THR ALA PHE ASN GLY HIS VAL GLN VAL SER ASN ASP GLY LYS LYS ILE TYR THR MET THR THR TYR HIS GLU ARG ILE THR ARG GLY LYS ARG SER ASP VAL VAL GLU VAL TRP ASP ALA ASP LYS LEU THR PHE GLU LYS GLU ILE SER LEU PRO PRO LYS ARG VAL GLN GLY LEU ASN TYR ASP GLY LEU PHE ARG GLN THR THR ASP GLY LYS PHE ILE VAL LEU GLN ASN ALA []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m = Inference(args.model_dir,\n",
    "                  args.arch,\n",
    "                  embed_size=args.embed_size,\n",
    "                  hidden_size=args.hidden_size,\n",
    "                  dropout=args.dropout,\n",
    "                  max_length=args.max_length\n",
    "                  )\n",
    "'''\n",
    "inputs = [\n",
    "    'MET LYS LYS LEU GLN ILE ALA VAL GLY ILE ILE ARG ASN GLU ASN ASN GLU ILE PHE ILE THR ARG ARG ALA ALA ASP ALA HIS MET ALA ASN LYS LEU GLU PHE PRO GLY GLY LYS ILE GLU MET GLY GLU THR PRO GLU GLN ALA VAL VAL ARG GLU LEU GLN GLU GLU VAL GLY ILE THR PRO GLN HIS PHE SER LEU PHE GLU LYS LEU GLU TYR GLU PHE PRO ASP ARG HIS ILE THR LEU TRP PHE TRP LEU VAL GLU ARG TRP GLU GLY GLU PRO TRP GLY LYS GLU GLY GLN PRO GLY GLU TRP MET SER LEU VAL GLY LEU ASN ALA ASP ASP PHE PRO PRO ALA ASN GLU PRO VAL ILE ALA LYS LEU LYS ARG LEU',\n",
    "    'ASP ALA ILE ALA ASP ALA SER LYS ARG PHE SER ASP ALA THR TYR PRO ILE ALA GLU LYS PHE ASP TRP GLY GLY SER SER ALA ILE ALA LYS TYR ILE ALA ASP ALA SER ALA GLY ASN PRO ARG GLN ALA ALA LEU ALA VAL GLU LYS LEU LEU GLU VAL GLY LEU THR MET ASP PRO LYS LEU VAL ARG ALA ALA VAL GLU ALA HIS SER LYS ALA LEU ASP SER ALA LYS LYS ASN ALA LYS LEU MET ALA SER LYS GLU ASP PHE ALA ALA VAL ASN GLU ALA LEU ALA ARG MET ILE ALA SER ALA ASP LYS GLN LYS PHE ALA ALA LEU ARG THR ALA PHE PRO GLU SER ARG GLU LEU GLN GLY LYS LEU PHE ALA GLY ASN ASN ALA PHE GLU ALA GLU LYS ALA TYR ASP SER PHE LYS ALA LEU THR SER ALA VAL ARG ASP ALA SER ILE ASN GLY ALA LYS ALA PRO VAL ILE ALA GLU ALA ALA ARG ALA GLU ARG TYR VAL GLY ASP GLY PRO VAL GLY ARG ALA ALA LYS LYS PHE SER GLU ALA THR TYR PRO ILE MET ASP LYS LEU ASP TRP GLY LYS SER PRO GLU ILE SER LYS TYR ILE GLU THR ALA SER ALA LYS ASN PRO LYS MET MET ALA ASP GLY ILE ASP LYS THR LEU GLU VAL ALA LEU THR MET ASN GLN ASN ALA ILE ASN ASP ALA VAL PHE ALA HIS VAL ARG ALA ILE LYS GLY ALA LEU ASN THR PRO GLY LEU VAL ALA GLU ARG ASP ASP PHE ALA ARG VAL ASN LEU ALA LEU ALA LYS MET ILE ALA THR ALA ASP PRO ALA LYS PHE LYS ALA LEU LEU THR ALA PHE PRO GLY ASN ALA ASP LEU GLN MET ALA LEU PHE ALA ALA ASN ASN PRO GLU GLN ALA LYS ALA ALA TYR GLU THR PHE VAL ALA LEU THR SER ALA VAL ALA SER SER THR'\n",
    "]\n",
    "'''\n",
    "inputs = [data[i][0] for i in res[:2]]\n",
    "outputs = m.predict(inputs)\n",
    "\n",
    "for a, b in zip(inputs, outputs):\n",
    "    print('input  :', a)\n",
    "    print('predict:', b[0], b[1])\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3cd0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf5ef44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
