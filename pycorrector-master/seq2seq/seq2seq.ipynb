{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bbf3c2f",
   "metadata": {},
   "source": [
    "# install all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58213b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20cb4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b4a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fbf512",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install loguru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1c2b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2213d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypinyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42bf554",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a331e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa28e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbd9a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09782ad",
   "metadata": {},
   "source": [
    "# SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "006b3936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import operator\n",
    "from sklearn.model_selection import train_test_split\n",
    "sys.path.append('../')\n",
    "sys.path.append('../..')\n",
    "#from pycorrector.seq2seq.data_reader import *\n",
    "#from pycorrector.seq2seq.train import *\n",
    "#from pycorrector.seq2seq.infer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3ce4d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--raw_train_path\",\n",
    "                    default=\"../pycorrector/data/cn/sighan_2015/train.tsv\", type=str,\n",
    "                    help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\",\n",
    "                    )\n",
    "parser.add_argument(\"--dataset\", default=\"sighan\", type=str,\n",
    "                    help=\"Dataset name. selected in the list:\" + \", \".join([\"sighan\", \"cged\"])\n",
    "                    )\n",
    "parser.add_argument(\"--use_segment\", action=\"store_true\", help=\"Whether not to segment train data\")\n",
    "parser.add_argument(\"--do_preprocess\", action=\"store_true\", default=\"True\",help=\"Whether not to preprocess train data\")\n",
    "parser.add_argument(\"--segment_type\", default=\"char\", type=str,\n",
    "                        help=\"Segment data type, selected in list: \" + \", \".join([\"char\", \"word\"]))\n",
    "parser.add_argument(\"--model_name_or_path\",\n",
    "                    default=\"bert-base-chinese\", type=str,\n",
    "                    help=\"Path to pretrained model or model identifier from huggingface.co/models\",\n",
    "                    )\n",
    "parser.add_argument(\"--model_dir\", default=\"output/RNA/\", type=str, help=\"Dir for model save.\")\n",
    "parser.add_argument(\"--arch\", default=\"seq2seq\", type=str,\n",
    "                    help=\"The name of the task to train selected in the list: \" + \", \".join(\n",
    "                        ['seq2seq', 'convseq2seq', 'bertseq2seq']),\n",
    "                    )\n",
    "parser.add_argument(\"--train_path\", default=\"output/train.txt\", type=str, help=\"Train file after preprocess.\")\n",
    "parser.add_argument(\"--test_path\", default=\"output/test.txt\", type=str, help=\"Test file after preprocess.\")\n",
    "parser.add_argument(\"--max_length\", default=500, type=int,\n",
    "                    help=\"The maximum total input sequence length after tokenization. \\n\"\n",
    "                            \"Sequences longer than this will be truncated, sequences shorter padded.\",\n",
    "                    )\n",
    "parser.add_argument(\"--batch_size\", default=32, type=int, help=\"Batch size.\")\n",
    "parser.add_argument(\"--embed_size\", default=128, type=int, help=\"Embedding size.\")\n",
    "parser.add_argument(\"--hidden_size\", default=128, type=int, help=\"Hidden size.\")\n",
    "parser.add_argument(\"--dropout\", default=0.25, type=float, help=\"Dropout rate.\")\n",
    "parser.add_argument(\"--epochs\", default=100, type=int, help=\"Epoch num.\")\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35b7943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c12f7f89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_data_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20788/786070335.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_data_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../pycorrector/data/RNA/train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_segment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msegment_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'get_data_file' is not defined"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "data_list.extend(get_data_file(\"../pycorrector/data/RNA/train\", args.use_segment, args.segment_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857de9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe792394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76f95f03",
   "metadata": {},
   "source": [
    "# preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "497f6463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data_list from path\n",
    "def get_data_file(path, use_segment, segment_type):\n",
    "    '''\n",
    "        params: (str,bool, str) -> list(list(str,str))\n",
    "        pupose: get data_list from path\n",
    "    '''\n",
    "    data_list = []\n",
    "    if not os.path.exists(path):\n",
    "        print('%s not exists' % path)\n",
    "        return data_list\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            parts = line.split(\"\\t\")\n",
    "            if len(parts) != 2:\n",
    "                continue\n",
    "            source = ' '.join(segment(parts[0].strip(), cut_type=segment_type)) if use_segment else parts[0].strip()\n",
    "            target = ' '.join(segment(parts[1].strip(), cut_type=segment_type)) if use_segment else parts[1].strip()\n",
    "\n",
    "            pair = [source, target]\n",
    "            if pair not in data_list:\n",
    "                data_list.append(pair)\n",
    "    return data_list\n",
    "\n",
    "\n",
    "def _save_data(data_list, data_path):\n",
    "    '''\n",
    "        params: (list(list(str)), str) -> empty\n",
    "        purpose: save data_list to data_path\n",
    "    '''\n",
    "    dirname = os.path.dirname(data_path)\n",
    "    os.makedirs(dirname, exist_ok=True)\n",
    "    with open(data_path, 'w', encoding='utf-8') as f:\n",
    "        count = 0\n",
    "        for src, dst in data_list:\n",
    "            f.write(src + '\\t' + dst + '\\n')\n",
    "            count += 1\n",
    "        print(\"save line size:%d to %s\" % (count, data_path))\n",
    "\n",
    "\n",
    "def save_corpus_data(data_list, train_data_path, test_data_path):\n",
    "    '''\n",
    "        params: (list(list(str)), str, str) -> empty\n",
    "        purpose: split the data_list to train and test and then save to train_data_path and test_data_path\n",
    "    '''\n",
    "    train_lst, test_lst = train_test_split(data_list, test_size=0.1)\n",
    "    _save_data(train_lst, train_data_path)\n",
    "    _save_data(test_lst, test_data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e086b810",
   "metadata": {},
   "source": [
    "# data_reader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7611ef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants associated with the usual special tokens.\n",
    "SOS_TOKEN = '<sos>' # represent the start of a sequence\n",
    "EOS_TOKEN = '<eos>' # represent the end of a sequence\n",
    "UNK_TOKEN = '<unk>' # unknown token -  is used to replace the rare words that did not fit in your vocabulary.\n",
    "PAD_TOKEN = '<pad>' # all the sentence in a batch should have the same length, it will be used to pad the sequence to fit the length\n",
    "class CscDataset(object):\n",
    "    '''\n",
    "        purpose: a dataset class that load the data from a json file and return the data_list\n",
    "    '''\n",
    "    def __init__(self, file_path):\n",
    "        self.data = json.load(open(file_path, 'r', encoding='utf-8'))\n",
    "\n",
    "    def load(self):\n",
    "        '''\n",
    "            params: empty -> list(str)\n",
    "        '''\n",
    "        data_list = []\n",
    "        for item in self.data:\n",
    "            data_list.append(item['original_text'] + '\\t' + item['correct_text'])\n",
    "        return data_list\n",
    "\n",
    "def create_dataset(path, num_examples=None, split_on_space=False):\n",
    "    '''\n",
    "        params: str, int, bool -> list(list(list(str),list(str)))\n",
    "        purpose: generate datalist from path to list of tokens\n",
    "    '''\n",
    "    if path.endswith('.json'):\n",
    "        d = CscDataset(path)\n",
    "        lines = d.load()\n",
    "    else:\n",
    "        lines = open(path, 'r', encoding='utf-8').read().strip().split('\\n')\n",
    "    word_pairs = [[preprocess_sentence(s, split_on_space) for s in l.split('\\t')] for l in lines[:num_examples]]\n",
    "    return zip(*word_pairs)\n",
    "\n",
    "\n",
    "def preprocess_sentence(sentence, split_on_space=False):\n",
    "    '''\n",
    "        purpose: give a sentence, slipt the string into tokens \n",
    "    '''\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    return [SOS_TOKEN] + (sentence.split() if split_on_space else list(sentence)) + [EOS_TOKEN]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aab244fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "'''\n",
    "class Counter(object):\n",
    "    def __init__(self):\n",
    "        self.counter = {}\n",
    "    def update(self, token):\n",
    "'''    \n",
    "\n",
    "\n",
    "def save_word_dict(dict_data, save_path):\n",
    "    '''\n",
    "        purpose: save the dict_data to save_path\n",
    "    '''\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        for k, v in dict_data.items():\n",
    "            f.write(\"%s\\t%d\\n\" % (k, v))\n",
    "\n",
    "\n",
    "def load_word_dict(save_path):\n",
    "    '''\n",
    "        purpose: load the word_dict from save_path and return\n",
    "    '''\n",
    "    dict_data = dict()\n",
    "    num = 0\n",
    "    with open(save_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip('\\n')\n",
    "            items = line.split('\\t')\n",
    "            num += 1\n",
    "            try:\n",
    "                dict_data[items[0]] = int(items[1])\n",
    "            except IndexError:\n",
    "                logger.error('IndexError, index:%s, line:%s' % (num, line))\n",
    "    return dict_data\n",
    "def read_vocab(input_texts, max_size=None, min_count=0):\n",
    "    '''\n",
    "        purpose: count the number of each vocabs and return the vocab2id dict\n",
    "    '''\n",
    "    token_counts = Counter()\n",
    "    special_tokens = [PAD_TOKEN, UNK_TOKEN, SOS_TOKEN, EOS_TOKEN]\n",
    "\n",
    "    for texts in input_texts:\n",
    "        #for token in texts:\n",
    "        token_counts.update(texts)\n",
    "    del token_counts[SOS_TOKEN]\n",
    "    del token_counts[EOS_TOKEN]\n",
    "    # Sort word count by value\n",
    "    count_pairs = token_counts.most_common()\n",
    "    vocab = [k for k, v in count_pairs if v >= min_count]\n",
    "    # Insert the special tokens to the beginning\n",
    "    vocab[0:0] = special_tokens\n",
    "    full_token_id = list(zip(vocab, range(len(vocab))))[:max_size]\n",
    "    vocab2id = dict(full_token_id)\n",
    "    return vocab2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8e0ec58",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12416/2234142552.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msrc_vocab_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vocab_source.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msource_texts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_texts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_on_space\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msrc_2_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_texts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msave_word_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_2_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_vocab_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "src_vocab_path = os.path.join(args.model_dir, 'vocab_source.txt')\n",
    "\n",
    "source_texts, target_texts = create_dataset(args.train_path, split_on_space=True)\n",
    "src_2_ids = read_vocab(source_texts)\n",
    "save_word_dict(src_2_ids, src_vocab_path)\n",
    "\n",
    "src_2_ids = load_word_dict(src_vocab_path)\n",
    "src_2_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04dc4dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(seqs, max_length=None):\n",
    "    if max_length:\n",
    "        seqs = [seq[:max_length] for seq in seqs]\n",
    "    lengths = [len(seq) for seq in seqs]\n",
    "    n_samples = len(seqs)\n",
    "    max_len = np.max(lengths)\n",
    "\n",
    "    x = np.zeros((n_samples, max_len)).astype('int32')\n",
    "    x_lengths = np.array(lengths).astype(\"int32\")\n",
    "    for idx, seq in enumerate(seqs):\n",
    "        x[idx, :lengths[idx]] = seq\n",
    "    return x, x_lengths  # x_mask\n",
    "def get_minibatches(n, minibatch_size, shuffle=True):\n",
    "    idx_list = np.arange(0, n, minibatch_size)  # [0, 1, ..., n-1]\n",
    "    if shuffle:\n",
    "        np.random.shuffle(idx_list)\n",
    "    minibatches = []\n",
    "    for idx in idx_list:\n",
    "        minibatches.append(np.arange(idx, min(idx + minibatch_size, n)))\n",
    "    return minibatches\n",
    "def gen_examples(src_sentences, trg_sentences, batch_size, max_length=None):\n",
    "    minibatches = get_minibatches(len(src_sentences), batch_size)\n",
    "    examples = []\n",
    "    for minibatch in minibatches:\n",
    "        mb_src_sentences = [src_sentences[t] for t in minibatch]\n",
    "        mb_trg_sentences = [trg_sentences[t] for t in minibatch]\n",
    "        mb_x, mb_x_len = prepare_data(mb_src_sentences, max_length)\n",
    "        mb_y, mb_y_len = prepare_data(mb_trg_sentences, max_length)\n",
    "        examples.append((mb_x, mb_x_len, mb_y, mb_y_len))\n",
    "    return examples\n",
    "def one_hot(src_sentences, trg_sentences, src_dict, trg_dict, sort_by_len=True):\n",
    "    \"\"\"vector the sequences.\n",
    "    \"\"\"\n",
    "\n",
    "    out_src_sentences = [[src_dict.get(w, 0) for w in sent] for sent in src_sentences]\n",
    "    out_trg_sentences = [[trg_dict.get(w, 0) for w in sent] for sent in trg_sentences]\n",
    "\n",
    "    # sort sentences by english lengths\n",
    "    def len_argsort(seq):\n",
    "        return sorted(range(len(seq)), key=lambda x: len(seq[x]))\n",
    "\n",
    "    # sort length\n",
    "    if sort_by_len:\n",
    "        sorted_index = len_argsort(out_src_sentences)\n",
    "        out_src_sentences = [out_src_sentences[i] for i in sorted_index]\n",
    "        out_trg_sentences = [out_trg_sentences[i] for i in sorted_index]\n",
    "\n",
    "    return out_src_sentences, out_trg_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d8d5ff",
   "metadata": {},
   "source": [
    "# seq2se2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d076ddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author:XuMing(xuming624@qq.com)\n",
    "@description: \n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, enc_hidden_size, dec_hidden_size, dropout=0.2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        '''\n",
    "            torch.nn.Embedding(numembeddings, embeddingdim)\n",
    "                * numembeddings代表一共有多少个词\n",
    "                * embedding_dim代表每个词创建一个多少维的向量来表示他\n",
    "        '''\n",
    "        self.rnn = nn.GRU(embed_size, enc_hidden_size, batch_first=True, bidirectional=True)\n",
    "        '''\n",
    "            torch.nn.GRU(input_size, hidden_size, num_layers, bias,batch_first,dropout,bidirectional)\n",
    "                * input_size: the number of expected features in the input x\n",
    "                * hidden_size: the number of features in the hidden state h\n",
    "                * batch_first: if True, then (batch, seq, feature), else (seq, batch, feature)\n",
    "                * bidirectional: if True, becomes a bidirectional GRU. Default: False\n",
    "            \n",
    "        '''\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(enc_hidden_size * 2, dec_hidden_size)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # 将x根据长度来排序\n",
    "        sorted_len, sorted_idx = lengths.sort(0, descending=True)\n",
    "        x_sorted = x[sorted_idx.long()]\n",
    "        embedded = self.dropout(self.embed(x_sorted))\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, sorted_len.long().cpu().data.numpy(),\n",
    "                                                            batch_first=True)\n",
    "        '''\n",
    "            https://zhuanlan.zhihu.com/p/34418001\n",
    "            torch.nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=False,enforce_sorted=True)\n",
    "            当我们进行batch个训练数据一起计算的时候，我们会遇到多个训练样例长度不同时的情况，这样我们就会很自然的进行padding，\n",
    "            将短句子padding为跟最长的句子一样\n",
    "            \n",
    "            pytorch中RNN处理变长padding主要用torch.nn.utils.rnn.pack_padded_sequence()以及torch.nn.utils.rnn.pad_packed_sequence()来进行。\n",
    "            \n",
    "            \n",
    "            \n",
    "        '''\n",
    "        packed_out, hid = self.rnn(packed_embedded)\n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)\n",
    "        _, original_idx = sorted_idx.sort(0, descending=False)\n",
    "        out = out[original_idx.long()].contiguous()\n",
    "        hid = hid[:, original_idx.long()].contiguous()\n",
    "\n",
    "        hid = torch.cat([hid[-2], hid[-1]], dim=1)\n",
    "        hid = torch.tanh(self.fc(hid)).unsqueeze(0)\n",
    "\n",
    "        return out, hid\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    Luong Attention,根据context vectors和当前的输出hidden states，计算输出\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, enc_hidden_size, dec_hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.enc_hidden_size = enc_hidden_size\n",
    "        self.dec_hidden_size = dec_hidden_size\n",
    "\n",
    "        self.linear_in = nn.Linear(enc_hidden_size * 2, dec_hidden_size, bias=False)\n",
    "        self.linear_out = nn.Linear(enc_hidden_size * 2 + dec_hidden_size, dec_hidden_size)\n",
    "\n",
    "    def forward(self, output, context, mask):\n",
    "        # output: batch_size, output_len, dec_hidden_size\n",
    "        # context: batch_size, context_len, 2*enc_hidden_size\n",
    "\n",
    "        batch_size = output.size(0)\n",
    "        output_len = output.size(1)\n",
    "        input_len = context.size(1)\n",
    "\n",
    "        context_in = self.linear_in(context.view(batch_size * input_len, -1)).view(\n",
    "            batch_size, input_len, -1)  # batch_size, context_len, dec_hidden_size\n",
    "\n",
    "        # context_in.transpose(1,2): batch_size, dec_hidden_size, context_len\n",
    "        # output: batch_size, output_len, dec_hidden_size\n",
    "        attn = torch.bmm(output, context_in.transpose(1, 2))\n",
    "        # batch_size, output_len, context_len\n",
    "\n",
    "        attn.data.masked_fill(mask, -1e6)\n",
    "\n",
    "        attn = F.softmax(attn, dim=2)\n",
    "        # batch_size, output_len, context_len\n",
    "\n",
    "        context = torch.bmm(attn, context)\n",
    "        # batch_size, output_len, enc_hidden_size\n",
    "\n",
    "        output = torch.cat((context, output), dim=2)  # batch_size, output_len, hidden_size*2\n",
    "\n",
    "        output = output.view(batch_size * output_len, -1)\n",
    "        output = torch.tanh(self.linear_out(output))\n",
    "        output = output.view(batch_size, output_len, -1)\n",
    "        return output, attn\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    decoder会根据已经翻译的句子内容，和context vectors，来决定下一个输出的单词\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embed_size, enc_hidden_size, dec_hidden_size, dropout=0.2):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.attention = Attention(enc_hidden_size, dec_hidden_size)\n",
    "        self.rnn = nn.GRU(embed_size, enc_hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(dec_hidden_size, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def create_mask(self, x_len, y_len):\n",
    "        # a mask of shape x_len * y_len\n",
    "        max_x_len = x_len.max()\n",
    "        max_y_len = y_len.max()\n",
    "        x_mask = torch.arange(max_x_len, device=x_len.device)[None, :] < x_len[:, None]\n",
    "        y_mask = torch.arange(max_y_len, device=x_len.device)[None, :] < y_len[:, None]\n",
    "        mask = ~ x_mask[:, :, None] * y_mask[:, None, :]\n",
    "        return mask\n",
    "\n",
    "    def forward(self, ctx, ctx_lengths, y, y_lengths, hid):\n",
    "        sorted_len, sorted_idx = y_lengths.sort(0, descending=True)\n",
    "        y_sorted = y[sorted_idx.long()]\n",
    "        hid = hid[:, sorted_idx.long()]\n",
    "\n",
    "        y_sorted = self.dropout(self.embed(y_sorted))  # batch_size, output_length, embed_size\n",
    "\n",
    "        packed_seq = nn.utils.rnn.pack_padded_sequence(y_sorted, sorted_len.long().cpu().data.numpy(), batch_first=True)\n",
    "        out, hid = self.rnn(packed_seq, hid)\n",
    "        unpacked, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
    "        _, original_idx = sorted_idx.sort(0, descending=False)\n",
    "        output_seq = unpacked[original_idx.long()].contiguous()\n",
    "        hid = hid[:, original_idx.long()].contiguous()\n",
    "\n",
    "        mask = self.create_mask(y_lengths, ctx_lengths)\n",
    "\n",
    "        output, attn = self.attention(output_seq, ctx, mask)\n",
    "        output = F.log_softmax(self.out(output), -1)\n",
    "\n",
    "        return output, hid, attn\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    \"\"\"\n",
    "    Seq2Seq, 最后我们构建Seq2Seq模型把encoder, attention, decoder串到一起\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 encoder_vocab_size,\n",
    "                 decoder_vocab_size,\n",
    "                 embed_size,\n",
    "                 enc_hidden_size,\n",
    "                 dec_hidden_size,\n",
    "                 dropout,\n",
    "                 ):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = Encoder(vocab_size=encoder_vocab_size,\n",
    "                               embed_size=embed_size,\n",
    "                               enc_hidden_size=enc_hidden_size,\n",
    "                               dec_hidden_size=dec_hidden_size,\n",
    "                               dropout=dropout)\n",
    "        self.decoder = Decoder(vocab_size=decoder_vocab_size,  # len(trg_2_ids),\n",
    "                               embed_size=embed_size,\n",
    "                               enc_hidden_size=enc_hidden_size,\n",
    "                               dec_hidden_size=dec_hidden_size,\n",
    "                               dropout=dropout)\n",
    "\n",
    "    def forward(self, x, x_lengths, y, y_lengths):\n",
    "        encoder_out, hid = self.encoder(x, x_lengths)\n",
    "        output, hid, attn = self.decoder(ctx=encoder_out,\n",
    "                                         ctx_lengths=x_lengths,\n",
    "                                         y=y,\n",
    "                                         y_lengths=y_lengths,\n",
    "                                         hid=hid)\n",
    "        return output, attn\n",
    "\n",
    "    def translate(self, x, x_lengths, y, max_length=128):\n",
    "        print(len(x))\n",
    "        encoder_out, hid = self.encoder(x, x_lengths)\n",
    "        preds = []\n",
    "        batch_size = x.shape[0]\n",
    "        attns = []\n",
    "        for i in range(max_length):\n",
    "            output, hid, attn = self.decoder(ctx=encoder_out,\n",
    "                                             ctx_lengths=x_lengths,\n",
    "                                             y=y,\n",
    "                                             y_lengths=torch.ones(batch_size).long().to(y.device),\n",
    "                                             hid=hid)\n",
    "            \n",
    "            y = output.max(2)[1].view(batch_size, 1)\n",
    "            preds.append(y)\n",
    "            \n",
    "            attns.append(attn)\n",
    "        return torch.cat(preds, 1), torch.cat(attns, 1)\n",
    "\n",
    "\n",
    "class LanguageModelCriterion(nn.Module):\n",
    "    \"\"\"\n",
    "    masked cross entropy loss\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LanguageModelCriterion, self).__init__()\n",
    "\n",
    "    def forward(self, input, target, mask):\n",
    "        # input: (batch_size * seq_len) * vocab_size\n",
    "        input = input.contiguous().view(-1, input.size(2))\n",
    "        # target: batch_size * 1\n",
    "        target = target.contiguous().view(-1, 1)\n",
    "        mask = mask.contiguous().view(-1, 1)\n",
    "        output = -input.gather(1, target) * mask\n",
    "        output = torch.sum(output) / torch.sum(mask)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2057f58c",
   "metadata": {},
   "source": [
    "# infer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "249d787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_tokens = [' ', '“', '”', '‘', '’', '琊', '\\n', '…', '—', '擤', '\\t', '֍', '玕', '', '《', '》']\n",
    "\n",
    "\n",
    "def get_errors(corrected_text, origin_text):\n",
    "    \n",
    "    corrected_lst = corrected_text.split()\n",
    "    origin_lst = origin_text.split()\n",
    "    sub_details = []\n",
    "    for i, ori_token in enumerate(origin_lst):\n",
    "        if i >= len(corrected_lst):\n",
    "            continue\n",
    "        if ori_token != corrected_lst[i]:\n",
    "            sub_details.append((ori_token, corrected_lst[i],i,i+1))\n",
    "    return corrected_text, sub_details\n",
    "    \n",
    "    '''\n",
    "    print(corrected_text)\n",
    "    print(origin_text)\n",
    "    sub_details = []\n",
    "    for i, ori_char in enumerate(origin_text):\n",
    "        if i >= len(corrected_text):\n",
    "            continue\n",
    "        if ori_char in unk_tokens:\n",
    "            # deal with unk word\n",
    "            corrected_text = corrected_text[:i] + ori_char + corrected_text[i:]\n",
    "            continue\n",
    "        if ori_char != corrected_text[i]:\n",
    "            sub_details.append((ori_char, corrected_text[i], i, i + 1))\n",
    "    sub_details = sorted(sub_details, key=operator.itemgetter(2))\n",
    "    return corrected_text, sub_details\n",
    "    '''\n",
    "\n",
    "class Inference(object):\n",
    "    def __init__(self, model_dir, arch='convseq2seq',\n",
    "                 embed_size=128, hidden_size=128, dropout=0.25, max_length=500):\n",
    "        logger.debug(\"Device: {}\".format(device))\n",
    "        logger.debug(f'Use {arch} model.')\n",
    "        if arch in ['seq2seq', 'convseq2seq']:\n",
    "            src_vocab_path = os.path.join(model_dir, 'vocab_source.txt')\n",
    "            trg_vocab_path = os.path.join(model_dir, 'vocab_target.txt')\n",
    "            self.src_2_ids = load_word_dict(src_vocab_path)\n",
    "            self.trg_2_ids = load_word_dict(trg_vocab_path)\n",
    "            self.id_2_trgs = {v: k for k, v in self.trg_2_ids.items()}\n",
    "            if arch == 'seq2seq':\n",
    "                self.model = Seq2Seq(encoder_vocab_size=len(self.src_2_ids),\n",
    "                                     decoder_vocab_size=len(self.trg_2_ids),\n",
    "                                     embed_size=embed_size,\n",
    "                                     enc_hidden_size=hidden_size,\n",
    "                                     dec_hidden_size=hidden_size,\n",
    "                                     dropout=dropout).to(device)\n",
    "                model_path = os.path.join(model_dir, 'seq2seq.pth')\n",
    "                logger.debug('Load model from {}'.format(model_path))\n",
    "                self.model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "                self.model.eval()\n",
    "            else:\n",
    "                trg_pad_idx = self.trg_2_ids[PAD_TOKEN]\n",
    "                self.model = ConvSeq2Seq(encoder_vocab_size=len(self.src_2_ids),\n",
    "                                         decoder_vocab_size=len(self.trg_2_ids),\n",
    "                                         embed_size=embed_size,\n",
    "                                         enc_hidden_size=hidden_size,\n",
    "                                         dec_hidden_size=hidden_size,\n",
    "                                         dropout=dropout,\n",
    "                                         trg_pad_idx=trg_pad_idx,\n",
    "                                         device=device,\n",
    "                                         max_length=max_length).to(device)\n",
    "                model_path = os.path.join(model_dir, 'convseq2seq.pth')\n",
    "                self.model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "                logger.debug('Load model from {}'.format(model_path))\n",
    "                self.model.eval()\n",
    "        elif arch == 'bertseq2seq':\n",
    "            # Bert Seq2seq model\n",
    "            use_cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "            # encoder_type=None, encoder_name=None, decoder_name=None\n",
    "            self.model = Seq2SeqModel(\"bert\", \"{}/encoder\".format(model_dir),\n",
    "                                      \"{}/decoder\".format(model_dir), use_cuda=use_cuda)\n",
    "        else:\n",
    "            logger.error('error arch: {}'.format(arch))\n",
    "            raise ValueError(\"Model arch choose error. Must use one of seq2seq model.\")\n",
    "        self.arch = arch\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def predict(self, sentence_list):\n",
    "        result = []\n",
    "        if self.arch in ['seq2seq', 'convseq2seq']:\n",
    "            for query in sentence_list:\n",
    "                out = []\n",
    "                tokens = query.split()\n",
    "                tokens = [SOS_TOKEN] + tokens + [EOS_TOKEN]\n",
    "                src_ids = [self.src_2_ids[i] for i in tokens if i in self.src_2_ids]\n",
    "\n",
    "                sos_idx = self.trg_2_ids[SOS_TOKEN]\n",
    "                if self.arch == 'seq2seq':\n",
    "                    src_tensor = torch.from_numpy(np.array(src_ids).reshape(1, -1)).long().to(device)\n",
    "                    src_tensor_len = torch.from_numpy(np.array([len(src_ids)])).long().to(device)\n",
    "                    sos_tensor = torch.Tensor([[self.trg_2_ids[SOS_TOKEN]]]).long().to(device)\n",
    "                    translation, attn = self.model.translate(src_tensor, src_tensor_len, sos_tensor, self.max_length)\n",
    "                    translation = [self.id_2_trgs[i] for i in translation.data.cpu().numpy().reshape(-1) if\n",
    "                                   i in self.id_2_trgs]\n",
    "                else:\n",
    "                    src_tensor = torch.from_numpy(np.array(src_ids).reshape(1, -1)).long().to(device)\n",
    "                    translation, attn = self.model.translate(src_tensor, sos_idx)\n",
    "                    translation = [self.id_2_trgs[i] for i in translation if i in self.id_2_trgs]\n",
    "                for word in translation:\n",
    "                    if word != EOS_TOKEN:\n",
    "                        out.append(word)\n",
    "                    else:\n",
    "                        break\n",
    "                corrected_text = ' '.join(out) # 已修改\n",
    "                corrected_text, sub_details = get_errors(corrected_text, query)\n",
    "                result.append([corrected_text, sub_details])\n",
    "        else:\n",
    "            corrected_sents = self.model.predict(sentence_list)\n",
    "            corrected_sents = [i.replace(' ', '') for i in corrected_sents]\n",
    "            for c, s in zip(corrected_sents, sentence_list):\n",
    "                c = c.replace(' ', '')\n",
    "                c, sub_details = get_errors(c, s)\n",
    "                result.append([c, sub_details])\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ea9c26",
   "metadata": {},
   "source": [
    "# train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88377ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_seq2seq_model(model, data, device, loss_fn):\n",
    "    model.eval()\n",
    "    total_num_words = 0.\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for it, (mb_x, mb_x_len, mb_y, mb_y_len) in enumerate(data):\n",
    "            mb_x = torch.from_numpy(mb_x).to(device).long()\n",
    "            mb_x_len = torch.from_numpy(mb_x_len).to(device).long()\n",
    "            mb_input = torch.from_numpy(mb_y[:, :-1]).to(device).long()\n",
    "            mb_output = torch.from_numpy(mb_y[:, 1:]).to(device).long()\n",
    "            mb_y_len = torch.from_numpy(mb_y_len - 1).to(device).long()\n",
    "            mb_y_len[mb_y_len <= 0] = 1\n",
    "\n",
    "            mb_pred, attn = model(mb_x, mb_x_len, mb_input, mb_y_len)\n",
    "\n",
    "            mb_out_mask = torch.arange(mb_y_len.max().item(), device=device)[None, :] < mb_y_len[:, None]\n",
    "            mb_out_mask = mb_out_mask.float()\n",
    "\n",
    "            loss = loss_fn(mb_pred, mb_output, mb_out_mask)\n",
    "\n",
    "            num_words = torch.sum(mb_y_len).item()\n",
    "            total_loss += loss.item() * num_words\n",
    "            total_num_words += num_words\n",
    "    loss = total_loss / total_num_words\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_seq2seq_model(model, train_data, device, loss_fn, optimizer, model_dir, epochs=20):\n",
    "    best_loss = 1e3\n",
    "    train_data, dev_data = train_test_split(train_data, test_size=0.1, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_num_words = 0.\n",
    "        total_loss = 0.\n",
    "        for it, (mb_x, mb_x_len, mb_y, mb_y_len) in enumerate(train_data):\n",
    "            mb_x = torch.from_numpy(mb_x).to(device).long()\n",
    "            mb_x_len = torch.from_numpy(mb_x_len).to(device).long()\n",
    "            mb_input = torch.from_numpy(mb_y[:, :-1]).to(device).long()\n",
    "            mb_output = torch.from_numpy(mb_y[:, 1:]).to(device).long()\n",
    "            mb_y_len = torch.from_numpy(mb_y_len - 1).to(device).long()\n",
    "            mb_y_len[mb_y_len <= 0] = 1\n",
    "\n",
    "            mb_pred, attn = model(mb_x, mb_x_len, mb_input, mb_y_len)\n",
    "\n",
    "            mb_out_mask = torch.arange(mb_y_len.max().item(), device=device)[None, :] < mb_y_len[:, None]\n",
    "            mb_out_mask = mb_out_mask.float()\n",
    "\n",
    "            loss = loss_fn(mb_pred, mb_output, mb_out_mask)\n",
    "\n",
    "            num_words = torch.sum(mb_y_len).item()\n",
    "            total_loss += loss.item() * num_words\n",
    "            total_num_words += num_words\n",
    "\n",
    "            # update optimizer\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.)\n",
    "            optimizer.step()\n",
    "\n",
    "            if it % 100 == 0:\n",
    "                logger.info(\"Epoch :{}/{}, iteration :{}/{} loss:{:.4f}\".format(epoch, epochs, it, len(train_data),\n",
    "                                                                                loss.item()))\n",
    "        cur_loss = total_loss / total_num_words\n",
    "        logger.info(\"Epoch :{}/{}, training loss:{:.4f}\".format(epoch, epochs, cur_loss))\n",
    "        if epoch % 1 == 0:\n",
    "            if dev_data:\n",
    "                eval_loss = evaluate_seq2seq_model(model, dev_data, device, loss_fn)\n",
    "                logger.info('Epoch:{}, dev loss:{:.4f}'.format(epoch, eval_loss))\n",
    "                cur_loss = eval_loss\n",
    "            # find best model\n",
    "            is_best = cur_loss < best_loss\n",
    "            best_loss = min(cur_loss, best_loss)\n",
    "            if is_best:\n",
    "                model_path = os.path.join(model_dir, 'seq2seq.pth')\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                logger.info('Epoch:{}, save new bert model:{}'.format(epoch, model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2dd74a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(arch, train_path, batch_size, embed_size, hidden_size, dropout, epochs,\n",
    "          model_dir, max_length, use_segment, model_name_or_path):\n",
    "    logger.info(\"device: {}\".format(device))\n",
    "    arch = arch.lower()\n",
    "    logger.debug(f'use {arch} model.')\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    if arch in ['seq2seq', 'convseq2seq']:\n",
    "        src_vocab_path = os.path.join(model_dir, 'vocab_source.txt')\n",
    "        trg_vocab_path = os.path.join(model_dir, 'vocab_target.txt')\n",
    "\n",
    "        source_texts, target_texts = create_dataset(train_path, split_on_space=True)\n",
    "        logger.debug(\"source_texts:\",source_texts)\n",
    "        src_2_ids = read_vocab(source_texts)\n",
    "        trg_2_ids = read_vocab(target_texts)\n",
    "        save_word_dict(src_2_ids, src_vocab_path)\n",
    "        save_word_dict(trg_2_ids, trg_vocab_path)\n",
    "\n",
    "        src_2_ids = load_word_dict(src_vocab_path)\n",
    "        trg_2_ids = load_word_dict(trg_vocab_path)\n",
    "        id_2_srcs = {v: k for k, v in src_2_ids.items()}\n",
    "        id_2_trgs = {v: k for k, v in trg_2_ids.items()}\n",
    "        train_src, train_trg = one_hot(source_texts, target_texts, src_2_ids, trg_2_ids, sort_by_len=True)\n",
    "\n",
    "        logger.debug(f'src: {[id_2_srcs[i] for i in train_src[0]]}')\n",
    "        logger.debug(f'trg: {[id_2_trgs[i] for i in train_trg[0]]}')\n",
    "\n",
    "        train_data = gen_examples(train_src, train_trg, batch_size, max_length)\n",
    "\n",
    "        if arch == 'seq2seq':\n",
    "            # Normal seq2seq\n",
    "            model = Seq2Seq(encoder_vocab_size=len(src_2_ids),\n",
    "                            decoder_vocab_size=len(trg_2_ids),\n",
    "                            embed_size=embed_size,\n",
    "                            enc_hidden_size=hidden_size,\n",
    "                            dec_hidden_size=hidden_size,\n",
    "                            dropout=dropout).to(device)\n",
    "            logger.info(model)\n",
    "            loss_fn = LanguageModelCriterion().to(device)\n",
    "            optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "            train_seq2seq_model(model, train_data, device, loss_fn, optimizer, model_dir, epochs=epochs)\n",
    "        else:\n",
    "            # Conv seq2seq model\n",
    "            trg_pad_idx = trg_2_ids[PAD_TOKEN]\n",
    "            model = ConvSeq2Seq(encoder_vocab_size=len(src_2_ids),\n",
    "                                decoder_vocab_size=len(trg_2_ids),\n",
    "                                embed_size=embed_size,\n",
    "                                enc_hidden_size=hidden_size,\n",
    "                                dec_hidden_size=hidden_size,\n",
    "                                dropout=dropout,\n",
    "                                trg_pad_idx=trg_pad_idx,\n",
    "                                device=device,\n",
    "                                max_length=max_length).to(device)\n",
    "            logger.info(model)\n",
    "            loss_fn = nn.CrossEntropyLoss(ignore_index=trg_pad_idx)\n",
    "            optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "            train_convseq2seq_model(model, train_data, device, loss_fn, optimizer, model_dir, epochs=epochs)\n",
    "    elif arch == 'bertseq2seq':\n",
    "        # Bert Seq2seq model\n",
    "        model_args = {\n",
    "            \"reprocess_input_data\": True,\n",
    "            \"overwrite_output_dir\": True,\n",
    "            \"max_seq_length\": max_length if max_length else 128,\n",
    "            \"train_batch_size\": batch_size if batch_size else 8,\n",
    "            \"num_train_epochs\": epochs if epochs else 10,\n",
    "            \"save_eval_checkpoints\": False,\n",
    "            \"save_model_every_epoch\": False,\n",
    "            \"silent\": False,\n",
    "            \"evaluate_generated_text\": True,\n",
    "            \"evaluate_during_training\": True,\n",
    "            \"evaluate_during_training_verbose\": True,\n",
    "            \"best_model_dir\": os.path.join(model_dir, 'best_model'),\n",
    "            \"use_multiprocessing\": False,\n",
    "            \"save_best_model\": True,\n",
    "            \"max_length\": max_length if max_length else 128,  # The maximum length of the sequence to be generated.\n",
    "            \"output_dir\": model_dir if model_dir else \"./output/bertseq2seq/\",\n",
    "        }\n",
    "\n",
    "        use_cuda = True if torch.cuda.is_available() else False\n",
    "        # encoder_type=None, encoder_name=None, decoder_name=None\n",
    "        # encoder_name=\"bert-base-chinese\"\n",
    "        model = Seq2SeqModel(\"bert\", model_name_or_path, model_name_or_path, args=model_args, use_cuda=use_cuda)\n",
    "\n",
    "        logger.info('start train bertseq2seq ...')\n",
    "        data = load_bert_data(train_path, use_segment)\n",
    "        logger.info(f'load data done, data size: {len(data)}')\n",
    "        logger.debug(f'data samples: {data[:10]}')\n",
    "        train_data, dev_data = train_test_split(data, test_size=0.1, shuffle=False)\n",
    "\n",
    "        train_df = pd.DataFrame(train_data, columns=['input_text', 'target_text'])\n",
    "        dev_df = pd.DataFrame(dev_data, columns=['input_text', 'target_text'])\n",
    "\n",
    "        def count_matches(labels, preds):\n",
    "            logger.debug(f\"labels: {labels[:10]}\")\n",
    "            logger.debug(f\"preds: {preds[:10]}\")\n",
    "            match = sum([1 if label == pred else 0 for label, pred in zip(labels, preds)])\n",
    "            logger.debug(f\"match: {match}\")\n",
    "            return match\n",
    "\n",
    "        model.train_model(train_df, eval_data=dev_df, matches=count_matches)\n",
    "    else:\n",
    "        logger.error('error arch: {}'.format(arch))\n",
    "        raise ValueError(\"Model arch choose error. Must use one of seq2seq model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6793d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 14:47:55.988 | INFO     | __main__:train:3 - device: cuda\n",
      "2022-09-19 14:47:55.989 | DEBUG    | __main__:train:5 - use seq2seq model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save line size:41487 to output/train.txt\n",
      "save line size:4610 to output/test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 14:47:57.928 | DEBUG    | __main__:train:12 - source_texts:\n",
      "2022-09-19 14:48:01.305 | DEBUG    | __main__:train:24 - src: ['<sos>', 'ASN', 'GLN', '<eos>']\n",
      "2022-09-19 14:48:01.305 | DEBUG    | __main__:train:25 - trg: ['<sos>', 'ASN', 'GLN', '<eos>']\n",
      "2022-09-19 14:48:02.077 | INFO     | __main__:train:37 - Seq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (embed): Embedding(24, 128)\n",
      "    (rnn): GRU(128, 128, batch_first=True, bidirectional=True)\n",
      "    (dropout): Dropout(p=0.25, inplace=False)\n",
      "    (fc): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embed): Embedding(24, 128)\n",
      "    (attention): Attention(\n",
      "      (linear_in): Linear(in_features=256, out_features=128, bias=False)\n",
      "      (linear_out): Linear(in_features=384, out_features=128, bias=True)\n",
      "    )\n",
      "    (rnn): GRU(128, 128, batch_first=True)\n",
      "    (out): Linear(in_features=128, out_features=24, bias=True)\n",
      "    (dropout): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      ")\n",
      "2022-09-19 14:48:02.135 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :0/1167 loss:3.1817\n",
      "2022-09-19 14:48:04.957 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :100/1167 loss:0.9524\n",
      "2022-09-19 14:48:08.169 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :200/1167 loss:0.1818\n",
      "2022-09-19 14:48:11.063 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :300/1167 loss:0.1288\n",
      "2022-09-19 14:48:13.906 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :400/1167 loss:0.0867\n",
      "2022-09-19 14:48:16.771 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :500/1167 loss:0.0531\n",
      "2022-09-19 14:48:20.026 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :600/1167 loss:0.0365\n",
      "2022-09-19 14:48:23.133 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :700/1167 loss:0.0675\n",
      "2022-09-19 14:48:26.177 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :800/1167 loss:0.0514\n",
      "2022-09-19 14:48:29.050 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :900/1167 loss:0.0631\n",
      "2022-09-19 14:48:31.798 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :1000/1167 loss:0.0302\n",
      "2022-09-19 14:48:34.625 | INFO     | __main__:train_seq2seq_model:62 - Epoch :0/100, iteration :1100/1167 loss:0.0248\n",
      "2022-09-19 14:48:36.591 | INFO     | __main__:train_seq2seq_model:65 - Epoch :0/100, training loss:0.2888\n",
      "2022-09-19 14:48:37.981 | INFO     | __main__:train_seq2seq_model:69 - Epoch:0, dev loss:0.0152\n",
      "2022-09-19 14:48:37.986 | INFO     | __main__:train_seq2seq_model:77 - Epoch:0, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-19 14:48:38.000 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :0/1167 loss:0.1049\n",
      "2022-09-19 14:48:40.681 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :100/1167 loss:0.0262\n",
      "2022-09-19 14:48:43.888 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :200/1167 loss:0.0211\n",
      "2022-09-19 14:48:46.795 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :300/1167 loss:0.0199\n",
      "2022-09-19 14:48:49.648 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :400/1167 loss:0.0325\n",
      "2022-09-19 14:48:52.515 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :500/1167 loss:0.0223\n",
      "2022-09-19 14:48:55.770 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :600/1167 loss:0.0096\n",
      "2022-09-19 14:48:58.878 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :700/1167 loss:0.0243\n",
      "2022-09-19 14:49:01.927 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :800/1167 loss:0.0236\n",
      "2022-09-19 14:49:04.806 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :900/1167 loss:0.0325\n",
      "2022-09-19 14:49:07.552 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :1000/1167 loss:0.0161\n",
      "2022-09-19 14:49:10.401 | INFO     | __main__:train_seq2seq_model:62 - Epoch :1/100, iteration :1100/1167 loss:0.0161\n",
      "2022-09-19 14:49:12.372 | INFO     | __main__:train_seq2seq_model:65 - Epoch :1/100, training loss:0.0214\n",
      "2022-09-19 14:49:13.760 | INFO     | __main__:train_seq2seq_model:69 - Epoch:1, dev loss:0.0106\n",
      "2022-09-19 14:49:13.765 | INFO     | __main__:train_seq2seq_model:77 - Epoch:1, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-19 14:49:13.779 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :0/1167 loss:0.0642\n",
      "2022-09-19 14:49:16.474 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :100/1167 loss:0.0136\n",
      "2022-09-19 14:49:19.682 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :200/1167 loss:0.0216\n",
      "2022-09-19 14:49:22.602 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :300/1167 loss:0.0089\n",
      "2022-09-19 14:49:25.462 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :400/1167 loss:0.0192\n",
      "2022-09-19 14:49:28.356 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :500/1167 loss:0.0094\n",
      "2022-09-19 14:49:31.614 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :600/1167 loss:0.0114\n",
      "2022-09-19 14:49:34.748 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :700/1167 loss:0.0255\n",
      "2022-09-19 14:49:37.811 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :800/1167 loss:0.0184\n",
      "2022-09-19 14:49:40.701 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :900/1167 loss:0.0365\n",
      "2022-09-19 14:49:43.464 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :1000/1167 loss:0.0074\n",
      "2022-09-19 14:49:46.330 | INFO     | __main__:train_seq2seq_model:62 - Epoch :2/100, iteration :1100/1167 loss:0.0135\n",
      "2022-09-19 14:49:48.303 | INFO     | __main__:train_seq2seq_model:65 - Epoch :2/100, training loss:0.0166\n",
      "2022-09-19 14:49:49.720 | INFO     | __main__:train_seq2seq_model:69 - Epoch:2, dev loss:0.0088\n",
      "2022-09-19 14:49:49.724 | INFO     | __main__:train_seq2seq_model:77 - Epoch:2, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-19 14:49:49.739 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :0/1167 loss:0.0631\n",
      "2022-09-19 14:49:52.453 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :100/1167 loss:0.0069\n",
      "2022-09-19 14:49:55.689 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :200/1167 loss:0.0097\n",
      "2022-09-19 14:49:58.636 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :300/1167 loss:0.0103\n",
      "2022-09-19 14:50:01.504 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :400/1167 loss:0.0183\n",
      "2022-09-19 14:50:04.392 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :500/1167 loss:0.0183\n",
      "2022-09-19 14:50:07.648 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :600/1167 loss:0.0108\n",
      "2022-09-19 14:50:10.777 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :700/1167 loss:0.0200\n",
      "2022-09-19 14:50:13.830 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :800/1167 loss:0.0125\n",
      "2022-09-19 14:50:16.718 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :900/1167 loss:0.0307\n",
      "2022-09-19 14:50:19.475 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :1000/1167 loss:0.0098\n",
      "2022-09-19 14:50:22.324 | INFO     | __main__:train_seq2seq_model:62 - Epoch :3/100, iteration :1100/1167 loss:0.0096\n",
      "2022-09-19 14:50:24.300 | INFO     | __main__:train_seq2seq_model:65 - Epoch :3/100, training loss:0.0129\n",
      "2022-09-19 14:50:25.696 | INFO     | __main__:train_seq2seq_model:69 - Epoch:3, dev loss:0.0094\n",
      "2022-09-19 14:50:25.711 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :0/1167 loss:0.0655\n",
      "2022-09-19 14:50:28.417 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :100/1167 loss:0.0098\n",
      "2022-09-19 14:50:31.625 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :200/1167 loss:0.0073\n",
      "2022-09-19 14:50:34.540 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :300/1167 loss:0.0538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 14:50:37.400 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :400/1167 loss:0.0256\n",
      "2022-09-19 14:50:40.313 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :500/1167 loss:0.0089\n",
      "2022-09-19 14:50:43.572 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :600/1167 loss:0.0044\n",
      "2022-09-19 14:50:46.703 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :700/1167 loss:0.0548\n",
      "2022-09-19 14:50:49.761 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :800/1167 loss:0.0120\n",
      "2022-09-19 14:50:52.648 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :900/1167 loss:0.0374\n",
      "2022-09-19 14:50:55.401 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :1000/1167 loss:0.0109\n",
      "2022-09-19 14:50:58.254 | INFO     | __main__:train_seq2seq_model:62 - Epoch :4/100, iteration :1100/1167 loss:0.0131\n",
      "2022-09-19 14:51:00.226 | INFO     | __main__:train_seq2seq_model:65 - Epoch :4/100, training loss:0.0147\n",
      "2022-09-19 14:51:01.645 | INFO     | __main__:train_seq2seq_model:69 - Epoch:4, dev loss:0.0096\n",
      "2022-09-19 14:51:01.659 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :0/1167 loss:0.0650\n",
      "2022-09-19 14:51:04.365 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :100/1167 loss:0.0109\n",
      "2022-09-19 14:51:07.567 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :200/1167 loss:0.0062\n",
      "2022-09-19 14:51:10.486 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :300/1167 loss:0.0048\n",
      "2022-09-19 14:51:13.337 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :400/1167 loss:0.0199\n",
      "2022-09-19 14:51:16.227 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :500/1167 loss:0.0057\n",
      "2022-09-19 14:51:19.486 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :600/1167 loss:0.0073\n",
      "2022-09-19 14:51:22.612 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :700/1167 loss:0.0204\n",
      "2022-09-19 14:51:25.718 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :800/1167 loss:0.0072\n",
      "2022-09-19 14:51:28.606 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :900/1167 loss:0.0300\n",
      "2022-09-19 14:51:31.365 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :1000/1167 loss:0.0105\n",
      "2022-09-19 14:51:34.224 | INFO     | __main__:train_seq2seq_model:62 - Epoch :5/100, iteration :1100/1167 loss:0.0075\n",
      "2022-09-19 14:51:36.199 | INFO     | __main__:train_seq2seq_model:65 - Epoch :5/100, training loss:0.0118\n",
      "2022-09-19 14:51:37.630 | INFO     | __main__:train_seq2seq_model:69 - Epoch:5, dev loss:0.0075\n",
      "2022-09-19 14:51:37.634 | INFO     | __main__:train_seq2seq_model:77 - Epoch:5, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-19 14:51:37.648 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :0/1167 loss:0.0577\n",
      "2022-09-19 14:51:40.357 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :100/1167 loss:0.0074\n",
      "2022-09-19 14:51:43.564 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :200/1167 loss:0.0037\n",
      "2022-09-19 14:51:46.479 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :300/1167 loss:0.0076\n",
      "2022-09-19 14:51:49.330 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :400/1167 loss:0.0186\n",
      "2022-09-19 14:51:52.226 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :500/1167 loss:0.0093\n",
      "2022-09-19 14:51:55.488 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :600/1167 loss:0.0029\n",
      "2022-09-19 14:51:58.612 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :700/1167 loss:0.0164\n",
      "2022-09-19 14:52:01.682 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :800/1167 loss:0.0098\n",
      "2022-09-19 14:52:04.569 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :900/1167 loss:0.0303\n",
      "2022-09-19 14:52:07.332 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :1000/1167 loss:0.0066\n",
      "2022-09-19 14:52:10.194 | INFO     | __main__:train_seq2seq_model:62 - Epoch :6/100, iteration :1100/1167 loss:0.0091\n",
      "2022-09-19 14:52:12.168 | INFO     | __main__:train_seq2seq_model:65 - Epoch :6/100, training loss:0.0101\n",
      "2022-09-19 14:52:13.561 | INFO     | __main__:train_seq2seq_model:69 - Epoch:6, dev loss:0.0099\n",
      "2022-09-19 14:52:13.575 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :0/1167 loss:0.0635\n",
      "2022-09-19 14:52:16.291 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :100/1167 loss:0.0069\n",
      "2022-09-19 14:52:19.499 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :200/1167 loss:0.0107\n",
      "2022-09-19 14:52:22.420 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :300/1167 loss:0.0119\n",
      "2022-09-19 14:52:25.275 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :400/1167 loss:0.0233\n",
      "2022-09-19 14:52:28.158 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :500/1167 loss:0.0087\n",
      "2022-09-19 14:52:31.416 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :600/1167 loss:0.0046\n",
      "2022-09-19 14:52:34.551 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :700/1167 loss:0.0150\n",
      "2022-09-19 14:52:37.610 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :800/1167 loss:0.0075\n",
      "2022-09-19 14:52:40.502 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :900/1167 loss:0.0273\n",
      "2022-09-19 14:52:43.255 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :1000/1167 loss:0.0089\n",
      "2022-09-19 14:52:46.115 | INFO     | __main__:train_seq2seq_model:62 - Epoch :7/100, iteration :1100/1167 loss:0.0066\n",
      "2022-09-19 14:52:48.085 | INFO     | __main__:train_seq2seq_model:65 - Epoch :7/100, training loss:0.0106\n",
      "2022-09-19 14:52:49.481 | INFO     | __main__:train_seq2seq_model:69 - Epoch:7, dev loss:0.0078\n",
      "2022-09-19 14:52:49.495 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :0/1167 loss:0.0682\n",
      "2022-09-19 14:52:52.212 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :100/1167 loss:0.0104\n",
      "2022-09-19 14:52:55.421 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :200/1167 loss:0.0041\n",
      "2022-09-19 14:52:58.346 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :300/1167 loss:0.0135\n",
      "2022-09-19 14:53:01.205 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :400/1167 loss:0.0141\n",
      "2022-09-19 14:53:04.106 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :500/1167 loss:0.0037\n",
      "2022-09-19 14:53:07.362 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :600/1167 loss:0.0026\n",
      "2022-09-19 14:53:10.496 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :700/1167 loss:0.0157\n",
      "2022-09-19 14:53:13.551 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :800/1167 loss:0.0129\n",
      "2022-09-19 14:53:16.452 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :900/1167 loss:0.0281\n",
      "2022-09-19 14:53:19.207 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :1000/1167 loss:0.0088\n",
      "2022-09-19 14:53:22.068 | INFO     | __main__:train_seq2seq_model:62 - Epoch :8/100, iteration :1100/1167 loss:0.0068\n",
      "2022-09-19 14:53:24.038 | INFO     | __main__:train_seq2seq_model:65 - Epoch :8/100, training loss:0.0094\n",
      "2022-09-19 14:53:25.449 | INFO     | __main__:train_seq2seq_model:69 - Epoch:8, dev loss:0.0083\n",
      "2022-09-19 14:53:25.462 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :0/1167 loss:0.0591\n",
      "2022-09-19 14:53:28.171 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :100/1167 loss:0.0096\n",
      "2022-09-19 14:53:31.381 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :200/1167 loss:0.0081\n",
      "2022-09-19 14:53:34.313 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :300/1167 loss:0.0063\n",
      "2022-09-19 14:53:37.162 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :400/1167 loss:0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 14:53:40.045 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :500/1167 loss:0.0071\n",
      "2022-09-19 14:53:43.309 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :600/1167 loss:0.0037\n",
      "2022-09-19 14:53:46.451 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :700/1167 loss:0.0180\n",
      "2022-09-19 14:53:49.506 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :800/1167 loss:0.0078\n",
      "2022-09-19 14:53:52.402 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :900/1167 loss:0.0278\n",
      "2022-09-19 14:53:55.153 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :1000/1167 loss:0.0075\n",
      "2022-09-19 14:53:58.014 | INFO     | __main__:train_seq2seq_model:62 - Epoch :9/100, iteration :1100/1167 loss:0.0068\n",
      "2022-09-19 14:53:59.986 | INFO     | __main__:train_seq2seq_model:65 - Epoch :9/100, training loss:0.0096\n",
      "2022-09-19 14:54:01.391 | INFO     | __main__:train_seq2seq_model:69 - Epoch:9, dev loss:0.0079\n",
      "2022-09-19 14:54:01.405 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :0/1167 loss:0.0559\n",
      "2022-09-19 14:54:04.119 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :100/1167 loss:0.0041\n",
      "2022-09-19 14:54:07.327 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :200/1167 loss:0.0055\n",
      "2022-09-19 14:54:10.253 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :300/1167 loss:0.0038\n",
      "2022-09-19 14:54:13.101 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :400/1167 loss:0.0213\n",
      "2022-09-19 14:54:15.994 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :500/1167 loss:0.0054\n",
      "2022-09-19 14:54:19.260 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :600/1167 loss:0.0039\n",
      "2022-09-19 14:54:22.405 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :700/1167 loss:0.0180\n",
      "2022-09-19 14:54:25.461 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :800/1167 loss:0.0131\n",
      "2022-09-19 14:54:28.355 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :900/1167 loss:0.0304\n",
      "2022-09-19 14:54:31.102 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :1000/1167 loss:0.0074\n",
      "2022-09-19 14:54:33.957 | INFO     | __main__:train_seq2seq_model:62 - Epoch :10/100, iteration :1100/1167 loss:0.0127\n",
      "2022-09-19 14:54:35.937 | INFO     | __main__:train_seq2seq_model:65 - Epoch :10/100, training loss:0.0085\n",
      "2022-09-19 14:54:37.337 | INFO     | __main__:train_seq2seq_model:69 - Epoch:10, dev loss:0.0076\n",
      "2022-09-19 14:54:37.351 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :0/1167 loss:0.0705\n",
      "2022-09-19 14:54:40.056 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :100/1167 loss:0.0037\n",
      "2022-09-19 14:54:43.263 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :200/1167 loss:0.0046\n",
      "2022-09-19 14:54:46.192 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :300/1167 loss:0.0040\n",
      "2022-09-19 14:54:49.047 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :400/1167 loss:0.0132\n",
      "2022-09-19 14:54:51.942 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :500/1167 loss:0.0053\n",
      "2022-09-19 14:54:55.210 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :600/1167 loss:0.0070\n",
      "2022-09-19 14:54:58.357 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :700/1167 loss:0.0166\n",
      "2022-09-19 14:55:01.412 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :800/1167 loss:0.0063\n",
      "2022-09-19 14:55:04.317 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :900/1167 loss:0.0262\n",
      "2022-09-19 14:55:07.075 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :1000/1167 loss:0.0088\n",
      "2022-09-19 14:55:09.937 | INFO     | __main__:train_seq2seq_model:62 - Epoch :11/100, iteration :1100/1167 loss:0.0109\n",
      "2022-09-19 14:55:11.909 | INFO     | __main__:train_seq2seq_model:65 - Epoch :11/100, training loss:0.0091\n",
      "2022-09-19 14:55:13.312 | INFO     | __main__:train_seq2seq_model:69 - Epoch:11, dev loss:0.0074\n",
      "2022-09-19 14:55:13.316 | INFO     | __main__:train_seq2seq_model:77 - Epoch:11, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-19 14:55:13.330 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :0/1167 loss:0.0619\n",
      "2022-09-19 14:55:16.041 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :100/1167 loss:0.0039\n",
      "2022-09-19 14:55:19.253 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :200/1167 loss:0.0039\n",
      "2022-09-19 14:55:22.177 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :300/1167 loss:0.0033\n",
      "2022-09-19 14:55:25.026 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :400/1167 loss:0.0132\n",
      "2022-09-19 14:55:27.921 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :500/1167 loss:0.0052\n",
      "2022-09-19 14:55:31.188 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :600/1167 loss:0.0033\n",
      "2022-09-19 14:55:34.330 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :700/1167 loss:0.0139\n",
      "2022-09-19 14:55:37.379 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :800/1167 loss:0.0045\n",
      "2022-09-19 14:55:40.270 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :900/1167 loss:0.0266\n",
      "2022-09-19 14:55:43.014 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :1000/1167 loss:0.0065\n",
      "2022-09-19 14:55:45.872 | INFO     | __main__:train_seq2seq_model:62 - Epoch :12/100, iteration :1100/1167 loss:0.0102\n",
      "2022-09-19 14:55:47.845 | INFO     | __main__:train_seq2seq_model:65 - Epoch :12/100, training loss:0.0083\n",
      "2022-09-19 14:55:49.241 | INFO     | __main__:train_seq2seq_model:69 - Epoch:12, dev loss:0.0079\n",
      "2022-09-19 14:55:49.255 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :0/1167 loss:0.0577\n",
      "2022-09-19 14:55:51.965 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :100/1167 loss:0.0094\n",
      "2022-09-19 14:55:55.181 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :200/1167 loss:0.0123\n",
      "2022-09-19 14:55:58.116 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :300/1167 loss:0.0090\n",
      "2022-09-19 14:56:00.972 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :400/1167 loss:0.0134\n",
      "2022-09-19 14:56:03.869 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :500/1167 loss:0.0055\n",
      "2022-09-19 14:56:07.136 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :600/1167 loss:0.0060\n",
      "2022-09-19 14:56:10.276 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :700/1167 loss:0.0172\n",
      "2022-09-19 14:56:13.330 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :800/1167 loss:0.0020\n",
      "2022-09-19 14:56:16.224 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :900/1167 loss:0.0287\n",
      "2022-09-19 14:56:18.980 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :1000/1167 loss:0.0037\n",
      "2022-09-19 14:56:21.842 | INFO     | __main__:train_seq2seq_model:62 - Epoch :13/100, iteration :1100/1167 loss:0.0079\n",
      "2022-09-19 14:56:23.816 | INFO     | __main__:train_seq2seq_model:65 - Epoch :13/100, training loss:0.0087\n",
      "2022-09-19 14:56:25.251 | INFO     | __main__:train_seq2seq_model:69 - Epoch:13, dev loss:0.0076\n",
      "2022-09-19 14:56:25.265 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :0/1167 loss:0.0592\n",
      "2022-09-19 14:56:27.981 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :100/1167 loss:0.0073\n",
      "2022-09-19 14:56:31.190 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :200/1167 loss:0.0124\n",
      "2022-09-19 14:56:34.113 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :300/1167 loss:0.0050\n",
      "2022-09-19 14:56:36.962 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :400/1167 loss:0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 14:56:39.858 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :500/1167 loss:0.0059\n",
      "2022-09-19 14:56:43.120 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :600/1167 loss:0.0057\n",
      "2022-09-19 14:56:46.266 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :700/1167 loss:0.0134\n",
      "2022-09-19 14:56:49.328 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :800/1167 loss:0.0045\n",
      "2022-09-19 14:56:52.234 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :900/1167 loss:0.0281\n",
      "2022-09-19 14:56:54.993 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :1000/1167 loss:0.0092\n",
      "2022-09-19 14:56:57.860 | INFO     | __main__:train_seq2seq_model:62 - Epoch :14/100, iteration :1100/1167 loss:0.0064\n",
      "2022-09-19 14:56:59.835 | INFO     | __main__:train_seq2seq_model:65 - Epoch :14/100, training loss:0.0089\n",
      "2022-09-19 14:57:01.251 | INFO     | __main__:train_seq2seq_model:69 - Epoch:14, dev loss:0.0077\n",
      "2022-09-19 14:57:01.264 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :0/1167 loss:0.0580\n",
      "2022-09-19 14:57:03.976 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :100/1167 loss:0.0055\n",
      "2022-09-19 14:57:07.184 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :200/1167 loss:0.0040\n",
      "2022-09-19 14:57:10.113 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :300/1167 loss:0.0036\n",
      "2022-09-19 14:57:12.960 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :400/1167 loss:0.0136\n",
      "2022-09-19 14:57:15.855 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :500/1167 loss:0.0063\n",
      "2022-09-19 14:57:19.113 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :600/1167 loss:0.0041\n",
      "2022-09-19 14:57:22.250 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :700/1167 loss:0.0146\n",
      "2022-09-19 14:57:25.299 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :800/1167 loss:0.0083\n",
      "2022-09-19 14:57:28.194 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :900/1167 loss:0.0283\n",
      "2022-09-19 14:57:30.950 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :1000/1167 loss:0.0065\n",
      "2022-09-19 14:57:33.808 | INFO     | __main__:train_seq2seq_model:62 - Epoch :15/100, iteration :1100/1167 loss:0.0106\n",
      "2022-09-19 14:57:35.780 | INFO     | __main__:train_seq2seq_model:65 - Epoch :15/100, training loss:0.0084\n",
      "2022-09-19 14:57:37.206 | INFO     | __main__:train_seq2seq_model:69 - Epoch:15, dev loss:0.0072\n",
      "2022-09-19 14:57:37.211 | INFO     | __main__:train_seq2seq_model:77 - Epoch:15, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-19 14:57:37.225 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :0/1167 loss:0.0565\n",
      "2022-09-19 14:57:39.939 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :100/1167 loss:0.0056\n",
      "2022-09-19 14:57:43.154 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :200/1167 loss:0.0064\n",
      "2022-09-19 14:57:46.083 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :300/1167 loss:0.0067\n",
      "2022-09-19 14:57:48.935 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :400/1167 loss:0.0128\n",
      "2022-09-19 14:57:51.832 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :500/1167 loss:0.0121\n",
      "2022-09-19 14:57:55.094 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :600/1167 loss:0.0066\n",
      "2022-09-19 14:57:58.243 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :700/1167 loss:0.0183\n",
      "2022-09-19 14:58:01.293 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :800/1167 loss:0.0039\n",
      "2022-09-19 14:58:04.207 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :900/1167 loss:0.0313\n",
      "2022-09-19 14:58:06.957 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :1000/1167 loss:0.0040\n",
      "2022-09-19 14:58:09.819 | INFO     | __main__:train_seq2seq_model:62 - Epoch :16/100, iteration :1100/1167 loss:0.0065\n",
      "2022-09-19 14:58:11.794 | INFO     | __main__:train_seq2seq_model:65 - Epoch :16/100, training loss:0.0090\n",
      "2022-09-19 14:58:13.219 | INFO     | __main__:train_seq2seq_model:69 - Epoch:16, dev loss:0.0069\n",
      "2022-09-19 14:58:13.223 | INFO     | __main__:train_seq2seq_model:77 - Epoch:16, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-19 14:58:13.237 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :0/1167 loss:0.0558\n",
      "2022-09-19 14:58:15.949 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :100/1167 loss:0.0048\n",
      "2022-09-19 14:58:19.165 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :200/1167 loss:0.0037\n",
      "2022-09-19 14:58:22.122 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :300/1167 loss:0.0047\n",
      "2022-09-19 14:58:24.968 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :400/1167 loss:0.0164\n",
      "2022-09-19 14:58:27.861 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :500/1167 loss:0.0064\n",
      "2022-09-19 14:58:31.129 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :600/1167 loss:0.0026\n",
      "2022-09-19 14:58:34.277 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :700/1167 loss:0.0151\n",
      "2022-09-19 14:58:37.331 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :800/1167 loss:0.0050\n",
      "2022-09-19 14:58:40.223 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :900/1167 loss:0.0259\n",
      "2022-09-19 14:58:42.974 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :1000/1167 loss:0.0145\n",
      "2022-09-19 14:58:45.830 | INFO     | __main__:train_seq2seq_model:62 - Epoch :17/100, iteration :1100/1167 loss:0.0093\n",
      "2022-09-19 14:58:47.809 | INFO     | __main__:train_seq2seq_model:65 - Epoch :17/100, training loss:0.0079\n",
      "2022-09-19 14:58:49.214 | INFO     | __main__:train_seq2seq_model:69 - Epoch:17, dev loss:0.0076\n",
      "2022-09-19 14:58:49.228 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :0/1167 loss:0.0595\n",
      "2022-09-19 14:58:51.930 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :100/1167 loss:0.0096\n",
      "2022-09-19 14:58:55.146 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :200/1167 loss:0.0041\n",
      "2022-09-19 14:58:58.069 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :300/1167 loss:0.0027\n",
      "2022-09-19 14:59:00.923 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :400/1167 loss:0.0156\n",
      "2022-09-19 14:59:03.814 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :500/1167 loss:0.0110\n",
      "2022-09-19 14:59:07.072 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :600/1167 loss:0.0024\n",
      "2022-09-19 14:59:10.218 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :700/1167 loss:0.0169\n",
      "2022-09-19 14:59:13.274 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :800/1167 loss:0.0036\n",
      "2022-09-19 14:59:16.172 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :900/1167 loss:0.0272\n",
      "2022-09-19 14:59:18.918 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :1000/1167 loss:0.0037\n",
      "2022-09-19 14:59:21.783 | INFO     | __main__:train_seq2seq_model:62 - Epoch :18/100, iteration :1100/1167 loss:0.0061\n",
      "2022-09-19 14:59:23.761 | INFO     | __main__:train_seq2seq_model:65 - Epoch :18/100, training loss:0.0077\n",
      "2022-09-19 14:59:25.192 | INFO     | __main__:train_seq2seq_model:69 - Epoch:18, dev loss:0.0083\n",
      "2022-09-19 14:59:25.205 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :0/1167 loss:0.0598\n",
      "2022-09-19 14:59:27.920 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :100/1167 loss:0.0068\n",
      "2022-09-19 14:59:31.139 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :200/1167 loss:0.0040\n",
      "2022-09-19 14:59:34.067 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :300/1167 loss:0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 14:59:36.918 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :400/1167 loss:0.0158\n",
      "2022-09-19 14:59:39.808 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :500/1167 loss:0.0069\n",
      "2022-09-19 14:59:43.075 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :600/1167 loss:0.0075\n",
      "2022-09-19 14:59:46.213 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :700/1167 loss:0.0141\n",
      "2022-09-19 14:59:49.268 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :800/1167 loss:0.0085\n",
      "2022-09-19 14:59:52.167 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :900/1167 loss:0.0255\n",
      "2022-09-19 14:59:54.918 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :1000/1167 loss:0.0036\n",
      "2022-09-19 14:59:57.779 | INFO     | __main__:train_seq2seq_model:62 - Epoch :19/100, iteration :1100/1167 loss:0.0059\n",
      "2022-09-19 14:59:59.750 | INFO     | __main__:train_seq2seq_model:65 - Epoch :19/100, training loss:0.0084\n",
      "2022-09-19 15:00:01.173 | INFO     | __main__:train_seq2seq_model:69 - Epoch:19, dev loss:0.0072\n",
      "2022-09-19 15:00:01.186 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :0/1167 loss:0.0555\n",
      "2022-09-19 15:00:03.906 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :100/1167 loss:0.0040\n",
      "2022-09-19 15:00:07.125 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :200/1167 loss:0.0082\n",
      "2022-09-19 15:00:10.052 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :300/1167 loss:0.0024\n",
      "2022-09-19 15:00:12.908 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :400/1167 loss:0.0194\n",
      "2022-09-19 15:00:15.800 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :500/1167 loss:0.0066\n",
      "2022-09-19 15:00:19.061 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :600/1167 loss:0.0018\n",
      "2022-09-19 15:00:22.199 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :700/1167 loss:0.0157\n",
      "2022-09-19 15:00:25.247 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :800/1167 loss:0.0090\n",
      "2022-09-19 15:00:28.147 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :900/1167 loss:0.0330\n",
      "2022-09-19 15:00:30.893 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :1000/1167 loss:0.0072\n",
      "2022-09-19 15:00:33.751 | INFO     | __main__:train_seq2seq_model:62 - Epoch :20/100, iteration :1100/1167 loss:0.0087\n",
      "2022-09-19 15:00:35.727 | INFO     | __main__:train_seq2seq_model:65 - Epoch :20/100, training loss:0.0085\n",
      "2022-09-19 15:00:37.149 | INFO     | __main__:train_seq2seq_model:69 - Epoch:20, dev loss:0.0072\n",
      "2022-09-19 15:00:37.163 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :0/1167 loss:0.0558\n",
      "2022-09-19 15:00:39.872 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :100/1167 loss:0.0041\n",
      "2022-09-19 15:00:43.080 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :200/1167 loss:0.0040\n",
      "2022-09-19 15:00:46.005 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :300/1167 loss:0.0028\n",
      "2022-09-19 15:00:48.867 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :400/1167 loss:0.0134\n",
      "2022-09-19 15:00:51.764 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :500/1167 loss:0.0039\n",
      "2022-09-19 15:00:55.021 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :600/1167 loss:0.0031\n",
      "2022-09-19 15:00:58.156 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :700/1167 loss:0.0157\n",
      "2022-09-19 15:01:01.207 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :800/1167 loss:0.0021\n",
      "2022-09-19 15:01:04.109 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :900/1167 loss:0.0300\n",
      "2022-09-19 15:01:06.858 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :1000/1167 loss:0.0073\n",
      "2022-09-19 15:01:09.718 | INFO     | __main__:train_seq2seq_model:62 - Epoch :21/100, iteration :1100/1167 loss:0.0060\n",
      "2022-09-19 15:01:11.689 | INFO     | __main__:train_seq2seq_model:65 - Epoch :21/100, training loss:0.0077\n",
      "2022-09-19 15:01:13.086 | INFO     | __main__:train_seq2seq_model:69 - Epoch:21, dev loss:0.0072\n",
      "2022-09-19 15:01:13.101 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :0/1167 loss:0.0575\n",
      "2022-09-19 15:01:15.809 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :100/1167 loss:0.0056\n",
      "2022-09-19 15:01:19.020 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :200/1167 loss:0.0086\n",
      "2022-09-19 15:01:21.950 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :300/1167 loss:0.0040\n",
      "2022-09-19 15:01:24.808 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :400/1167 loss:0.0159\n",
      "2022-09-19 15:01:27.689 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :500/1167 loss:0.0035\n",
      "2022-09-19 15:01:30.944 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :600/1167 loss:0.0016\n",
      "2022-09-19 15:01:34.080 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :700/1167 loss:0.0172\n",
      "2022-09-19 15:01:37.132 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :800/1167 loss:0.0035\n",
      "2022-09-19 15:01:40.028 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :900/1167 loss:0.0324\n",
      "2022-09-19 15:01:42.777 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :1000/1167 loss:0.0074\n",
      "2022-09-19 15:01:45.636 | INFO     | __main__:train_seq2seq_model:62 - Epoch :22/100, iteration :1100/1167 loss:0.0064\n",
      "2022-09-19 15:01:47.607 | INFO     | __main__:train_seq2seq_model:65 - Epoch :22/100, training loss:0.0081\n",
      "2022-09-19 15:01:49.001 | INFO     | __main__:train_seq2seq_model:69 - Epoch:22, dev loss:0.0079\n",
      "2022-09-19 15:01:49.015 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :0/1167 loss:0.0519\n",
      "2022-09-19 15:01:51.723 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :100/1167 loss:0.0068\n",
      "2022-09-19 15:01:54.937 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :200/1167 loss:0.0111\n",
      "2022-09-19 15:01:57.865 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :300/1167 loss:0.0031\n",
      "2022-09-19 15:02:00.719 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :400/1167 loss:0.0300\n",
      "2022-09-19 15:02:03.616 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :500/1167 loss:0.0036\n",
      "2022-09-19 15:02:06.880 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :600/1167 loss:0.0021\n",
      "2022-09-19 15:02:10.016 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :700/1167 loss:0.0159\n",
      "2022-09-19 15:02:13.060 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :800/1167 loss:0.0015\n",
      "2022-09-19 15:02:15.956 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :900/1167 loss:0.0307\n",
      "2022-09-19 15:02:18.706 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :1000/1167 loss:0.0043\n",
      "2022-09-19 15:02:21.567 | INFO     | __main__:train_seq2seq_model:62 - Epoch :23/100, iteration :1100/1167 loss:0.0057\n",
      "2022-09-19 15:02:23.538 | INFO     | __main__:train_seq2seq_model:65 - Epoch :23/100, training loss:0.0082\n",
      "2022-09-19 15:02:24.947 | INFO     | __main__:train_seq2seq_model:69 - Epoch:23, dev loss:0.0071\n",
      "2022-09-19 15:02:24.961 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :0/1167 loss:0.0565\n",
      "2022-09-19 15:02:27.668 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :100/1167 loss:0.0066\n",
      "2022-09-19 15:02:30.887 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :200/1167 loss:0.0075\n",
      "2022-09-19 15:02:33.814 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :300/1167 loss:0.0029\n",
      "2022-09-19 15:02:36.664 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :400/1167 loss:0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 15:02:39.558 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :500/1167 loss:0.0037\n",
      "2022-09-19 15:02:42.815 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :600/1167 loss:0.0032\n",
      "2022-09-19 15:02:45.953 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :700/1167 loss:0.0182\n",
      "2022-09-19 15:02:49.006 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :800/1167 loss:0.0041\n",
      "2022-09-19 15:02:51.909 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :900/1167 loss:0.0269\n",
      "2022-09-19 15:02:54.659 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :1000/1167 loss:0.0167\n",
      "2022-09-19 15:02:57.510 | INFO     | __main__:train_seq2seq_model:62 - Epoch :24/100, iteration :1100/1167 loss:0.0060\n",
      "2022-09-19 15:02:59.483 | INFO     | __main__:train_seq2seq_model:65 - Epoch :24/100, training loss:0.0077\n",
      "2022-09-19 15:03:00.884 | INFO     | __main__:train_seq2seq_model:69 - Epoch:24, dev loss:0.0076\n",
      "2022-09-19 15:03:00.898 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :0/1167 loss:0.0560\n",
      "2022-09-19 15:03:03.614 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :100/1167 loss:0.0122\n",
      "2022-09-19 15:03:06.828 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :200/1167 loss:0.0081\n",
      "2022-09-19 15:03:09.749 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :300/1167 loss:0.0043\n",
      "2022-09-19 15:03:12.595 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :400/1167 loss:0.0125\n",
      "2022-09-19 15:03:15.481 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :500/1167 loss:0.0060\n",
      "2022-09-19 15:03:18.747 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :600/1167 loss:0.0021\n",
      "2022-09-19 15:03:21.902 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :700/1167 loss:0.0209\n",
      "2022-09-19 15:03:24.949 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :800/1167 loss:0.0039\n",
      "2022-09-19 15:03:27.846 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :900/1167 loss:0.0374\n",
      "2022-09-19 15:03:30.600 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :1000/1167 loss:0.0074\n",
      "2022-09-19 15:03:33.458 | INFO     | __main__:train_seq2seq_model:62 - Epoch :25/100, iteration :1100/1167 loss:0.0082\n",
      "2022-09-19 15:03:35.429 | INFO     | __main__:train_seq2seq_model:65 - Epoch :25/100, training loss:0.0081\n",
      "2022-09-19 15:03:36.856 | INFO     | __main__:train_seq2seq_model:69 - Epoch:25, dev loss:0.0081\n",
      "2022-09-19 15:03:36.870 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :0/1167 loss:0.0637\n",
      "2022-09-19 15:03:39.589 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :100/1167 loss:0.0040\n",
      "2022-09-19 15:03:42.800 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :200/1167 loss:0.0064\n",
      "2022-09-19 15:03:45.721 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :300/1167 loss:0.0024\n",
      "2022-09-19 15:03:48.584 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :400/1167 loss:0.0157\n",
      "2022-09-19 15:03:51.468 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :500/1167 loss:0.0046\n",
      "2022-09-19 15:03:54.727 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :600/1167 loss:0.0032\n",
      "2022-09-19 15:03:57.867 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :700/1167 loss:0.0148\n",
      "2022-09-19 15:04:00.918 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :800/1167 loss:0.0055\n",
      "2022-09-19 15:04:03.824 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :900/1167 loss:0.0273\n",
      "2022-09-19 15:04:06.573 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :1000/1167 loss:0.0041\n",
      "2022-09-19 15:04:09.429 | INFO     | __main__:train_seq2seq_model:62 - Epoch :26/100, iteration :1100/1167 loss:0.0080\n",
      "2022-09-19 15:04:11.405 | INFO     | __main__:train_seq2seq_model:65 - Epoch :26/100, training loss:0.0080\n",
      "2022-09-19 15:04:12.816 | INFO     | __main__:train_seq2seq_model:69 - Epoch:26, dev loss:0.0080\n",
      "2022-09-19 15:04:12.830 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :0/1167 loss:0.0575\n",
      "2022-09-19 15:04:15.540 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :100/1167 loss:0.0056\n",
      "2022-09-19 15:04:18.753 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :200/1167 loss:0.0080\n",
      "2022-09-19 15:04:21.677 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :300/1167 loss:0.0075\n",
      "2022-09-19 15:04:24.536 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :400/1167 loss:0.0154\n",
      "2022-09-19 15:04:27.426 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :500/1167 loss:0.0033\n",
      "2022-09-19 15:04:30.685 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :600/1167 loss:0.0059\n",
      "2022-09-19 15:04:33.829 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :700/1167 loss:0.0164\n",
      "2022-09-19 15:04:36.879 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :800/1167 loss:0.0059\n",
      "2022-09-19 15:04:39.769 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :900/1167 loss:0.0252\n",
      "2022-09-19 15:04:42.523 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :1000/1167 loss:0.0048\n",
      "2022-09-19 15:04:45.379 | INFO     | __main__:train_seq2seq_model:62 - Epoch :27/100, iteration :1100/1167 loss:0.0054\n",
      "2022-09-19 15:04:47.351 | INFO     | __main__:train_seq2seq_model:65 - Epoch :27/100, training loss:0.0073\n",
      "2022-09-19 15:04:48.751 | INFO     | __main__:train_seq2seq_model:69 - Epoch:27, dev loss:0.0069\n",
      "2022-09-19 15:04:48.755 | INFO     | __main__:train_seq2seq_model:77 - Epoch:27, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-19 15:04:48.769 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :0/1167 loss:0.0574\n",
      "2022-09-19 15:04:51.474 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :100/1167 loss:0.0048\n",
      "2022-09-19 15:04:54.692 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :200/1167 loss:0.0031\n",
      "2022-09-19 15:04:57.621 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :300/1167 loss:0.0035\n",
      "2022-09-19 15:05:00.480 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :400/1167 loss:0.0125\n",
      "2022-09-19 15:05:03.369 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :500/1167 loss:0.0033\n",
      "2022-09-19 15:05:06.632 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :600/1167 loss:0.0040\n",
      "2022-09-19 15:05:09.775 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :700/1167 loss:0.0150\n",
      "2022-09-19 15:05:12.823 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :800/1167 loss:0.0095\n",
      "2022-09-19 15:05:15.727 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :900/1167 loss:0.0263\n",
      "2022-09-19 15:05:18.482 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :1000/1167 loss:0.0054\n",
      "2022-09-19 15:05:21.334 | INFO     | __main__:train_seq2seq_model:62 - Epoch :28/100, iteration :1100/1167 loss:0.0055\n",
      "2022-09-19 15:05:23.304 | INFO     | __main__:train_seq2seq_model:65 - Epoch :28/100, training loss:0.0080\n",
      "2022-09-19 15:05:24.698 | INFO     | __main__:train_seq2seq_model:69 - Epoch:28, dev loss:0.0074\n",
      "2022-09-19 15:05:24.713 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :0/1167 loss:0.0555\n",
      "2022-09-19 15:05:27.425 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :100/1167 loss:0.0041\n",
      "2022-09-19 15:05:30.640 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :200/1167 loss:0.0036\n",
      "2022-09-19 15:05:33.564 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :300/1167 loss:0.0024\n",
      "2022-09-19 15:05:36.413 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :400/1167 loss:0.0201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 15:05:39.294 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :500/1167 loss:0.0046\n",
      "2022-09-19 15:05:42.556 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :600/1167 loss:0.0035\n",
      "2022-09-19 15:05:45.691 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :700/1167 loss:0.0242\n",
      "2022-09-19 15:05:48.741 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :800/1167 loss:0.0080\n",
      "2022-09-19 15:05:51.641 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :900/1167 loss:0.0315\n",
      "2022-09-19 15:05:54.400 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :1000/1167 loss:0.0044\n",
      "2022-09-19 15:05:57.247 | INFO     | __main__:train_seq2seq_model:62 - Epoch :29/100, iteration :1100/1167 loss:0.0071\n",
      "2022-09-19 15:05:59.217 | INFO     | __main__:train_seq2seq_model:65 - Epoch :29/100, training loss:0.0082\n",
      "2022-09-19 15:06:00.619 | INFO     | __main__:train_seq2seq_model:69 - Epoch:29, dev loss:0.0079\n",
      "2022-09-19 15:06:00.631 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :0/1167 loss:0.0598\n",
      "2022-09-19 15:06:03.347 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :100/1167 loss:0.0051\n",
      "2022-09-19 15:06:06.568 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :200/1167 loss:0.0082\n",
      "2022-09-19 15:06:09.485 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :300/1167 loss:0.0032\n",
      "2022-09-19 15:06:12.343 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :400/1167 loss:0.0183\n",
      "2022-09-19 15:06:15.228 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :500/1167 loss:0.0093\n",
      "2022-09-19 15:06:18.491 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :600/1167 loss:0.0046\n",
      "2022-09-19 15:06:21.621 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :700/1167 loss:0.0171\n",
      "2022-09-19 15:06:24.668 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :800/1167 loss:0.0066\n",
      "2022-09-19 15:06:27.613 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :900/1167 loss:0.0258\n",
      "2022-09-19 15:06:30.370 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :1000/1167 loss:0.0094\n",
      "2022-09-19 15:06:33.217 | INFO     | __main__:train_seq2seq_model:62 - Epoch :30/100, iteration :1100/1167 loss:0.0067\n",
      "2022-09-19 15:06:35.185 | INFO     | __main__:train_seq2seq_model:65 - Epoch :30/100, training loss:0.0079\n",
      "2022-09-19 15:06:36.581 | INFO     | __main__:train_seq2seq_model:69 - Epoch:30, dev loss:0.0073\n",
      "2022-09-19 15:06:36.595 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :0/1167 loss:0.0526\n",
      "2022-09-19 15:06:39.309 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :100/1167 loss:0.0067\n",
      "2022-09-19 15:06:42.524 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :200/1167 loss:0.0124\n",
      "2022-09-19 15:06:45.442 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :300/1167 loss:0.0021\n",
      "2022-09-19 15:06:48.303 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :400/1167 loss:0.0128\n",
      "2022-09-19 15:06:51.183 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :500/1167 loss:0.0049\n",
      "2022-09-19 15:06:54.452 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :600/1167 loss:0.0049\n",
      "2022-09-19 15:06:57.582 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :700/1167 loss:0.0164\n",
      "2022-09-19 15:07:00.630 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :800/1167 loss:0.0046\n",
      "2022-09-19 15:07:03.529 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :900/1167 loss:0.0259\n",
      "2022-09-19 15:07:06.282 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :1000/1167 loss:0.0069\n",
      "2022-09-19 15:07:09.135 | INFO     | __main__:train_seq2seq_model:62 - Epoch :31/100, iteration :1100/1167 loss:0.0054\n",
      "2022-09-19 15:07:11.103 | INFO     | __main__:train_seq2seq_model:65 - Epoch :31/100, training loss:0.0074\n",
      "2022-09-19 15:07:12.552 | INFO     | __main__:train_seq2seq_model:69 - Epoch:31, dev loss:0.0073\n",
      "2022-09-19 15:07:12.566 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :0/1167 loss:0.0568\n",
      "2022-09-19 15:07:15.271 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :100/1167 loss:0.0065\n",
      "2022-09-19 15:07:18.484 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :200/1167 loss:0.0034\n",
      "2022-09-19 15:07:21.395 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :300/1167 loss:0.0105\n",
      "2022-09-19 15:07:24.262 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :400/1167 loss:0.0152\n",
      "2022-09-19 15:07:27.141 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :500/1167 loss:0.0036\n",
      "2022-09-19 15:07:30.414 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :600/1167 loss:0.0077\n",
      "2022-09-19 15:07:33.546 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :700/1167 loss:0.0141\n",
      "2022-09-19 15:07:36.604 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :800/1167 loss:0.0042\n",
      "2022-09-19 15:07:39.501 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :900/1167 loss:0.0250\n",
      "2022-09-19 15:07:42.261 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :1000/1167 loss:0.0050\n",
      "2022-09-19 15:07:45.110 | INFO     | __main__:train_seq2seq_model:62 - Epoch :32/100, iteration :1100/1167 loss:0.0103\n",
      "2022-09-19 15:07:47.083 | INFO     | __main__:train_seq2seq_model:65 - Epoch :32/100, training loss:0.0077\n",
      "2022-09-19 15:07:48.483 | INFO     | __main__:train_seq2seq_model:69 - Epoch:32, dev loss:0.0084\n",
      "2022-09-19 15:07:48.497 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :0/1167 loss:0.0558\n",
      "2022-09-19 15:07:51.203 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :100/1167 loss:0.0056\n",
      "2022-09-19 15:07:54.424 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :200/1167 loss:0.0061\n",
      "2022-09-19 15:07:57.349 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :300/1167 loss:0.0129\n",
      "2022-09-19 15:08:00.217 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :400/1167 loss:0.0154\n",
      "2022-09-19 15:08:03.106 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :500/1167 loss:0.0042\n",
      "2022-09-19 15:08:06.374 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :600/1167 loss:0.0018\n",
      "2022-09-19 15:08:09.507 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :700/1167 loss:0.0152\n",
      "2022-09-19 15:08:12.565 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :800/1167 loss:0.0052\n",
      "2022-09-19 15:08:15.452 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :900/1167 loss:0.0291\n",
      "2022-09-19 15:08:18.210 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :1000/1167 loss:0.0055\n",
      "2022-09-19 15:08:21.072 | INFO     | __main__:train_seq2seq_model:62 - Epoch :33/100, iteration :1100/1167 loss:0.0055\n",
      "2022-09-19 15:08:23.044 | INFO     | __main__:train_seq2seq_model:65 - Epoch :33/100, training loss:0.0075\n",
      "2022-09-19 15:08:24.447 | INFO     | __main__:train_seq2seq_model:69 - Epoch:33, dev loss:0.0073\n",
      "2022-09-19 15:08:24.460 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :0/1167 loss:0.0503\n",
      "2022-09-19 15:08:27.167 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :100/1167 loss:0.0093\n",
      "2022-09-19 15:08:30.379 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :200/1167 loss:0.0082\n",
      "2022-09-19 15:08:33.293 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :300/1167 loss:0.0024\n",
      "2022-09-19 15:08:36.157 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :400/1167 loss:0.0164\n",
      "2022-09-19 15:08:39.041 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :500/1167 loss:0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 15:08:42.312 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :600/1167 loss:0.0009\n",
      "2022-09-19 15:08:45.447 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :700/1167 loss:0.0174\n",
      "2022-09-19 15:08:48.505 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :800/1167 loss:0.0029\n",
      "2022-09-19 15:08:51.394 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :900/1167 loss:0.0249\n",
      "2022-09-19 15:08:54.151 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :1000/1167 loss:0.0044\n",
      "2022-09-19 15:08:56.993 | INFO     | __main__:train_seq2seq_model:62 - Epoch :34/100, iteration :1100/1167 loss:0.0058\n",
      "2022-09-19 15:08:58.966 | INFO     | __main__:train_seq2seq_model:65 - Epoch :34/100, training loss:0.0076\n",
      "2022-09-19 15:09:00.419 | INFO     | __main__:train_seq2seq_model:69 - Epoch:34, dev loss:0.0072\n",
      "2022-09-19 15:09:00.433 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :0/1167 loss:0.0557\n",
      "2022-09-19 15:09:03.183 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :100/1167 loss:0.0039\n",
      "2022-09-19 15:09:06.406 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :200/1167 loss:0.0039\n",
      "2022-09-19 15:09:09.329 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :300/1167 loss:0.0073\n",
      "2022-09-19 15:09:12.186 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :400/1167 loss:0.0212\n",
      "2022-09-19 15:09:15.066 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :500/1167 loss:0.0034\n",
      "2022-09-19 15:09:18.329 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :600/1167 loss:0.0036\n",
      "2022-09-19 15:09:21.456 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :700/1167 loss:0.0152\n",
      "2022-09-19 15:09:24.518 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :800/1167 loss:0.0030\n",
      "2022-09-19 15:09:27.421 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :900/1167 loss:0.0251\n",
      "2022-09-19 15:09:30.177 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :1000/1167 loss:0.0065\n",
      "2022-09-19 15:09:33.022 | INFO     | __main__:train_seq2seq_model:62 - Epoch :35/100, iteration :1100/1167 loss:0.0054\n",
      "2022-09-19 15:09:34.998 | INFO     | __main__:train_seq2seq_model:65 - Epoch :35/100, training loss:0.0075\n",
      "2022-09-19 15:09:36.423 | INFO     | __main__:train_seq2seq_model:69 - Epoch:35, dev loss:0.0075\n",
      "2022-09-19 15:09:36.437 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :0/1167 loss:0.0507\n",
      "2022-09-19 15:09:39.137 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :100/1167 loss:0.0059\n",
      "2022-09-19 15:09:42.353 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :200/1167 loss:0.0090\n",
      "2022-09-19 15:09:45.272 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :300/1167 loss:0.0027\n",
      "2022-09-19 15:09:48.133 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :400/1167 loss:0.0136\n",
      "2022-09-19 15:09:51.011 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :500/1167 loss:0.0031\n",
      "2022-09-19 15:09:54.286 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :600/1167 loss:0.0046\n",
      "2022-09-19 15:09:57.414 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :700/1167 loss:0.0152\n",
      "2022-09-19 15:10:00.472 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :800/1167 loss:0.0037\n",
      "2022-09-19 15:10:03.369 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :900/1167 loss:0.0242\n",
      "2022-09-19 15:10:06.142 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :1000/1167 loss:0.0057\n",
      "2022-09-19 15:10:08.988 | INFO     | __main__:train_seq2seq_model:62 - Epoch :36/100, iteration :1100/1167 loss:0.0093\n",
      "2022-09-19 15:10:10.965 | INFO     | __main__:train_seq2seq_model:65 - Epoch :36/100, training loss:0.0067\n",
      "2022-09-19 15:10:12.366 | INFO     | __main__:train_seq2seq_model:69 - Epoch:36, dev loss:0.0067\n",
      "2022-09-19 15:10:12.371 | INFO     | __main__:train_seq2seq_model:77 - Epoch:36, save new bert model:output/RNA/seq2seq.pth\n",
      "2022-09-19 15:10:12.385 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :0/1167 loss:0.0531\n",
      "2022-09-19 15:10:15.088 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :100/1167 loss:0.0039\n",
      "2022-09-19 15:10:18.308 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :200/1167 loss:0.0075\n",
      "2022-09-19 15:10:21.222 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :300/1167 loss:0.0023\n",
      "2022-09-19 15:10:24.079 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :400/1167 loss:0.0162\n",
      "2022-09-19 15:10:26.953 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :500/1167 loss:0.0057\n",
      "2022-09-19 15:10:30.223 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :600/1167 loss:0.0026\n",
      "2022-09-19 15:10:33.353 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :700/1167 loss:0.0161\n",
      "2022-09-19 15:10:36.410 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :800/1167 loss:0.0036\n",
      "2022-09-19 15:10:39.298 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :900/1167 loss:0.0273\n",
      "2022-09-19 15:10:42.062 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :1000/1167 loss:0.0044\n",
      "2022-09-19 15:10:44.913 | INFO     | __main__:train_seq2seq_model:62 - Epoch :37/100, iteration :1100/1167 loss:0.0055\n",
      "2022-09-19 15:10:46.885 | INFO     | __main__:train_seq2seq_model:65 - Epoch :37/100, training loss:0.0068\n",
      "2022-09-19 15:10:48.287 | INFO     | __main__:train_seq2seq_model:69 - Epoch:37, dev loss:0.0071\n",
      "2022-09-19 15:10:48.301 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :0/1167 loss:0.0565\n",
      "2022-09-19 15:10:50.998 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :100/1167 loss:0.0037\n",
      "2022-09-19 15:10:54.218 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :200/1167 loss:0.0078\n",
      "2022-09-19 15:10:57.131 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :300/1167 loss:0.0031\n",
      "2022-09-19 15:10:59.995 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :400/1167 loss:0.0153\n",
      "2022-09-19 15:11:02.873 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :500/1167 loss:0.0074\n",
      "2022-09-19 15:11:06.142 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :600/1167 loss:0.0033\n",
      "2022-09-19 15:11:09.270 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :700/1167 loss:0.0228\n",
      "2022-09-19 15:11:12.330 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :800/1167 loss:0.0112\n",
      "2022-09-19 15:11:15.219 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :900/1167 loss:0.0277\n",
      "2022-09-19 15:11:17.973 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :1000/1167 loss:0.0043\n",
      "2022-09-19 15:11:20.822 | INFO     | __main__:train_seq2seq_model:62 - Epoch :38/100, iteration :1100/1167 loss:0.0051\n",
      "2022-09-19 15:11:22.797 | INFO     | __main__:train_seq2seq_model:65 - Epoch :38/100, training loss:0.0079\n",
      "2022-09-19 15:11:24.198 | INFO     | __main__:train_seq2seq_model:69 - Epoch:38, dev loss:0.0075\n",
      "2022-09-19 15:11:24.212 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :0/1167 loss:0.0524\n",
      "2022-09-19 15:11:26.915 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :100/1167 loss:0.0061\n",
      "2022-09-19 15:11:30.129 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :200/1167 loss:0.0077\n",
      "2022-09-19 15:11:33.050 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :300/1167 loss:0.0024\n",
      "2022-09-19 15:11:35.914 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :400/1167 loss:0.0162\n",
      "2022-09-19 15:11:38.792 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :500/1167 loss:0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 15:11:42.063 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :600/1167 loss:0.0030\n",
      "2022-09-19 15:11:45.186 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :700/1167 loss:0.0194\n",
      "2022-09-19 15:11:48.251 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :800/1167 loss:0.0025\n",
      "2022-09-19 15:11:51.140 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :900/1167 loss:0.0267\n",
      "2022-09-19 15:11:53.899 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :1000/1167 loss:0.0040\n",
      "2022-09-19 15:11:56.749 | INFO     | __main__:train_seq2seq_model:62 - Epoch :39/100, iteration :1100/1167 loss:0.0049\n",
      "2022-09-19 15:11:58.724 | INFO     | __main__:train_seq2seq_model:65 - Epoch :39/100, training loss:0.0072\n",
      "2022-09-19 15:12:00.126 | INFO     | __main__:train_seq2seq_model:69 - Epoch:39, dev loss:0.0072\n",
      "2022-09-19 15:12:00.140 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :0/1167 loss:0.0508\n",
      "2022-09-19 15:12:02.853 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :100/1167 loss:0.0064\n",
      "2022-09-19 15:12:06.068 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :200/1167 loss:0.0038\n",
      "2022-09-19 15:12:08.977 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :300/1167 loss:0.0078\n",
      "2022-09-19 15:12:11.839 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :400/1167 loss:0.0117\n",
      "2022-09-19 15:12:14.726 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :500/1167 loss:0.0036\n",
      "2022-09-19 15:12:17.993 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :600/1167 loss:0.0038\n",
      "2022-09-19 15:12:21.118 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :700/1167 loss:0.0188\n",
      "2022-09-19 15:12:24.182 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :800/1167 loss:0.0024\n",
      "2022-09-19 15:12:27.065 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :900/1167 loss:0.0263\n",
      "2022-09-19 15:12:29.829 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :1000/1167 loss:0.0035\n",
      "2022-09-19 15:12:32.714 | INFO     | __main__:train_seq2seq_model:62 - Epoch :40/100, iteration :1100/1167 loss:0.0083\n",
      "2022-09-19 15:12:34.706 | INFO     | __main__:train_seq2seq_model:65 - Epoch :40/100, training loss:0.0079\n",
      "2022-09-19 15:12:36.118 | INFO     | __main__:train_seq2seq_model:69 - Epoch:40, dev loss:0.0074\n",
      "2022-09-19 15:12:36.132 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :0/1167 loss:0.0469\n",
      "2022-09-19 15:12:38.827 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :100/1167 loss:0.0040\n",
      "2022-09-19 15:12:42.049 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :200/1167 loss:0.0063\n",
      "2022-09-19 15:12:44.957 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :300/1167 loss:0.0029\n",
      "2022-09-19 15:12:47.821 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :400/1167 loss:0.0113\n",
      "2022-09-19 15:12:50.704 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :500/1167 loss:0.0039\n",
      "2022-09-19 15:12:53.976 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :600/1167 loss:0.0038\n",
      "2022-09-19 15:12:57.092 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :700/1167 loss:0.0157\n",
      "2022-09-19 15:13:00.154 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :800/1167 loss:0.0016\n",
      "2022-09-19 15:13:03.047 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :900/1167 loss:0.0239\n",
      "2022-09-19 15:13:05.814 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :1000/1167 loss:0.0098\n",
      "2022-09-19 15:13:08.665 | INFO     | __main__:train_seq2seq_model:62 - Epoch :41/100, iteration :1100/1167 loss:0.0058\n",
      "2022-09-19 15:13:10.639 | INFO     | __main__:train_seq2seq_model:65 - Epoch :41/100, training loss:0.0067\n",
      "2022-09-19 15:13:12.086 | INFO     | __main__:train_seq2seq_model:69 - Epoch:41, dev loss:0.0077\n",
      "2022-09-19 15:13:12.100 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :0/1167 loss:0.0520\n",
      "2022-09-19 15:13:14.798 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :100/1167 loss:0.0088\n",
      "2022-09-19 15:13:18.012 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :200/1167 loss:0.0070\n",
      "2022-09-19 15:13:20.938 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :300/1167 loss:0.0042\n",
      "2022-09-19 15:13:23.801 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :400/1167 loss:0.0205\n",
      "2022-09-19 15:13:26.681 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :500/1167 loss:0.0040\n",
      "2022-09-19 15:13:29.939 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :600/1167 loss:0.0041\n",
      "2022-09-19 15:13:33.068 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :700/1167 loss:0.0160\n",
      "2022-09-19 15:13:36.129 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :800/1167 loss:0.0025\n",
      "2022-09-19 15:13:39.017 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :900/1167 loss:0.0266\n",
      "2022-09-19 15:13:41.775 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :1000/1167 loss:0.0078\n",
      "2022-09-19 15:13:44.633 | INFO     | __main__:train_seq2seq_model:62 - Epoch :42/100, iteration :1100/1167 loss:0.0052\n",
      "2022-09-19 15:13:46.610 | INFO     | __main__:train_seq2seq_model:65 - Epoch :42/100, training loss:0.0072\n",
      "2022-09-19 15:13:48.015 | INFO     | __main__:train_seq2seq_model:69 - Epoch:42, dev loss:0.0073\n",
      "2022-09-19 15:13:48.028 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :0/1167 loss:0.0500\n",
      "2022-09-19 15:13:50.735 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :100/1167 loss:0.0039\n",
      "2022-09-19 15:13:53.959 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :200/1167 loss:0.0035\n",
      "2022-09-19 15:13:56.871 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :300/1167 loss:0.0090\n",
      "2022-09-19 15:13:59.734 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :400/1167 loss:0.0165\n",
      "2022-09-19 15:14:02.617 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :500/1167 loss:0.0093\n",
      "2022-09-19 15:14:05.892 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :600/1167 loss:0.0023\n",
      "2022-09-19 15:14:09.021 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :700/1167 loss:0.0178\n",
      "2022-09-19 15:14:12.089 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :800/1167 loss:0.0026\n",
      "2022-09-19 15:14:14.976 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :900/1167 loss:0.0259\n",
      "2022-09-19 15:14:17.737 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :1000/1167 loss:0.0037\n",
      "2022-09-19 15:14:20.590 | INFO     | __main__:train_seq2seq_model:62 - Epoch :43/100, iteration :1100/1167 loss:0.0079\n",
      "2022-09-19 15:14:22.560 | INFO     | __main__:train_seq2seq_model:65 - Epoch :43/100, training loss:0.0073\n",
      "2022-09-19 15:14:23.987 | INFO     | __main__:train_seq2seq_model:69 - Epoch:43, dev loss:0.0075\n",
      "2022-09-19 15:14:24.000 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :0/1167 loss:0.0460\n",
      "2022-09-19 15:14:26.704 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :100/1167 loss:0.0040\n",
      "2022-09-19 15:14:29.921 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :200/1167 loss:0.0033\n",
      "2022-09-19 15:14:32.844 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :300/1167 loss:0.0027\n",
      "2022-09-19 15:14:35.704 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :400/1167 loss:0.0196\n",
      "2022-09-19 15:14:38.586 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :500/1167 loss:0.0061\n",
      "2022-09-19 15:14:41.861 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :600/1167 loss:0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 15:14:44.996 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :700/1167 loss:0.0179\n",
      "2022-09-19 15:14:48.058 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :800/1167 loss:0.0029\n",
      "2022-09-19 15:14:50.940 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :900/1167 loss:0.0263\n",
      "2022-09-19 15:14:53.699 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :1000/1167 loss:0.0056\n",
      "2022-09-19 15:14:56.567 | INFO     | __main__:train_seq2seq_model:62 - Epoch :44/100, iteration :1100/1167 loss:0.0051\n",
      "2022-09-19 15:14:58.545 | INFO     | __main__:train_seq2seq_model:65 - Epoch :44/100, training loss:0.0077\n",
      "2022-09-19 15:14:59.942 | INFO     | __main__:train_seq2seq_model:69 - Epoch:44, dev loss:0.0073\n",
      "2022-09-19 15:14:59.956 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :0/1167 loss:0.0483\n",
      "2022-09-19 15:15:02.669 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :100/1167 loss:0.0037\n",
      "2022-09-19 15:15:05.909 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :200/1167 loss:0.0032\n",
      "2022-09-19 15:15:08.837 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :300/1167 loss:0.0021\n",
      "2022-09-19 15:15:11.839 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :400/1167 loss:0.0105\n",
      "2022-09-19 15:15:14.882 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :500/1167 loss:0.0036\n",
      "2022-09-19 15:15:18.293 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :600/1167 loss:0.0016\n",
      "2022-09-19 15:15:21.514 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :700/1167 loss:0.0182\n",
      "2022-09-19 15:15:24.746 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :800/1167 loss:0.0025\n",
      "2022-09-19 15:15:27.711 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :900/1167 loss:0.0237\n",
      "2022-09-19 15:15:30.473 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :1000/1167 loss:0.0068\n",
      "2022-09-19 15:15:33.331 | INFO     | __main__:train_seq2seq_model:62 - Epoch :45/100, iteration :1100/1167 loss:0.0049\n",
      "2022-09-19 15:15:35.303 | INFO     | __main__:train_seq2seq_model:65 - Epoch :45/100, training loss:0.0066\n",
      "2022-09-19 15:15:36.694 | INFO     | __main__:train_seq2seq_model:69 - Epoch:45, dev loss:0.0077\n",
      "2022-09-19 15:15:36.708 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :0/1167 loss:0.0521\n",
      "2022-09-19 15:15:39.433 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :100/1167 loss:0.0067\n",
      "2022-09-19 15:15:42.642 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :200/1167 loss:0.0032\n",
      "2022-09-19 15:15:45.560 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :300/1167 loss:0.0025\n",
      "2022-09-19 15:15:48.423 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :400/1167 loss:0.0110\n",
      "2022-09-19 15:15:51.313 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :500/1167 loss:0.0031\n",
      "2022-09-19 15:15:54.593 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :600/1167 loss:0.0044\n",
      "2022-09-19 15:15:57.734 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :700/1167 loss:0.0146\n",
      "2022-09-19 15:16:00.795 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :800/1167 loss:0.0030\n",
      "2022-09-19 15:16:03.781 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :900/1167 loss:0.0245\n",
      "2022-09-19 15:16:06.569 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :1000/1167 loss:0.0041\n",
      "2022-09-19 15:16:09.457 | INFO     | __main__:train_seq2seq_model:62 - Epoch :46/100, iteration :1100/1167 loss:0.0065\n",
      "2022-09-19 15:16:11.434 | INFO     | __main__:train_seq2seq_model:65 - Epoch :46/100, training loss:0.0072\n",
      "2022-09-19 15:16:12.875 | INFO     | __main__:train_seq2seq_model:69 - Epoch:46, dev loss:0.0081\n",
      "2022-09-19 15:16:12.888 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :0/1167 loss:0.0450\n",
      "2022-09-19 15:16:15.641 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :100/1167 loss:0.0072\n",
      "2022-09-19 15:16:18.879 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :200/1167 loss:0.0034\n",
      "2022-09-19 15:16:21.818 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :300/1167 loss:0.0026\n",
      "2022-09-19 15:16:24.681 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :400/1167 loss:0.0100\n",
      "2022-09-19 15:16:27.580 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :500/1167 loss:0.0047\n",
      "2022-09-19 15:16:30.847 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :600/1167 loss:0.0031\n",
      "2022-09-19 15:16:33.997 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :700/1167 loss:0.0202\n",
      "2022-09-19 15:16:37.053 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :800/1167 loss:0.0025\n",
      "2022-09-19 15:16:39.952 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :900/1167 loss:0.0232\n",
      "2022-09-19 15:16:42.714 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :1000/1167 loss:0.0091\n",
      "2022-09-19 15:16:45.584 | INFO     | __main__:train_seq2seq_model:62 - Epoch :47/100, iteration :1100/1167 loss:0.0048\n",
      "2022-09-19 15:16:47.565 | INFO     | __main__:train_seq2seq_model:65 - Epoch :47/100, training loss:0.0071\n",
      "2022-09-19 15:16:48.995 | INFO     | __main__:train_seq2seq_model:69 - Epoch:47, dev loss:0.0076\n",
      "2022-09-19 15:16:49.009 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :0/1167 loss:0.0478\n",
      "2022-09-19 15:16:51.728 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :100/1167 loss:0.0065\n",
      "2022-09-19 15:16:54.952 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :200/1167 loss:0.0075\n",
      "2022-09-19 15:16:57.883 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :300/1167 loss:0.0026\n",
      "2022-09-19 15:17:00.742 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :400/1167 loss:0.0171\n",
      "2022-09-19 15:17:03.645 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :500/1167 loss:0.0054\n",
      "2022-09-19 15:17:06.910 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :600/1167 loss:0.0024\n",
      "2022-09-19 15:17:10.062 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :700/1167 loss:0.0183\n",
      "2022-09-19 15:17:13.161 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :800/1167 loss:0.0063\n",
      "2022-09-19 15:17:16.122 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :900/1167 loss:0.0238\n",
      "2022-09-19 15:17:18.891 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :1000/1167 loss:0.0064\n",
      "2022-09-19 15:17:21.765 | INFO     | __main__:train_seq2seq_model:62 - Epoch :48/100, iteration :1100/1167 loss:0.0053\n",
      "2022-09-19 15:17:23.748 | INFO     | __main__:train_seq2seq_model:65 - Epoch :48/100, training loss:0.0070\n",
      "2022-09-19 15:17:25.163 | INFO     | __main__:train_seq2seq_model:69 - Epoch:48, dev loss:0.0080\n",
      "2022-09-19 15:17:25.177 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :0/1167 loss:0.0436\n",
      "2022-09-19 15:17:27.916 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :100/1167 loss:0.0051\n",
      "2022-09-19 15:17:31.150 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :200/1167 loss:0.0034\n",
      "2022-09-19 15:17:34.085 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :300/1167 loss:0.0036\n",
      "2022-09-19 15:17:36.948 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :400/1167 loss:0.0122\n",
      "2022-09-19 15:17:39.845 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :500/1167 loss:0.0079\n",
      "2022-09-19 15:17:43.120 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :600/1167 loss:0.0019\n",
      "2022-09-19 15:17:46.268 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :700/1167 loss:0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 15:17:49.326 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :800/1167 loss:0.0052\n",
      "2022-09-19 15:17:52.234 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :900/1167 loss:0.0247\n",
      "2022-09-19 15:17:54.993 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :1000/1167 loss:0.0058\n",
      "2022-09-19 15:17:57.860 | INFO     | __main__:train_seq2seq_model:62 - Epoch :49/100, iteration :1100/1167 loss:0.0051\n",
      "2022-09-19 15:17:59.833 | INFO     | __main__:train_seq2seq_model:65 - Epoch :49/100, training loss:0.0077\n",
      "2022-09-19 15:18:01.229 | INFO     | __main__:train_seq2seq_model:69 - Epoch:49, dev loss:0.0089\n",
      "2022-09-19 15:18:01.243 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :0/1167 loss:0.0433\n",
      "2022-09-19 15:18:03.964 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :100/1167 loss:0.0077\n",
      "2022-09-19 15:18:07.192 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :200/1167 loss:0.0035\n",
      "2022-09-19 15:18:10.136 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :300/1167 loss:0.0045\n",
      "2022-09-19 15:18:12.995 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :400/1167 loss:0.0178\n",
      "2022-09-19 15:18:15.891 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :500/1167 loss:0.0076\n",
      "2022-09-19 15:18:19.165 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :600/1167 loss:0.0023\n",
      "2022-09-19 15:18:22.333 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :700/1167 loss:0.0143\n",
      "2022-09-19 15:18:25.386 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :800/1167 loss:0.0029\n",
      "2022-09-19 15:18:28.293 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :900/1167 loss:0.0263\n",
      "2022-09-19 15:18:31.053 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :1000/1167 loss:0.0036\n",
      "2022-09-19 15:18:33.916 | INFO     | __main__:train_seq2seq_model:62 - Epoch :50/100, iteration :1100/1167 loss:0.0053\n",
      "2022-09-19 15:18:35.894 | INFO     | __main__:train_seq2seq_model:65 - Epoch :50/100, training loss:0.0070\n",
      "2022-09-19 15:18:37.292 | INFO     | __main__:train_seq2seq_model:69 - Epoch:50, dev loss:0.0073\n",
      "2022-09-19 15:18:37.306 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :0/1167 loss:0.0399\n",
      "2022-09-19 15:18:40.019 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :100/1167 loss:0.0076\n",
      "2022-09-19 15:18:43.232 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :200/1167 loss:0.0104\n",
      "2022-09-19 15:18:46.164 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :300/1167 loss:0.0046\n",
      "2022-09-19 15:18:49.020 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :400/1167 loss:0.0115\n",
      "2022-09-19 15:18:51.909 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :500/1167 loss:0.0038\n",
      "2022-09-19 15:18:55.172 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :600/1167 loss:0.0034\n",
      "2022-09-19 15:18:58.316 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :700/1167 loss:0.0156\n",
      "2022-09-19 15:19:01.374 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :800/1167 loss:0.0044\n",
      "2022-09-19 15:19:04.279 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :900/1167 loss:0.0269\n",
      "2022-09-19 15:19:07.038 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :1000/1167 loss:0.0053\n",
      "2022-09-19 15:19:09.910 | INFO     | __main__:train_seq2seq_model:62 - Epoch :51/100, iteration :1100/1167 loss:0.0052\n",
      "2022-09-19 15:19:11.889 | INFO     | __main__:train_seq2seq_model:65 - Epoch :51/100, training loss:0.0072\n",
      "2022-09-19 15:19:13.306 | INFO     | __main__:train_seq2seq_model:69 - Epoch:51, dev loss:0.0077\n",
      "2022-09-19 15:19:13.321 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :0/1167 loss:0.0401\n",
      "2022-09-19 15:19:16.038 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :100/1167 loss:0.0056\n",
      "2022-09-19 15:19:19.261 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :200/1167 loss:0.0073\n",
      "2022-09-19 15:19:22.195 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :300/1167 loss:0.0031\n",
      "2022-09-19 15:19:25.055 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :400/1167 loss:0.0143\n",
      "2022-09-19 15:19:27.952 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :500/1167 loss:0.0044\n",
      "2022-09-19 15:19:31.214 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :600/1167 loss:0.0034\n",
      "2022-09-19 15:19:34.366 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :700/1167 loss:0.0175\n",
      "2022-09-19 15:19:37.423 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :800/1167 loss:0.0034\n",
      "2022-09-19 15:19:40.333 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :900/1167 loss:0.0252\n",
      "2022-09-19 15:19:43.093 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :1000/1167 loss:0.0078\n",
      "2022-09-19 15:19:45.956 | INFO     | __main__:train_seq2seq_model:62 - Epoch :52/100, iteration :1100/1167 loss:0.0077\n",
      "2022-09-19 15:19:47.940 | INFO     | __main__:train_seq2seq_model:65 - Epoch :52/100, training loss:0.0070\n",
      "2022-09-19 15:19:49.359 | INFO     | __main__:train_seq2seq_model:69 - Epoch:52, dev loss:0.0072\n",
      "2022-09-19 15:19:49.373 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :0/1167 loss:0.0362\n",
      "2022-09-19 15:19:52.089 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :100/1167 loss:0.0037\n",
      "2022-09-19 15:19:55.301 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :200/1167 loss:0.0034\n",
      "2022-09-19 15:19:58.238 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :300/1167 loss:0.0029\n",
      "2022-09-19 15:20:01.092 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :400/1167 loss:0.0122\n",
      "2022-09-19 15:20:03.986 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :500/1167 loss:0.0046\n",
      "2022-09-19 15:20:07.252 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :600/1167 loss:0.0044\n",
      "2022-09-19 15:20:10.395 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :700/1167 loss:0.0151\n",
      "2022-09-19 15:20:13.452 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :800/1167 loss:0.0046\n",
      "2022-09-19 15:20:16.350 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :900/1167 loss:0.0241\n",
      "2022-09-19 15:20:19.137 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :1000/1167 loss:0.0063\n",
      "2022-09-19 15:20:22.004 | INFO     | __main__:train_seq2seq_model:62 - Epoch :53/100, iteration :1100/1167 loss:0.0061\n",
      "2022-09-19 15:20:23.979 | INFO     | __main__:train_seq2seq_model:65 - Epoch :53/100, training loss:0.0066\n",
      "2022-09-19 15:20:25.382 | INFO     | __main__:train_seq2seq_model:69 - Epoch:53, dev loss:0.0075\n",
      "2022-09-19 15:20:25.395 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :0/1167 loss:0.0368\n",
      "2022-09-19 15:20:28.112 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :100/1167 loss:0.0037\n",
      "2022-09-19 15:20:31.330 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :200/1167 loss:0.0033\n",
      "2022-09-19 15:20:34.259 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :300/1167 loss:0.0028\n",
      "2022-09-19 15:20:37.120 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :400/1167 loss:0.0108\n",
      "2022-09-19 15:20:40.010 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :500/1167 loss:0.0049\n",
      "2022-09-19 15:20:43.272 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :600/1167 loss:0.0020\n",
      "2022-09-19 15:20:46.417 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :700/1167 loss:0.0157\n",
      "2022-09-19 15:20:49.477 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :800/1167 loss:0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 15:20:52.389 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :900/1167 loss:0.0248\n",
      "2022-09-19 15:20:55.150 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :1000/1167 loss:0.0067\n",
      "2022-09-19 15:20:58.011 | INFO     | __main__:train_seq2seq_model:62 - Epoch :54/100, iteration :1100/1167 loss:0.0057\n",
      "2022-09-19 15:20:59.990 | INFO     | __main__:train_seq2seq_model:65 - Epoch :54/100, training loss:0.0075\n",
      "2022-09-19 15:21:01.427 | INFO     | __main__:train_seq2seq_model:69 - Epoch:54, dev loss:0.0080\n",
      "2022-09-19 15:21:01.440 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :0/1167 loss:0.0381\n",
      "2022-09-19 15:21:04.164 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :100/1167 loss:0.0039\n",
      "2022-09-19 15:21:07.380 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :200/1167 loss:0.0044\n",
      "2022-09-19 15:21:10.314 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :300/1167 loss:0.0024\n",
      "2022-09-19 15:21:13.170 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :400/1167 loss:0.0155\n",
      "2022-09-19 15:21:16.063 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :500/1167 loss:0.0028\n",
      "2022-09-19 15:21:19.328 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :600/1167 loss:0.0016\n",
      "2022-09-19 15:21:22.471 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :700/1167 loss:0.0161\n",
      "2022-09-19 15:21:25.529 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :800/1167 loss:0.0017\n",
      "2022-09-19 15:21:28.478 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :900/1167 loss:0.0238\n",
      "2022-09-19 15:21:31.253 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :1000/1167 loss:0.0063\n",
      "2022-09-19 15:21:34.120 | INFO     | __main__:train_seq2seq_model:62 - Epoch :55/100, iteration :1100/1167 loss:0.0089\n",
      "2022-09-19 15:21:36.093 | INFO     | __main__:train_seq2seq_model:65 - Epoch :55/100, training loss:0.0071\n",
      "2022-09-19 15:21:37.500 | INFO     | __main__:train_seq2seq_model:69 - Epoch:55, dev loss:0.0076\n",
      "2022-09-19 15:21:37.514 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :0/1167 loss:0.0370\n",
      "2022-09-19 15:21:40.234 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :100/1167 loss:0.0089\n",
      "2022-09-19 15:21:43.443 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :200/1167 loss:0.0070\n",
      "2022-09-19 15:21:46.371 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :300/1167 loss:0.0075\n",
      "2022-09-19 15:21:49.240 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :400/1167 loss:0.0255\n",
      "2022-09-19 15:21:52.133 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :500/1167 loss:0.0025\n",
      "2022-09-19 15:21:55.402 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :600/1167 loss:0.0024\n",
      "2022-09-19 15:21:58.536 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :700/1167 loss:0.0139\n",
      "2022-09-19 15:22:01.596 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :800/1167 loss:0.0026\n",
      "2022-09-19 15:22:04.502 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :900/1167 loss:0.0238\n",
      "2022-09-19 15:22:07.271 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :1000/1167 loss:0.0034\n",
      "2022-09-19 15:22:10.133 | INFO     | __main__:train_seq2seq_model:62 - Epoch :56/100, iteration :1100/1167 loss:0.0053\n",
      "2022-09-19 15:22:12.111 | INFO     | __main__:train_seq2seq_model:65 - Epoch :56/100, training loss:0.0073\n",
      "2022-09-19 15:22:13.519 | INFO     | __main__:train_seq2seq_model:69 - Epoch:56, dev loss:0.0074\n",
      "2022-09-19 15:22:13.532 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :0/1167 loss:0.0363\n",
      "2022-09-19 15:22:16.247 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :100/1167 loss:0.0049\n",
      "2022-09-19 15:22:19.464 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :200/1167 loss:0.0073\n",
      "2022-09-19 15:22:22.399 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :300/1167 loss:0.0025\n",
      "2022-09-19 15:22:25.261 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :400/1167 loss:0.0132\n",
      "2022-09-19 15:22:28.165 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :500/1167 loss:0.0027\n",
      "2022-09-19 15:22:31.434 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :600/1167 loss:0.0037\n",
      "2022-09-19 15:22:34.567 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :700/1167 loss:0.0155\n",
      "2022-09-19 15:22:37.633 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :800/1167 loss:0.0056\n",
      "2022-09-19 15:22:40.527 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :900/1167 loss:0.0261\n",
      "2022-09-19 15:22:43.290 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :1000/1167 loss:0.0041\n",
      "2022-09-19 15:22:46.146 | INFO     | __main__:train_seq2seq_model:62 - Epoch :57/100, iteration :1100/1167 loss:0.0060\n",
      "2022-09-19 15:22:48.127 | INFO     | __main__:train_seq2seq_model:65 - Epoch :57/100, training loss:0.0069\n",
      "2022-09-19 15:22:49.520 | INFO     | __main__:train_seq2seq_model:69 - Epoch:57, dev loss:0.0074\n",
      "2022-09-19 15:22:49.534 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :0/1167 loss:0.0350\n",
      "2022-09-19 15:22:52.246 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :100/1167 loss:0.0039\n",
      "2022-09-19 15:22:55.472 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :200/1167 loss:0.0042\n",
      "2022-09-19 15:22:58.403 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :300/1167 loss:0.0029\n",
      "2022-09-19 15:23:01.267 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :400/1167 loss:0.0124\n",
      "2022-09-19 15:23:04.171 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :500/1167 loss:0.0026\n",
      "2022-09-19 15:23:07.435 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :600/1167 loss:0.0036\n",
      "2022-09-19 15:23:10.571 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :700/1167 loss:0.0195\n",
      "2022-09-19 15:23:13.638 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :800/1167 loss:0.0028\n",
      "2022-09-19 15:23:16.543 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :900/1167 loss:0.0234\n",
      "2022-09-19 15:23:19.320 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :1000/1167 loss:0.0076\n",
      "2022-09-19 15:23:22.190 | INFO     | __main__:train_seq2seq_model:62 - Epoch :58/100, iteration :1100/1167 loss:0.0059\n",
      "2022-09-19 15:23:24.165 | INFO     | __main__:train_seq2seq_model:65 - Epoch :58/100, training loss:0.0068\n",
      "2022-09-19 15:23:25.566 | INFO     | __main__:train_seq2seq_model:69 - Epoch:58, dev loss:0.0071\n",
      "2022-09-19 15:23:25.580 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :0/1167 loss:0.0402\n",
      "2022-09-19 15:23:28.300 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :100/1167 loss:0.0038\n",
      "2022-09-19 15:23:31.520 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :200/1167 loss:0.0071\n",
      "2022-09-19 15:23:34.445 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :300/1167 loss:0.0033\n",
      "2022-09-19 15:23:37.309 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :400/1167 loss:0.0103\n",
      "2022-09-19 15:23:40.206 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :500/1167 loss:0.0045\n",
      "2022-09-19 15:23:43.470 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :600/1167 loss:0.0036\n",
      "2022-09-19 15:23:46.610 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :700/1167 loss:0.0143\n",
      "2022-09-19 15:23:49.673 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :800/1167 loss:0.0041\n",
      "2022-09-19 15:23:52.563 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :900/1167 loss:0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 15:23:55.336 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :1000/1167 loss:0.0032\n",
      "2022-09-19 15:23:58.192 | INFO     | __main__:train_seq2seq_model:62 - Epoch :59/100, iteration :1100/1167 loss:0.0048\n",
      "2022-09-19 15:24:00.174 | INFO     | __main__:train_seq2seq_model:65 - Epoch :59/100, training loss:0.0069\n",
      "2022-09-19 15:24:01.576 | INFO     | __main__:train_seq2seq_model:69 - Epoch:59, dev loss:0.0079\n",
      "2022-09-19 15:24:01.590 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :0/1167 loss:0.0341\n",
      "2022-09-19 15:24:04.311 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :100/1167 loss:0.0039\n",
      "2022-09-19 15:24:07.530 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :200/1167 loss:0.0032\n",
      "2022-09-19 15:24:10.452 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :300/1167 loss:0.0023\n",
      "2022-09-19 15:24:13.308 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :400/1167 loss:0.0207\n",
      "2022-09-19 15:24:16.207 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :500/1167 loss:0.0051\n",
      "2022-09-19 15:24:19.471 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :600/1167 loss:0.0053\n",
      "2022-09-19 15:24:22.613 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :700/1167 loss:0.0193\n",
      "2022-09-19 15:24:25.679 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :800/1167 loss:0.0015\n",
      "2022-09-19 15:24:28.575 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :900/1167 loss:0.0235\n",
      "2022-09-19 15:24:31.336 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :1000/1167 loss:0.0065\n",
      "2022-09-19 15:24:34.198 | INFO     | __main__:train_seq2seq_model:62 - Epoch :60/100, iteration :1100/1167 loss:0.0054\n",
      "2022-09-19 15:24:36.176 | INFO     | __main__:train_seq2seq_model:65 - Epoch :60/100, training loss:0.0070\n",
      "2022-09-19 15:24:37.574 | INFO     | __main__:train_seq2seq_model:69 - Epoch:60, dev loss:0.0088\n",
      "2022-09-19 15:24:37.587 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :0/1167 loss:0.0341\n",
      "2022-09-19 15:24:40.300 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :100/1167 loss:0.0037\n",
      "2022-09-19 15:24:43.517 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :200/1167 loss:0.0072\n",
      "2022-09-19 15:24:46.450 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :300/1167 loss:0.0052\n",
      "2022-09-19 15:24:49.311 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :400/1167 loss:0.0101\n",
      "2022-09-19 15:24:52.211 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :500/1167 loss:0.0028\n",
      "2022-09-19 15:24:55.475 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :600/1167 loss:0.0023\n",
      "2022-09-19 15:24:58.615 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :700/1167 loss:0.0185\n",
      "2022-09-19 15:25:01.674 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :800/1167 loss:0.0052\n",
      "2022-09-19 15:25:04.567 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :900/1167 loss:0.0247\n",
      "2022-09-19 15:25:07.327 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :1000/1167 loss:0.0110\n",
      "2022-09-19 15:25:10.195 | INFO     | __main__:train_seq2seq_model:62 - Epoch :61/100, iteration :1100/1167 loss:0.0075\n",
      "2022-09-19 15:25:12.175 | INFO     | __main__:train_seq2seq_model:65 - Epoch :61/100, training loss:0.0076\n",
      "2022-09-19 15:25:13.582 | INFO     | __main__:train_seq2seq_model:69 - Epoch:61, dev loss:0.0105\n",
      "2022-09-19 15:25:13.596 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :0/1167 loss:0.0377\n",
      "2022-09-19 15:25:16.315 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :100/1167 loss:0.0061\n",
      "2022-09-19 15:25:19.522 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :200/1167 loss:0.0044\n",
      "2022-09-19 15:25:22.454 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :300/1167 loss:0.0038\n",
      "2022-09-19 15:25:25.313 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :400/1167 loss:0.0153\n",
      "2022-09-19 15:25:28.214 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :500/1167 loss:0.0050\n",
      "2022-09-19 15:25:31.480 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :600/1167 loss:0.0074\n",
      "2022-09-19 15:25:34.614 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :700/1167 loss:0.0180\n",
      "2022-09-19 15:25:37.676 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :800/1167 loss:0.0037\n",
      "2022-09-19 15:25:40.574 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :900/1167 loss:0.0234\n",
      "2022-09-19 15:25:43.342 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :1000/1167 loss:0.0116\n",
      "2022-09-19 15:25:46.203 | INFO     | __main__:train_seq2seq_model:62 - Epoch :62/100, iteration :1100/1167 loss:0.0060\n",
      "2022-09-19 15:25:48.175 | INFO     | __main__:train_seq2seq_model:65 - Epoch :62/100, training loss:0.0079\n",
      "2022-09-19 15:25:49.566 | INFO     | __main__:train_seq2seq_model:69 - Epoch:62, dev loss:0.0081\n",
      "2022-09-19 15:25:49.580 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :0/1167 loss:0.0346\n",
      "2022-09-19 15:25:52.290 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :100/1167 loss:0.0056\n",
      "2022-09-19 15:25:55.509 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :200/1167 loss:0.0062\n",
      "2022-09-19 15:25:58.438 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :300/1167 loss:0.0026\n",
      "2022-09-19 15:26:01.301 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :400/1167 loss:0.0107\n",
      "2022-09-19 15:26:04.205 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :500/1167 loss:0.0025\n",
      "2022-09-19 15:26:07.465 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :600/1167 loss:0.0026\n",
      "2022-09-19 15:26:10.605 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :700/1167 loss:0.0200\n",
      "2022-09-19 15:26:13.667 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :800/1167 loss:0.0028\n",
      "2022-09-19 15:26:16.563 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :900/1167 loss:0.0228\n",
      "2022-09-19 15:26:19.321 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :1000/1167 loss:0.0067\n",
      "2022-09-19 15:26:22.188 | INFO     | __main__:train_seq2seq_model:62 - Epoch :63/100, iteration :1100/1167 loss:0.0079\n",
      "2022-09-19 15:26:24.168 | INFO     | __main__:train_seq2seq_model:65 - Epoch :63/100, training loss:0.0065\n",
      "2022-09-19 15:26:25.570 | INFO     | __main__:train_seq2seq_model:69 - Epoch:63, dev loss:0.0073\n",
      "2022-09-19 15:26:25.584 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :0/1167 loss:0.0329\n",
      "2022-09-19 15:26:28.297 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :100/1167 loss:0.0039\n",
      "2022-09-19 15:26:31.520 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :200/1167 loss:0.0040\n",
      "2022-09-19 15:26:34.444 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :300/1167 loss:0.0030\n",
      "2022-09-19 15:26:37.305 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :400/1167 loss:0.0102\n",
      "2022-09-19 15:26:40.196 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :500/1167 loss:0.0027\n",
      "2022-09-19 15:26:43.454 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :600/1167 loss:0.0033\n",
      "2022-09-19 15:26:46.587 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :700/1167 loss:0.0153\n",
      "2022-09-19 15:26:49.652 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :800/1167 loss:0.0036\n",
      "2022-09-19 15:26:52.553 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :900/1167 loss:0.0236\n",
      "2022-09-19 15:26:55.330 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :1000/1167 loss:0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 15:26:58.200 | INFO     | __main__:train_seq2seq_model:62 - Epoch :64/100, iteration :1100/1167 loss:0.0057\n",
      "2022-09-19 15:27:00.173 | INFO     | __main__:train_seq2seq_model:65 - Epoch :64/100, training loss:0.0068\n",
      "2022-09-19 15:27:01.574 | INFO     | __main__:train_seq2seq_model:69 - Epoch:64, dev loss:0.0077\n",
      "2022-09-19 15:27:01.588 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :0/1167 loss:0.0323\n",
      "2022-09-19 15:27:04.304 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :100/1167 loss:0.0037\n",
      "2022-09-19 15:27:07.522 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :200/1167 loss:0.0080\n",
      "2022-09-19 15:27:10.448 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :300/1167 loss:0.0023\n",
      "2022-09-19 15:27:13.307 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :400/1167 loss:0.0155\n",
      "2022-09-19 15:27:16.208 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :500/1167 loss:0.0038\n",
      "2022-09-19 15:27:19.473 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :600/1167 loss:0.0034\n",
      "2022-09-19 15:27:22.610 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :700/1167 loss:0.0151\n",
      "2022-09-19 15:27:25.676 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :800/1167 loss:0.0017\n",
      "2022-09-19 15:27:28.574 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :900/1167 loss:0.0233\n",
      "2022-09-19 15:27:31.336 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :1000/1167 loss:0.0033\n",
      "2022-09-19 15:27:34.198 | INFO     | __main__:train_seq2seq_model:62 - Epoch :65/100, iteration :1100/1167 loss:0.0047\n",
      "2022-09-19 15:27:36.177 | INFO     | __main__:train_seq2seq_model:65 - Epoch :65/100, training loss:0.0067\n",
      "2022-09-19 15:27:37.618 | INFO     | __main__:train_seq2seq_model:69 - Epoch:65, dev loss:0.0080\n",
      "2022-09-19 15:27:37.632 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :0/1167 loss:0.0326\n",
      "2022-09-19 15:27:40.352 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :100/1167 loss:0.0040\n",
      "2022-09-19 15:27:43.569 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :200/1167 loss:0.0087\n",
      "2022-09-19 15:27:46.494 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :300/1167 loss:0.0020\n",
      "2022-09-19 15:27:49.356 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :400/1167 loss:0.0110\n",
      "2022-09-19 15:27:52.249 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :500/1167 loss:0.0033\n",
      "2022-09-19 15:27:55.507 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :600/1167 loss:0.0043\n",
      "2022-09-19 15:27:58.644 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :700/1167 loss:0.0214\n",
      "2022-09-19 15:28:01.708 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :800/1167 loss:0.0045\n",
      "2022-09-19 15:28:04.601 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :900/1167 loss:0.0258\n",
      "2022-09-19 15:28:07.358 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :1000/1167 loss:0.0036\n",
      "2022-09-19 15:28:10.216 | INFO     | __main__:train_seq2seq_model:62 - Epoch :66/100, iteration :1100/1167 loss:0.0050\n",
      "2022-09-19 15:28:12.196 | INFO     | __main__:train_seq2seq_model:65 - Epoch :66/100, training loss:0.0065\n",
      "2022-09-19 15:28:13.600 | INFO     | __main__:train_seq2seq_model:69 - Epoch:66, dev loss:0.0079\n",
      "2022-09-19 15:28:13.614 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :0/1167 loss:0.0327\n",
      "2022-09-19 15:28:16.325 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :100/1167 loss:0.0041\n",
      "2022-09-19 15:28:19.557 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :200/1167 loss:0.0032\n",
      "2022-09-19 15:28:22.511 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :300/1167 loss:0.0022\n",
      "2022-09-19 15:28:25.378 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :400/1167 loss:0.0175\n",
      "2022-09-19 15:28:28.273 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :500/1167 loss:0.0027\n",
      "2022-09-19 15:28:31.531 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :600/1167 loss:0.0029\n",
      "2022-09-19 15:28:34.660 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :700/1167 loss:0.0201\n",
      "2022-09-19 15:28:37.727 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :800/1167 loss:0.0036\n",
      "2022-09-19 15:28:40.620 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :900/1167 loss:0.0245\n",
      "2022-09-19 15:28:43.396 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :1000/1167 loss:0.0037\n",
      "2022-09-19 15:28:46.260 | INFO     | __main__:train_seq2seq_model:62 - Epoch :67/100, iteration :1100/1167 loss:0.0114\n",
      "2022-09-19 15:28:48.232 | INFO     | __main__:train_seq2seq_model:65 - Epoch :67/100, training loss:0.0070\n",
      "2022-09-19 15:28:49.627 | INFO     | __main__:train_seq2seq_model:69 - Epoch:67, dev loss:0.0079\n",
      "2022-09-19 15:28:49.641 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :0/1167 loss:0.0371\n",
      "2022-09-19 15:28:52.361 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :100/1167 loss:0.0039\n",
      "2022-09-19 15:28:55.583 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :200/1167 loss:0.0065\n",
      "2022-09-19 15:28:58.511 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :300/1167 loss:0.0078\n",
      "2022-09-19 15:29:01.388 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :400/1167 loss:0.0113\n",
      "2022-09-19 15:29:04.282 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :500/1167 loss:0.0053\n",
      "2022-09-19 15:29:07.549 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :600/1167 loss:0.0020\n",
      "2022-09-19 15:29:10.685 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :700/1167 loss:0.0184\n",
      "2022-09-19 15:29:13.754 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :800/1167 loss:0.0037\n",
      "2022-09-19 15:29:16.647 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :900/1167 loss:0.0247\n",
      "2022-09-19 15:29:19.419 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :1000/1167 loss:0.0034\n",
      "2022-09-19 15:29:22.282 | INFO     | __main__:train_seq2seq_model:62 - Epoch :68/100, iteration :1100/1167 loss:0.0048\n",
      "2022-09-19 15:29:24.266 | INFO     | __main__:train_seq2seq_model:65 - Epoch :68/100, training loss:0.0070\n",
      "2022-09-19 15:29:25.675 | INFO     | __main__:train_seq2seq_model:69 - Epoch:68, dev loss:0.0076\n",
      "2022-09-19 15:29:25.689 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :0/1167 loss:0.0336\n",
      "2022-09-19 15:29:28.398 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :100/1167 loss:0.0040\n",
      "2022-09-19 15:29:31.610 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :200/1167 loss:0.0035\n",
      "2022-09-19 15:29:34.534 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :300/1167 loss:0.0023\n",
      "2022-09-19 15:29:37.399 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :400/1167 loss:0.0103\n",
      "2022-09-19 15:29:40.294 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :500/1167 loss:0.0050\n",
      "2022-09-19 15:29:43.560 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :600/1167 loss:0.0023\n",
      "2022-09-19 15:29:46.690 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :700/1167 loss:0.0153\n",
      "2022-09-19 15:29:49.756 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :800/1167 loss:0.0070\n",
      "2022-09-19 15:29:52.645 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :900/1167 loss:0.0257\n",
      "2022-09-19 15:29:55.413 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :1000/1167 loss:0.0032\n",
      "2022-09-19 15:29:58.278 | INFO     | __main__:train_seq2seq_model:62 - Epoch :69/100, iteration :1100/1167 loss:0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 15:30:00.255 | INFO     | __main__:train_seq2seq_model:65 - Epoch :69/100, training loss:0.0067\n",
      "2022-09-19 15:30:01.659 | INFO     | __main__:train_seq2seq_model:69 - Epoch:69, dev loss:0.0075\n",
      "2022-09-19 15:30:01.673 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :0/1167 loss:0.0326\n",
      "2022-09-19 15:30:04.387 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :100/1167 loss:0.0069\n",
      "2022-09-19 15:30:07.604 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :200/1167 loss:0.0056\n",
      "2022-09-19 15:30:10.538 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :300/1167 loss:0.0020\n",
      "2022-09-19 15:30:13.401 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :400/1167 loss:0.0112\n",
      "2022-09-19 15:30:16.298 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :500/1167 loss:0.0062\n",
      "2022-09-19 15:30:19.575 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :600/1167 loss:0.0022\n",
      "2022-09-19 15:30:22.718 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :700/1167 loss:0.0152\n",
      "2022-09-19 15:30:25.786 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :800/1167 loss:0.0039\n",
      "2022-09-19 15:30:28.675 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :900/1167 loss:0.0242\n",
      "2022-09-19 15:30:31.438 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :1000/1167 loss:0.0034\n",
      "2022-09-19 15:30:34.297 | INFO     | __main__:train_seq2seq_model:62 - Epoch :70/100, iteration :1100/1167 loss:0.0037\n",
      "2022-09-19 15:30:36.267 | INFO     | __main__:train_seq2seq_model:65 - Epoch :70/100, training loss:0.0067\n",
      "2022-09-19 15:30:37.684 | INFO     | __main__:train_seq2seq_model:69 - Epoch:70, dev loss:0.0080\n",
      "2022-09-19 15:30:37.698 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :0/1167 loss:0.0359\n",
      "2022-09-19 15:30:40.412 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :100/1167 loss:0.0068\n",
      "2022-09-19 15:30:43.625 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :200/1167 loss:0.0069\n",
      "2022-09-19 15:30:46.555 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :300/1167 loss:0.0035\n",
      "2022-09-19 15:30:49.418 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :400/1167 loss:0.0098\n",
      "2022-09-19 15:30:52.318 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :500/1167 loss:0.0073\n",
      "2022-09-19 15:30:55.579 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :600/1167 loss:0.0064\n",
      "2022-09-19 15:30:58.705 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :700/1167 loss:0.0154\n",
      "2022-09-19 15:31:01.779 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :800/1167 loss:0.0025\n",
      "2022-09-19 15:31:04.669 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :900/1167 loss:0.0243\n",
      "2022-09-19 15:31:07.437 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :1000/1167 loss:0.0104\n",
      "2022-09-19 15:31:10.299 | INFO     | __main__:train_seq2seq_model:62 - Epoch :71/100, iteration :1100/1167 loss:0.0136\n",
      "2022-09-19 15:31:12.276 | INFO     | __main__:train_seq2seq_model:65 - Epoch :71/100, training loss:0.0069\n",
      "2022-09-19 15:31:13.666 | INFO     | __main__:train_seq2seq_model:69 - Epoch:71, dev loss:0.0082\n",
      "2022-09-19 15:31:13.680 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :0/1167 loss:0.0356\n",
      "2022-09-19 15:31:16.390 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :100/1167 loss:0.0041\n",
      "2022-09-19 15:31:19.603 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :200/1167 loss:0.0046\n",
      "2022-09-19 15:31:22.537 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :300/1167 loss:0.0028\n",
      "2022-09-19 15:31:25.395 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :400/1167 loss:0.0100\n",
      "2022-09-19 15:31:28.294 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :500/1167 loss:0.0049\n",
      "2022-09-19 15:31:31.553 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :600/1167 loss:0.0041\n",
      "2022-09-19 15:31:34.683 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :700/1167 loss:0.0150\n",
      "2022-09-19 15:31:37.748 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :800/1167 loss:0.0057\n",
      "2022-09-19 15:31:40.637 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :900/1167 loss:0.0225\n",
      "2022-09-19 15:31:43.408 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :1000/1167 loss:0.0031\n",
      "2022-09-19 15:31:46.270 | INFO     | __main__:train_seq2seq_model:62 - Epoch :72/100, iteration :1100/1167 loss:0.0043\n",
      "2022-09-19 15:31:48.247 | INFO     | __main__:train_seq2seq_model:65 - Epoch :72/100, training loss:0.0069\n",
      "2022-09-19 15:31:49.642 | INFO     | __main__:train_seq2seq_model:69 - Epoch:72, dev loss:0.0080\n",
      "2022-09-19 15:31:49.656 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :0/1167 loss:0.0327\n",
      "2022-09-19 15:31:52.372 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :100/1167 loss:0.0041\n",
      "2022-09-19 15:31:55.589 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :200/1167 loss:0.0035\n",
      "2022-09-19 15:31:58.516 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :300/1167 loss:0.0018\n",
      "2022-09-19 15:32:01.386 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :400/1167 loss:0.0165\n",
      "2022-09-19 15:32:04.284 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :500/1167 loss:0.0031\n",
      "2022-09-19 15:32:07.545 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :600/1167 loss:0.0017\n",
      "2022-09-19 15:32:10.675 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :700/1167 loss:0.0167\n",
      "2022-09-19 15:32:13.744 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :800/1167 loss:0.0017\n",
      "2022-09-19 15:32:16.639 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :900/1167 loss:0.0262\n",
      "2022-09-19 15:32:19.394 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :1000/1167 loss:0.0033\n",
      "2022-09-19 15:32:22.261 | INFO     | __main__:train_seq2seq_model:62 - Epoch :73/100, iteration :1100/1167 loss:0.0046\n",
      "2022-09-19 15:32:24.237 | INFO     | __main__:train_seq2seq_model:65 - Epoch :73/100, training loss:0.0068\n",
      "2022-09-19 15:32:25.666 | INFO     | __main__:train_seq2seq_model:69 - Epoch:73, dev loss:0.0078\n",
      "2022-09-19 15:32:25.680 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :0/1167 loss:0.0325\n",
      "2022-09-19 15:32:28.392 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :100/1167 loss:0.0039\n",
      "2022-09-19 15:32:31.610 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :200/1167 loss:0.0071\n",
      "2022-09-19 15:32:34.530 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :300/1167 loss:0.0154\n",
      "2022-09-19 15:32:37.396 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :400/1167 loss:0.0097\n",
      "2022-09-19 15:32:40.304 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :500/1167 loss:0.0072\n",
      "2022-09-19 15:32:43.566 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :600/1167 loss:0.0031\n",
      "2022-09-19 15:32:46.699 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :700/1167 loss:0.0142\n",
      "2022-09-19 15:32:49.766 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :800/1167 loss:0.0036\n",
      "2022-09-19 15:32:52.661 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :900/1167 loss:0.0289\n",
      "2022-09-19 15:32:55.421 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :1000/1167 loss:0.0058\n",
      "2022-09-19 15:32:58.287 | INFO     | __main__:train_seq2seq_model:62 - Epoch :74/100, iteration :1100/1167 loss:0.0046\n",
      "2022-09-19 15:33:00.262 | INFO     | __main__:train_seq2seq_model:65 - Epoch :74/100, training loss:0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 15:33:01.674 | INFO     | __main__:train_seq2seq_model:69 - Epoch:74, dev loss:0.0080\n",
      "2022-09-19 15:33:01.688 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :0/1167 loss:0.0299\n",
      "2022-09-19 15:33:04.401 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :100/1167 loss:0.0041\n",
      "2022-09-19 15:33:07.630 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :200/1167 loss:0.0032\n",
      "2022-09-19 15:33:10.553 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :300/1167 loss:0.0026\n",
      "2022-09-19 15:33:13.420 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :400/1167 loss:0.0103\n",
      "2022-09-19 15:33:16.325 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :500/1167 loss:0.0031\n",
      "2022-09-19 15:33:19.605 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :600/1167 loss:0.0019\n",
      "2022-09-19 15:33:22.742 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :700/1167 loss:0.0169\n",
      "2022-09-19 15:33:25.804 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :800/1167 loss:0.0045\n",
      "2022-09-19 15:33:28.699 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :900/1167 loss:0.0250\n",
      "2022-09-19 15:33:31.459 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :1000/1167 loss:0.0033\n",
      "2022-09-19 15:33:34.322 | INFO     | __main__:train_seq2seq_model:62 - Epoch :75/100, iteration :1100/1167 loss:0.0090\n",
      "2022-09-19 15:33:36.302 | INFO     | __main__:train_seq2seq_model:65 - Epoch :75/100, training loss:0.0068\n",
      "2022-09-19 15:33:37.696 | INFO     | __main__:train_seq2seq_model:69 - Epoch:75, dev loss:0.0088\n",
      "2022-09-19 15:33:37.711 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :0/1167 loss:0.0380\n",
      "2022-09-19 15:33:40.431 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :100/1167 loss:0.0083\n",
      "2022-09-19 15:33:43.649 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :200/1167 loss:0.0071\n",
      "2022-09-19 15:33:46.572 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :300/1167 loss:0.0071\n",
      "2022-09-19 15:33:49.440 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :400/1167 loss:0.0102\n",
      "2022-09-19 15:33:52.334 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :500/1167 loss:0.0064\n",
      "2022-09-19 15:33:55.596 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :600/1167 loss:0.0041\n",
      "2022-09-19 15:33:58.732 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :700/1167 loss:0.0187\n",
      "2022-09-19 15:34:01.802 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :800/1167 loss:0.0039\n",
      "2022-09-19 15:34:04.694 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :900/1167 loss:0.0254\n",
      "2022-09-19 15:34:07.459 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :1000/1167 loss:0.0034\n",
      "2022-09-19 15:34:10.316 | INFO     | __main__:train_seq2seq_model:62 - Epoch :76/100, iteration :1100/1167 loss:0.0047\n",
      "2022-09-19 15:34:12.287 | INFO     | __main__:train_seq2seq_model:65 - Epoch :76/100, training loss:0.0073\n",
      "2022-09-19 15:34:13.681 | INFO     | __main__:train_seq2seq_model:69 - Epoch:76, dev loss:0.0075\n",
      "2022-09-19 15:34:13.695 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :0/1167 loss:0.0279\n",
      "2022-09-19 15:34:16.406 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :100/1167 loss:0.0042\n",
      "2022-09-19 15:34:19.628 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :200/1167 loss:0.0031\n",
      "2022-09-19 15:34:22.554 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :300/1167 loss:0.0089\n",
      "2022-09-19 15:34:25.422 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :400/1167 loss:0.0095\n",
      "2022-09-19 15:34:28.321 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :500/1167 loss:0.0021\n",
      "2022-09-19 15:34:31.582 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :600/1167 loss:0.0033\n",
      "2022-09-19 15:34:34.718 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :700/1167 loss:0.0176\n",
      "2022-09-19 15:34:37.777 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :800/1167 loss:0.0033\n",
      "2022-09-19 15:34:40.667 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :900/1167 loss:0.0225\n",
      "2022-09-19 15:34:43.431 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :1000/1167 loss:0.0056\n",
      "2022-09-19 15:34:46.300 | INFO     | __main__:train_seq2seq_model:62 - Epoch :77/100, iteration :1100/1167 loss:0.0080\n",
      "2022-09-19 15:34:48.280 | INFO     | __main__:train_seq2seq_model:65 - Epoch :77/100, training loss:0.0063\n",
      "2022-09-19 15:34:49.699 | INFO     | __main__:train_seq2seq_model:69 - Epoch:77, dev loss:0.0075\n",
      "2022-09-19 15:34:49.713 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :0/1167 loss:0.0264\n",
      "2022-09-19 15:34:52.425 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :100/1167 loss:0.0039\n",
      "2022-09-19 15:34:55.646 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :200/1167 loss:0.0043\n",
      "2022-09-19 15:34:58.575 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :300/1167 loss:0.0023\n",
      "2022-09-19 15:35:01.444 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :400/1167 loss:0.0129\n",
      "2022-09-19 15:35:04.351 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :500/1167 loss:0.0036\n",
      "2022-09-19 15:35:07.614 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :600/1167 loss:0.0026\n",
      "2022-09-19 15:35:10.750 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :700/1167 loss:0.0148\n",
      "2022-09-19 15:35:13.813 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :800/1167 loss:0.0043\n",
      "2022-09-19 15:35:16.710 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :900/1167 loss:0.0232\n",
      "2022-09-19 15:35:19.472 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :1000/1167 loss:0.0037\n",
      "2022-09-19 15:35:22.337 | INFO     | __main__:train_seq2seq_model:62 - Epoch :78/100, iteration :1100/1167 loss:0.0053\n",
      "2022-09-19 15:35:24.312 | INFO     | __main__:train_seq2seq_model:65 - Epoch :78/100, training loss:0.0068\n",
      "2022-09-19 15:35:25.709 | INFO     | __main__:train_seq2seq_model:69 - Epoch:78, dev loss:0.0082\n",
      "2022-09-19 15:35:25.723 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :0/1167 loss:0.0302\n",
      "2022-09-19 15:35:28.436 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :100/1167 loss:0.0037\n",
      "2022-09-19 15:35:31.662 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :200/1167 loss:0.0076\n",
      "2022-09-19 15:35:34.577 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :300/1167 loss:0.0028\n",
      "2022-09-19 15:35:37.469 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :400/1167 loss:0.0163\n",
      "2022-09-19 15:35:40.410 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :500/1167 loss:0.0036\n",
      "2022-09-19 15:35:43.720 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :600/1167 loss:0.0041\n",
      "2022-09-19 15:35:46.889 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :700/1167 loss:0.0175\n",
      "2022-09-19 15:35:49.957 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :800/1167 loss:0.0050\n",
      "2022-09-19 15:35:52.846 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :900/1167 loss:0.0238\n",
      "2022-09-19 15:35:55.614 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :1000/1167 loss:0.0040\n",
      "2022-09-19 15:35:58.471 | INFO     | __main__:train_seq2seq_model:62 - Epoch :79/100, iteration :1100/1167 loss:0.0047\n",
      "2022-09-19 15:36:00.451 | INFO     | __main__:train_seq2seq_model:65 - Epoch :79/100, training loss:0.0068\n",
      "2022-09-19 15:36:01.871 | INFO     | __main__:train_seq2seq_model:69 - Epoch:79, dev loss:0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 15:36:01.885 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :0/1167 loss:0.0300\n",
      "2022-09-19 15:36:04.602 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :100/1167 loss:0.0041\n",
      "2022-09-19 15:36:07.829 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :200/1167 loss:0.0077\n",
      "2022-09-19 15:36:10.750 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :300/1167 loss:0.0043\n",
      "2022-09-19 15:36:13.619 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :400/1167 loss:0.0102\n",
      "2022-09-19 15:36:16.510 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :500/1167 loss:0.0034\n",
      "2022-09-19 15:36:19.779 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :600/1167 loss:0.0010\n",
      "2022-09-19 15:36:22.918 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :700/1167 loss:0.0168\n",
      "2022-09-19 15:36:25.993 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :800/1167 loss:0.0018\n",
      "2022-09-19 15:36:28.880 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :900/1167 loss:0.0234\n",
      "2022-09-19 15:36:31.650 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :1000/1167 loss:0.0063\n",
      "2022-09-19 15:36:34.516 | INFO     | __main__:train_seq2seq_model:62 - Epoch :80/100, iteration :1100/1167 loss:0.0096\n",
      "2022-09-19 15:36:36.494 | INFO     | __main__:train_seq2seq_model:65 - Epoch :80/100, training loss:0.0068\n",
      "2022-09-19 15:36:37.907 | INFO     | __main__:train_seq2seq_model:69 - Epoch:80, dev loss:0.0079\n",
      "2022-09-19 15:36:37.919 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :0/1167 loss:0.0299\n",
      "2022-09-19 15:36:40.626 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :100/1167 loss:0.0043\n",
      "2022-09-19 15:36:43.850 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :200/1167 loss:0.0055\n",
      "2022-09-19 15:36:46.776 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :300/1167 loss:0.0021\n",
      "2022-09-19 15:36:49.643 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :400/1167 loss:0.0099\n",
      "2022-09-19 15:36:52.538 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :500/1167 loss:0.0024\n",
      "2022-09-19 15:36:55.816 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :600/1167 loss:0.0018\n",
      "2022-09-19 15:36:58.945 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :700/1167 loss:0.0176\n",
      "2022-09-19 15:37:02.009 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :800/1167 loss:0.0059\n",
      "2022-09-19 15:37:04.895 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :900/1167 loss:0.0233\n",
      "2022-09-19 15:37:07.657 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :1000/1167 loss:0.0061\n",
      "2022-09-19 15:37:10.524 | INFO     | __main__:train_seq2seq_model:62 - Epoch :81/100, iteration :1100/1167 loss:0.0055\n",
      "2022-09-19 15:37:12.500 | INFO     | __main__:train_seq2seq_model:65 - Epoch :81/100, training loss:0.0063\n",
      "2022-09-19 15:37:13.908 | INFO     | __main__:train_seq2seq_model:69 - Epoch:81, dev loss:0.0080\n",
      "2022-09-19 15:37:13.922 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :0/1167 loss:0.0299\n",
      "2022-09-19 15:37:16.631 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :100/1167 loss:0.0103\n",
      "2022-09-19 15:37:19.869 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :200/1167 loss:0.0029\n",
      "2022-09-19 15:37:22.793 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :300/1167 loss:0.0020\n",
      "2022-09-19 15:37:25.659 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :400/1167 loss:0.0096\n",
      "2022-09-19 15:37:28.549 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :500/1167 loss:0.0081\n",
      "2022-09-19 15:37:31.819 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :600/1167 loss:0.0031\n",
      "2022-09-19 15:37:34.958 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :700/1167 loss:0.0164\n",
      "2022-09-19 15:37:38.024 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :800/1167 loss:0.0046\n",
      "2022-09-19 15:37:40.921 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :900/1167 loss:0.0254\n",
      "2022-09-19 15:37:43.688 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :1000/1167 loss:0.0058\n",
      "2022-09-19 15:37:46.541 | INFO     | __main__:train_seq2seq_model:62 - Epoch :82/100, iteration :1100/1167 loss:0.0066\n",
      "2022-09-19 15:37:48.518 | INFO     | __main__:train_seq2seq_model:65 - Epoch :82/100, training loss:0.0063\n",
      "2022-09-19 15:37:49.965 | INFO     | __main__:train_seq2seq_model:69 - Epoch:82, dev loss:0.0080\n",
      "2022-09-19 15:37:49.979 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :0/1167 loss:0.0306\n",
      "2022-09-19 15:37:52.685 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :100/1167 loss:0.0117\n",
      "2022-09-19 15:37:55.914 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :200/1167 loss:0.0034\n",
      "2022-09-19 15:37:58.841 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :300/1167 loss:0.0073\n",
      "2022-09-19 15:38:01.714 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :400/1167 loss:0.0106\n",
      "2022-09-19 15:38:04.599 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :500/1167 loss:0.0061\n",
      "2022-09-19 15:38:07.880 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :600/1167 loss:0.0050\n",
      "2022-09-19 15:38:11.011 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :700/1167 loss:0.0145\n",
      "2022-09-19 15:38:14.084 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :800/1167 loss:0.0036\n",
      "2022-09-19 15:38:16.976 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :900/1167 loss:0.0223\n",
      "2022-09-19 15:38:19.769 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :1000/1167 loss:0.0029\n",
      "2022-09-19 15:38:22.632 | INFO     | __main__:train_seq2seq_model:62 - Epoch :83/100, iteration :1100/1167 loss:0.0086\n",
      "2022-09-19 15:38:24.609 | INFO     | __main__:train_seq2seq_model:65 - Epoch :83/100, training loss:0.0066\n",
      "2022-09-19 15:38:26.012 | INFO     | __main__:train_seq2seq_model:69 - Epoch:83, dev loss:0.0080\n",
      "2022-09-19 15:38:26.025 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :0/1167 loss:0.0333\n",
      "2022-09-19 15:38:28.731 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :100/1167 loss:0.0066\n",
      "2022-09-19 15:38:31.959 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :200/1167 loss:0.0027\n",
      "2022-09-19 15:38:34.879 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :300/1167 loss:0.0104\n",
      "2022-09-19 15:38:37.753 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :400/1167 loss:0.0139\n",
      "2022-09-19 15:38:40.640 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :500/1167 loss:0.0023\n",
      "2022-09-19 15:38:43.914 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :600/1167 loss:0.0025\n",
      "2022-09-19 15:38:47.047 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :700/1167 loss:0.0180\n",
      "2022-09-19 15:38:50.114 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :800/1167 loss:0.0044\n",
      "2022-09-19 15:38:53.009 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :900/1167 loss:0.0247\n",
      "2022-09-19 15:38:55.772 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :1000/1167 loss:0.0062\n",
      "2022-09-19 15:38:58.630 | INFO     | __main__:train_seq2seq_model:62 - Epoch :84/100, iteration :1100/1167 loss:0.0047\n",
      "2022-09-19 15:39:00.611 | INFO     | __main__:train_seq2seq_model:65 - Epoch :84/100, training loss:0.0067\n",
      "2022-09-19 15:39:02.019 | INFO     | __main__:train_seq2seq_model:69 - Epoch:84, dev loss:0.0076\n",
      "2022-09-19 15:39:02.033 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :0/1167 loss:0.0268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 15:39:04.742 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :100/1167 loss:0.0040\n",
      "2022-09-19 15:39:07.973 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :200/1167 loss:0.0068\n",
      "2022-09-19 15:39:10.890 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :300/1167 loss:0.0032\n",
      "2022-09-19 15:39:13.760 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :400/1167 loss:0.0099\n",
      "2022-09-19 15:39:16.643 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :500/1167 loss:0.0025\n",
      "2022-09-19 15:39:19.923 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :600/1167 loss:0.0025\n",
      "2022-09-19 15:39:23.061 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :700/1167 loss:0.0167\n",
      "2022-09-19 15:39:26.134 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :800/1167 loss:0.0049\n",
      "2022-09-19 15:39:29.033 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :900/1167 loss:0.0214\n",
      "2022-09-19 15:39:31.800 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :1000/1167 loss:0.0114\n",
      "2022-09-19 15:39:34.656 | INFO     | __main__:train_seq2seq_model:62 - Epoch :85/100, iteration :1100/1167 loss:0.0046\n",
      "2022-09-19 15:39:36.636 | INFO     | __main__:train_seq2seq_model:65 - Epoch :85/100, training loss:0.0069\n",
      "2022-09-19 15:39:38.038 | INFO     | __main__:train_seq2seq_model:69 - Epoch:85, dev loss:0.0082\n",
      "2022-09-19 15:39:38.052 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :0/1167 loss:0.0271\n",
      "2022-09-19 15:39:40.759 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :100/1167 loss:0.0046\n",
      "2022-09-19 15:39:43.994 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :200/1167 loss:0.0063\n",
      "2022-09-19 15:39:46.911 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :300/1167 loss:0.0022\n",
      "2022-09-19 15:39:49.802 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :400/1167 loss:0.0108\n",
      "2022-09-19 15:39:52.691 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :500/1167 loss:0.0049\n",
      "2022-09-19 15:39:55.965 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :600/1167 loss:0.0014\n",
      "2022-09-19 15:39:59.110 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :700/1167 loss:0.0169\n",
      "2022-09-19 15:40:02.184 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :800/1167 loss:0.0057\n",
      "2022-09-19 15:40:05.084 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :900/1167 loss:0.0215\n",
      "2022-09-19 15:40:07.844 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :1000/1167 loss:0.0029\n",
      "2022-09-19 15:40:10.701 | INFO     | __main__:train_seq2seq_model:62 - Epoch :86/100, iteration :1100/1167 loss:0.0041\n",
      "2022-09-19 15:40:12.682 | INFO     | __main__:train_seq2seq_model:65 - Epoch :86/100, training loss:0.0064\n",
      "2022-09-19 15:40:14.094 | INFO     | __main__:train_seq2seq_model:69 - Epoch:86, dev loss:0.0078\n",
      "2022-09-19 15:40:14.108 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :0/1167 loss:0.0295\n",
      "2022-09-19 15:40:16.814 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :100/1167 loss:0.0045\n",
      "2022-09-19 15:40:20.039 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :200/1167 loss:0.0024\n",
      "2022-09-19 15:40:22.963 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :300/1167 loss:0.0021\n",
      "2022-09-19 15:40:25.840 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :400/1167 loss:0.0163\n",
      "2022-09-19 15:40:28.725 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :500/1167 loss:0.0023\n",
      "2022-09-19 15:40:32.021 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :600/1167 loss:0.0015\n",
      "2022-09-19 15:40:35.158 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :700/1167 loss:0.0150\n",
      "2022-09-19 15:40:38.225 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :800/1167 loss:0.0027\n",
      "2022-09-19 15:40:41.125 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :900/1167 loss:0.0218\n",
      "2022-09-19 15:40:43.895 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :1000/1167 loss:0.0030\n",
      "2022-09-19 15:40:46.756 | INFO     | __main__:train_seq2seq_model:62 - Epoch :87/100, iteration :1100/1167 loss:0.0043\n",
      "2022-09-19 15:40:48.736 | INFO     | __main__:train_seq2seq_model:65 - Epoch :87/100, training loss:0.0063\n",
      "2022-09-19 15:40:50.143 | INFO     | __main__:train_seq2seq_model:69 - Epoch:87, dev loss:0.0081\n",
      "2022-09-19 15:40:50.156 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :0/1167 loss:0.0325\n",
      "2022-09-19 15:40:52.870 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :100/1167 loss:0.0038\n",
      "2022-09-19 15:40:56.097 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :200/1167 loss:0.0029\n",
      "2022-09-19 15:40:59.023 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :300/1167 loss:0.0021\n",
      "2022-09-19 15:41:01.899 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :400/1167 loss:0.0091\n",
      "2022-09-19 15:41:04.785 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :500/1167 loss:0.0044\n",
      "2022-09-19 15:41:08.063 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :600/1167 loss:0.0047\n",
      "2022-09-19 15:41:11.197 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :700/1167 loss:0.0164\n",
      "2022-09-19 15:41:14.269 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :800/1167 loss:0.0016\n",
      "2022-09-19 15:41:17.164 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :900/1167 loss:0.0222\n",
      "2022-09-19 15:41:19.927 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :1000/1167 loss:0.0091\n",
      "2022-09-19 15:41:22.777 | INFO     | __main__:train_seq2seq_model:62 - Epoch :88/100, iteration :1100/1167 loss:0.0106\n",
      "2022-09-19 15:41:24.757 | INFO     | __main__:train_seq2seq_model:65 - Epoch :88/100, training loss:0.0066\n",
      "2022-09-19 15:41:26.198 | INFO     | __main__:train_seq2seq_model:69 - Epoch:88, dev loss:0.0081\n",
      "2022-09-19 15:41:26.211 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :0/1167 loss:0.0297\n",
      "2022-09-19 15:41:28.921 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :100/1167 loss:0.0040\n",
      "2022-09-19 15:41:32.151 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :200/1167 loss:0.0103\n",
      "2022-09-19 15:41:35.083 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :300/1167 loss:0.0020\n",
      "2022-09-19 15:41:37.953 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :400/1167 loss:0.0176\n",
      "2022-09-19 15:41:40.838 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :500/1167 loss:0.0025\n",
      "2022-09-19 15:41:44.124 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :600/1167 loss:0.0031\n",
      "2022-09-19 15:41:47.266 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :700/1167 loss:0.0147\n",
      "2022-09-19 15:41:50.335 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :800/1167 loss:0.0027\n",
      "2022-09-19 15:41:53.230 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :900/1167 loss:0.0245\n",
      "2022-09-19 15:41:56.004 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :1000/1167 loss:0.0033\n",
      "2022-09-19 15:41:58.860 | INFO     | __main__:train_seq2seq_model:62 - Epoch :89/100, iteration :1100/1167 loss:0.0059\n",
      "2022-09-19 15:42:00.838 | INFO     | __main__:train_seq2seq_model:65 - Epoch :89/100, training loss:0.0071\n",
      "2022-09-19 15:42:02.252 | INFO     | __main__:train_seq2seq_model:69 - Epoch:89, dev loss:0.0080\n",
      "2022-09-19 15:42:02.265 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :0/1167 loss:0.0298\n",
      "2022-09-19 15:42:04.976 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :100/1167 loss:0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 15:42:08.198 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :200/1167 loss:0.0089\n",
      "2022-09-19 15:42:11.123 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :300/1167 loss:0.0025\n",
      "2022-09-19 15:42:13.988 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :400/1167 loss:0.0094\n",
      "2022-09-19 15:42:16.875 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :500/1167 loss:0.0062\n",
      "2022-09-19 15:42:20.151 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :600/1167 loss:0.0024\n",
      "2022-09-19 15:42:23.296 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :700/1167 loss:0.0182\n",
      "2022-09-19 15:42:26.374 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :800/1167 loss:0.0029\n",
      "2022-09-19 15:42:29.267 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :900/1167 loss:0.0228\n",
      "2022-09-19 15:42:32.032 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :1000/1167 loss:0.0030\n",
      "2022-09-19 15:42:34.883 | INFO     | __main__:train_seq2seq_model:62 - Epoch :90/100, iteration :1100/1167 loss:0.0046\n",
      "2022-09-19 15:42:36.865 | INFO     | __main__:train_seq2seq_model:65 - Epoch :90/100, training loss:0.0064\n",
      "2022-09-19 15:42:38.300 | INFO     | __main__:train_seq2seq_model:69 - Epoch:90, dev loss:0.0080\n",
      "2022-09-19 15:42:38.314 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :0/1167 loss:0.0264\n",
      "2022-09-19 15:42:41.022 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :100/1167 loss:0.0036\n",
      "2022-09-19 15:42:44.247 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :200/1167 loss:0.0076\n",
      "2022-09-19 15:42:47.178 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :300/1167 loss:0.0019\n",
      "2022-09-19 15:42:50.042 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :400/1167 loss:0.0086\n",
      "2022-09-19 15:42:52.932 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :500/1167 loss:0.0025\n",
      "2022-09-19 15:42:56.203 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :600/1167 loss:0.0052\n",
      "2022-09-19 15:42:59.351 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :700/1167 loss:0.0155\n",
      "2022-09-19 15:43:02.422 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :800/1167 loss:0.0024\n",
      "2022-09-19 15:43:05.317 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :900/1167 loss:0.0244\n",
      "2022-09-19 15:43:08.080 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :1000/1167 loss:0.0098\n",
      "2022-09-19 15:43:10.938 | INFO     | __main__:train_seq2seq_model:62 - Epoch :91/100, iteration :1100/1167 loss:0.0048\n",
      "2022-09-19 15:43:12.919 | INFO     | __main__:train_seq2seq_model:65 - Epoch :91/100, training loss:0.0067\n",
      "2022-09-19 15:43:14.370 | INFO     | __main__:train_seq2seq_model:69 - Epoch:91, dev loss:0.0076\n",
      "2022-09-19 15:43:14.383 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :0/1167 loss:0.0262\n",
      "2022-09-19 15:43:17.087 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :100/1167 loss:0.0037\n",
      "2022-09-19 15:43:20.325 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :200/1167 loss:0.0090\n",
      "2022-09-19 15:43:23.245 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :300/1167 loss:0.0081\n",
      "2022-09-19 15:43:26.115 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :400/1167 loss:0.0088\n",
      "2022-09-19 15:43:29.006 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :500/1167 loss:0.0025\n",
      "2022-09-19 15:43:32.274 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :600/1167 loss:0.0018\n",
      "2022-09-19 15:43:35.408 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :700/1167 loss:0.0160\n",
      "2022-09-19 15:43:38.472 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :800/1167 loss:0.0034\n",
      "2022-09-19 15:43:41.370 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :900/1167 loss:0.0229\n",
      "2022-09-19 15:43:44.141 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :1000/1167 loss:0.0054\n",
      "2022-09-19 15:43:46.991 | INFO     | __main__:train_seq2seq_model:62 - Epoch :92/100, iteration :1100/1167 loss:0.0038\n",
      "2022-09-19 15:43:48.968 | INFO     | __main__:train_seq2seq_model:65 - Epoch :92/100, training loss:0.0064\n",
      "2022-09-19 15:43:50.432 | INFO     | __main__:train_seq2seq_model:69 - Epoch:92, dev loss:0.0077\n",
      "2022-09-19 15:43:50.446 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :0/1167 loss:0.0253\n",
      "2022-09-19 15:43:53.156 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :100/1167 loss:0.0039\n",
      "2022-09-19 15:43:56.373 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :200/1167 loss:0.0023\n",
      "2022-09-19 15:43:59.299 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :300/1167 loss:0.0135\n",
      "2022-09-19 15:44:02.174 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :400/1167 loss:0.0158\n",
      "2022-09-19 15:44:05.066 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :500/1167 loss:0.0026\n",
      "2022-09-19 15:44:08.350 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :600/1167 loss:0.0031\n",
      "2022-09-19 15:44:11.493 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :700/1167 loss:0.0152\n",
      "2022-09-19 15:44:14.555 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :800/1167 loss:0.0036\n",
      "2022-09-19 15:44:17.453 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :900/1167 loss:0.0219\n",
      "2022-09-19 15:44:20.224 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :1000/1167 loss:0.0054\n",
      "2022-09-19 15:44:23.078 | INFO     | __main__:train_seq2seq_model:62 - Epoch :93/100, iteration :1100/1167 loss:0.0047\n",
      "2022-09-19 15:44:25.056 | INFO     | __main__:train_seq2seq_model:65 - Epoch :93/100, training loss:0.0064\n",
      "2022-09-19 15:44:26.469 | INFO     | __main__:train_seq2seq_model:69 - Epoch:93, dev loss:0.0088\n",
      "2022-09-19 15:44:26.483 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :0/1167 loss:0.0287\n",
      "2022-09-19 15:44:29.195 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :100/1167 loss:0.0042\n",
      "2022-09-19 15:44:32.422 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :200/1167 loss:0.0090\n",
      "2022-09-19 15:44:35.345 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :300/1167 loss:0.0033\n",
      "2022-09-19 15:44:38.217 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :400/1167 loss:0.0101\n",
      "2022-09-19 15:44:41.102 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :500/1167 loss:0.0025\n",
      "2022-09-19 15:44:44.375 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :600/1167 loss:0.0023\n",
      "2022-09-19 15:44:47.509 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :700/1167 loss:0.0162\n",
      "2022-09-19 15:44:50.575 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :800/1167 loss:0.0048\n",
      "2022-09-19 15:44:53.475 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :900/1167 loss:0.0218\n",
      "2022-09-19 15:44:56.245 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :1000/1167 loss:0.0142\n",
      "2022-09-19 15:44:59.111 | INFO     | __main__:train_seq2seq_model:62 - Epoch :94/100, iteration :1100/1167 loss:0.0047\n",
      "2022-09-19 15:45:01.090 | INFO     | __main__:train_seq2seq_model:65 - Epoch :94/100, training loss:0.0067\n",
      "2022-09-19 15:45:02.493 | INFO     | __main__:train_seq2seq_model:69 - Epoch:94, dev loss:0.0082\n",
      "2022-09-19 15:45:02.507 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :0/1167 loss:0.0271\n",
      "2022-09-19 15:45:05.219 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :100/1167 loss:0.0079\n",
      "2022-09-19 15:45:08.441 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :200/1167 loss:0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 15:45:11.369 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :300/1167 loss:0.0093\n",
      "2022-09-19 15:45:14.239 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :400/1167 loss:0.0095\n",
      "2022-09-19 15:45:17.125 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :500/1167 loss:0.0037\n",
      "2022-09-19 15:45:20.399 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :600/1167 loss:0.0055\n",
      "2022-09-19 15:45:23.528 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :700/1167 loss:0.0164\n",
      "2022-09-19 15:45:26.586 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :800/1167 loss:0.0042\n",
      "2022-09-19 15:45:29.490 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :900/1167 loss:0.0216\n",
      "2022-09-19 15:45:32.259 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :1000/1167 loss:0.0057\n",
      "2022-09-19 15:45:35.113 | INFO     | __main__:train_seq2seq_model:62 - Epoch :95/100, iteration :1100/1167 loss:0.0041\n",
      "2022-09-19 15:45:37.089 | INFO     | __main__:train_seq2seq_model:65 - Epoch :95/100, training loss:0.0069\n",
      "2022-09-19 15:45:38.508 | INFO     | __main__:train_seq2seq_model:69 - Epoch:95, dev loss:0.0079\n",
      "2022-09-19 15:45:38.521 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :0/1167 loss:0.0292\n",
      "2022-09-19 15:45:41.235 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :100/1167 loss:0.0053\n",
      "2022-09-19 15:45:44.454 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :200/1167 loss:0.0080\n",
      "2022-09-19 15:45:47.379 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :300/1167 loss:0.0079\n",
      "2022-09-19 15:45:50.248 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :400/1167 loss:0.0140\n",
      "2022-09-19 15:45:53.133 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :500/1167 loss:0.0064\n",
      "2022-09-19 15:45:56.413 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :600/1167 loss:0.0071\n",
      "2022-09-19 15:45:59.546 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :700/1167 loss:0.0194\n",
      "2022-09-19 15:46:02.609 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :800/1167 loss:0.0045\n",
      "2022-09-19 15:46:05.517 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :900/1167 loss:0.0214\n",
      "2022-09-19 15:46:08.284 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :1000/1167 loss:0.0030\n",
      "2022-09-19 15:46:11.144 | INFO     | __main__:train_seq2seq_model:62 - Epoch :96/100, iteration :1100/1167 loss:0.0037\n",
      "2022-09-19 15:46:13.125 | INFO     | __main__:train_seq2seq_model:65 - Epoch :96/100, training loss:0.0065\n",
      "2022-09-19 15:46:14.528 | INFO     | __main__:train_seq2seq_model:69 - Epoch:96, dev loss:0.0080\n",
      "2022-09-19 15:46:14.542 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :0/1167 loss:0.0270\n",
      "2022-09-19 15:46:17.252 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :100/1167 loss:0.0041\n",
      "2022-09-19 15:46:20.466 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :200/1167 loss:0.0122\n",
      "2022-09-19 15:46:23.390 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :300/1167 loss:0.0080\n",
      "2022-09-19 15:46:26.259 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :400/1167 loss:0.0077\n",
      "2022-09-19 15:46:29.150 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :500/1167 loss:0.0056\n",
      "2022-09-19 15:46:32.430 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :600/1167 loss:0.0067\n",
      "2022-09-19 15:46:35.574 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :700/1167 loss:0.0163\n",
      "2022-09-19 15:46:38.633 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :800/1167 loss:0.0039\n",
      "2022-09-19 15:46:41.531 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :900/1167 loss:0.0217\n",
      "2022-09-19 15:46:44.298 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :1000/1167 loss:0.0046\n",
      "2022-09-19 15:46:47.149 | INFO     | __main__:train_seq2seq_model:62 - Epoch :97/100, iteration :1100/1167 loss:0.0047\n",
      "2022-09-19 15:46:49.122 | INFO     | __main__:train_seq2seq_model:65 - Epoch :97/100, training loss:0.0064\n",
      "2022-09-19 15:46:50.519 | INFO     | __main__:train_seq2seq_model:69 - Epoch:97, dev loss:0.0078\n",
      "2022-09-19 15:46:50.533 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :0/1167 loss:0.0243\n",
      "2022-09-19 15:46:53.254 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :100/1167 loss:0.0040\n",
      "2022-09-19 15:46:56.483 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :200/1167 loss:0.0079\n",
      "2022-09-19 15:46:59.409 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :300/1167 loss:0.0133\n",
      "2022-09-19 15:47:02.279 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :400/1167 loss:0.0100\n",
      "2022-09-19 15:47:05.172 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :500/1167 loss:0.0074\n",
      "2022-09-19 15:47:08.444 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :600/1167 loss:0.0058\n",
      "2022-09-19 15:47:11.587 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :700/1167 loss:0.0196\n",
      "2022-09-19 15:47:14.651 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :800/1167 loss:0.0038\n",
      "2022-09-19 15:47:17.551 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :900/1167 loss:0.0262\n",
      "2022-09-19 15:47:20.317 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :1000/1167 loss:0.0129\n",
      "2022-09-19 15:47:23.170 | INFO     | __main__:train_seq2seq_model:62 - Epoch :98/100, iteration :1100/1167 loss:0.0043\n",
      "2022-09-19 15:47:25.158 | INFO     | __main__:train_seq2seq_model:65 - Epoch :98/100, training loss:0.0072\n",
      "2022-09-19 15:47:26.554 | INFO     | __main__:train_seq2seq_model:69 - Epoch:98, dev loss:0.0086\n",
      "2022-09-19 15:47:26.568 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :0/1167 loss:0.0287\n",
      "2022-09-19 15:47:29.298 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :100/1167 loss:0.0042\n",
      "2022-09-19 15:47:32.534 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :200/1167 loss:0.0035\n",
      "2022-09-19 15:47:35.462 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :300/1167 loss:0.0059\n",
      "2022-09-19 15:47:38.332 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :400/1167 loss:0.0146\n",
      "2022-09-19 15:47:41.224 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :500/1167 loss:0.0055\n",
      "2022-09-19 15:47:44.493 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :600/1167 loss:0.0030\n",
      "2022-09-19 15:47:47.639 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :700/1167 loss:0.0158\n",
      "2022-09-19 15:47:50.689 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :800/1167 loss:0.0052\n",
      "2022-09-19 15:47:53.587 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :900/1167 loss:0.0217\n",
      "2022-09-19 15:47:56.353 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :1000/1167 loss:0.0067\n",
      "2022-09-19 15:47:59.205 | INFO     | __main__:train_seq2seq_model:62 - Epoch :99/100, iteration :1100/1167 loss:0.0051\n",
      "2022-09-19 15:48:01.178 | INFO     | __main__:train_seq2seq_model:65 - Epoch :99/100, training loss:0.0065\n",
      "2022-09-19 15:48:02.586 | INFO     | __main__:train_seq2seq_model:69 - Epoch:99, dev loss:0.0082\n"
     ]
    }
   ],
   "source": [
    "if args.do_preprocess:\n",
    "    # Preprocess\n",
    "    data_list = []\n",
    "    os.makedirs(args.model_dir, exist_ok=True)\n",
    "    '''\n",
    "    if args.dataset == 'sighan':\n",
    "        data_list.extend(get_data_file(args.raw_train_path, args.use_segment, args.segment_type))\n",
    "    else:\n",
    "        data_list.extend(parse_xml_file(args.raw_train_path, args.use_segment, args.segment_type))\n",
    "    '''\n",
    "    # get the data list\n",
    "    data_list.extend(get_data_file(\"../pycorrector/data/RNA/train\", args.use_segment, args.segment_type))\n",
    "    if data_list:\n",
    "        # save the datalist to a file\n",
    "        save_corpus_data(data_list, args.train_path, args.test_path)\n",
    "# Train model with train data file\n",
    "train(args.arch, \n",
    "        args.train_path, # specify which model architecture to use\n",
    "        args.batch_size,\n",
    "        args.embed_size,\n",
    "        args.hidden_size,\n",
    "        args.dropout,\n",
    "        args.epochs,\n",
    "        args.model_dir,\n",
    "        args.max_length,\n",
    "        args.use_segment,\n",
    "        args.model_name_or_path,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04c116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data = get_data_file(\"../pycorrector/data/RNA/train\", args.use_segment, args.segment_type)\n",
    "res = []\n",
    "for i in range(len(data)-1,len(data)-100,-1):\n",
    "    a,b = data[i]\n",
    "    if a != b:\n",
    "        res.append(i)\n",
    "res\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9747223",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " [data[i][1] for i in res[:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d935965",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg5 = \"MET ASN LYS SER VAL ALA PRO LEU LEU LEU ALA ALA SER ILE LEU TYR GLY GLY ALA ALA ALA GLN GLN THR VAL TRP GLY GLN CYS GLY GLY ILE GLY TRP SER GLY PRO THR ASN CYS ALA PRO GLY SER ALA CYS SER THR LEU ASN PRO TYR TYR ALA GLN CYS ILE PRO GLY ALA THR THR ILE THR THR SER THR ARG PRO PRO SER GLY PRO THR THR THR THR ARG ALA THR SER THR SER SER SER THR PRO PRO THR SER SER GLY VAL ARG PHE ALA GLY VAL ASN ILE ALA GLY PHE ASP PHE GLY CYS THR THR ASP GLY THR CYS VAL THR SER LYS VAL TYR PRO PRO LEU LYS ASN PHE THR GLY SER ASN ASN TYR PRO ASP GLY ILE GLY GLN MET GLN HIS PHE VAL ASN ASP ASP GLY MET THR ILE PHE ARG LEU PRO VAL GLY TRP GLN TYR LEU VAL ASN ASN ASN LEU GLY GLY ASN LEU ASP SER THR SER ILE SER LYS TYR ASP GLN LEU VAL GLN GLY CYS LEU SER LEU GLY ALA TYR CYS ILE VAL ASP ILE HIS ASN TYR ALA ARG TRP ASN GLY GLY ILE ILE GLY GLN GLY GLY PRO THR ASN ALA GLN PHE THR SER LEU TRP SER GLN LEU ALA SER LYS TYR ALA SER GLN SER ARG VAL TRP PHE GLY ILE MET ASN GLU PRO HIS ASP VAL ASN ILE ASN THR TRP ALA ALA THR VAL GLN GLU VAL VAL THR ALA ILE ARG ASN ALA GLY ALA THR SER GLN PHE ILE SER LEU PRO GLY ASN ASP TRP GLN SER ALA GLY ALA PHE ILE SER ASP GLY SER ALA ALA ALA LEU SER GLN VAL THR ASN PRO ASP GLY SER THR THR ASN LEU ILE PHE ASP VAL HIS LYS TYR LEU ASP SER ASP ASN SER GLY THR HIS ALA GLU CYS THR THR ASN ASN ILE ASP GLY ALA PHE SER PRO LEU ALA THR TRP LEU ARG GLN ASN ASN ARG GLN ALA ILE LEU THR GLU THR GLY GLY GLY ASN VAL GLN SER CYS ILE GLN ASP MET CYS GLN GLN ILE GLN TYR LEU ASN GLN ASN SER ASP VAL TYR LEU GLY TYR VAL GLY TRP GLY ALA GLY SER PHE ASP SER THR TYR VAL LEU THR GLU THR PRO THR GLY SER GLY ASN SER TRP THR ASP THR SER LEU VAL SER SER CYS LEU ALA ARG LYS GLY\"\n",
    "eg7 = \"MET ALA PRO SER VAL THR LEU PRO LEU THR THR ALA ILE LEU ALA ILE ALA ARG LEU VAL ALA ALA GLN GLN PRO GLY THR SER THR PRO GLU VAL HIS PRO LYS LEU THR THR TYR LYS CYS THR LYS SER GLY GLY CYS VAL ALA GLN ASP THR SER VAL VAL LEU ASP TRP ASN TYR ARG TRP MET HIS ASP ALA ASN TYR ASN SER CYS THR VAL ASN GLY GLY VAL ASN THR THR LEU CYS PRO ASP GLU ALA THR CYS GLY LYS ASN CYS PHE ILE GLU GLY VAL ASP TYR ALA ALA SER GLY VAL THR THR SER GLY SER SER LEU THR MET ASN GLN TYR MET PRO SER SER SER GLY GLY TYR SER SER VAL SER PRO ARG LEU TYR LEU LEU ASP SER ASP GLY GLU TYR VAL MET LEU LYS LEU ASN GLY GLN GLU LEU SER PHE ASP VAL ASP LEU SER ALA LEU PRO CYS GLY GLU ASN GLY SER LEU TYR LEU SER GLN MET ASP GLU ASN GLY GLY ALA ASN GLN TYR ASN THR ALA GLY ALA ASN TYR GLY SER GLY TYR CYS ASP ALA GLN CYS PRO VAL GLN THR TRP ARG ASN GLY THR LEU ASN THR SER HIS GLN GLY PHE CYS CYS ASN GLU MET ASP ILE LEU GLU GLY ASN SER ARG ALA ASN ALA LEU THR PRO HIS SER CYS THR ALA THR ALA CYS ASP SER ALA GLY CYS GLY PHE ASN PRO TYR GLY SER GLY TYR LYS SER TYR TYR GLY PRO GLY ASP THR VAL ASP THR SER LYS THR PHE THR ILE ILE THR GLN PHE ASN THR ASP ASN GLY SER PRO SER GLY ASN LEU VAL SER ILE THR ARG LYS TYR GLN GLN ASN GLY VAL ASP ILE PRO SER ALA GLN PRO GLY GLY ASP THR ILE SER SER CYS PRO SER ALA SER ALA TYR GLY GLY LEU ALA THR MET GLY LYS ALA LEU SER SER GLY MET VAL LEU VAL PHE SER ILE TRP ASN ASP ASN SER GLN TYR MET ASN TRP LEU ASP SER GLY ASN ALA GLY PRO CYS SER SER THR GLU GLY ASN PRO SER ASN ILE LEU ALA ASN ASN PRO ASN THR HIS VAL VAL PHE SER ASN ILE ARG TRP GLY ASP ILE GLY SER THR THR ASN SER THR ALA PRO PRO PRO PRO PRO ALA SER SER THR THR PHE SER THR THR ARG ARG SER SER THR THR SER SER SER PRO SER CYS THR GLN THR HIS TRP GLY GLN CYS GLY GLY ILE GLY TYR SER GLY CYS LYS THR CYS THR SER GLY THR THR CYS GLN TYR SER ASN ASP TYR TYR SER GLN CYS LEU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28819632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 17:53:34.112 | DEBUG    | __main__:__init__:36 - Device: cuda\n",
      "2022-09-19 17:53:34.113 | DEBUG    | __main__:__init__:37 - Use seq2seq model.\n",
      "2022-09-19 17:53:34.122 | DEBUG    | __main__:__init__:52 - Load model from output/RNA/seq2seq.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "input  : MET ASN LYS SER VAL ALA PRO LEU LEU LEU ALA ALA SER ILE LEU TYR GLY GLY ALA ALA ALA GLN GLN THR VAL TRP GLY GLN CYS GLY GLY ILE GLY TRP SER GLY PRO THR ASN CYS ALA PRO GLY SER ALA CYS SER THR LEU ASN PRO TYR TYR ALA GLN CYS ILE PRO GLY ALA THR THR ILE THR THR SER THR ARG PRO PRO SER GLY PRO THR THR THR THR ARG ALA THR SER THR SER SER SER THR PRO PRO THR SER SER GLY VAL ARG PHE ALA GLY VAL ASN ILE ALA GLY PHE ASP PHE GLY CYS THR THR ASP GLY THR CYS VAL THR SER LYS VAL TYR PRO PRO LEU LYS ASN PHE THR GLY SER ASN ASN TYR PRO ASP GLY ILE GLY GLN MET GLN HIS PHE VAL ASN ASP ASP GLY MET THR ILE PHE ARG LEU PRO VAL GLY TRP GLN TYR LEU VAL ASN ASN ASN LEU GLY GLY ASN LEU ASP SER THR SER ILE SER LYS TYR ASP GLN LEU VAL GLN GLY CYS LEU SER LEU GLY ALA TYR CYS ILE VAL ASP ILE HIS ASN TYR ALA ARG TRP ASN GLY GLY ILE ILE GLY GLN GLY GLY PRO THR ASN ALA GLN PHE THR SER LEU TRP SER GLN LEU ALA SER LYS TYR ALA SER GLN SER ARG VAL TRP PHE GLY ILE MET ASN GLU PRO HIS ASP VAL ASN ILE ASN THR TRP ALA ALA THR VAL GLN GLU VAL VAL THR ALA ILE ARG ASN ALA GLY ALA THR SER GLN PHE ILE SER LEU PRO GLY ASN ASP TRP GLN SER ALA GLY ALA PHE ILE SER ASP GLY SER ALA ALA ALA LEU SER GLN VAL THR ASN PRO ASP GLY SER THR THR ASN LEU ILE PHE ASP VAL HIS LYS TYR LEU ASP SER ASP ASN SER GLY THR HIS ALA GLU CYS THR THR ASN ASN ILE ASP GLY ALA PHE SER PRO LEU ALA THR TRP LEU ARG GLN ASN ASN ARG GLN ALA ILE LEU THR GLU THR GLY GLY GLY ASN VAL GLN SER CYS ILE GLN ASP MET CYS GLN GLN ILE GLN TYR LEU ASN GLN ASN SER ASP VAL TYR LEU GLY TYR VAL GLY TRP GLY ALA GLY SER PHE ASP SER THR TYR VAL LEU THR GLU THR PRO THR GLY SER GLY ASN SER TRP THR ASP THR SER LEU VAL SER SER CYS LEU ALA ARG LYS GLY\n",
      "predict: MET ASN LYS SER VAL ALA PRO LEU LEU LEU ALA ALA SER ILE LEU TYR GLY GLY ALA ALA ALA GLN GLN THR VAL TRP GLY GLN CYS GLY GLY ILE GLY TRP SER GLY PRO THR ASN CYS ALA PRO GLY SER ALA CYS SER THR LEU ASN PRO TYR TYR ALA GLN CYS ILE PRO GLY ALA THR THR ILE THR THR SER THR ARG PRO PRO SER GLY PRO THR THR THR THR ARG ALA THR SER THR SER SER SER THR PRO PRO THR SER SER GLY VAL ARG PHE ALA GLY VAL ASN ILE ALA GLY PHE ASP PHE GLY CYS THR THR ASP GLY THR CYS VAL THR SER LYS VAL TYR PRO PRO LEU LYS ASN PHE THR GLY SER ASN ASN TYR PRO ASP GLY ILE GLY GLN MET GLN HIS PHE VAL ASN ASP ASP GLY MET THR ILE PHE ARG LEU PRO VAL GLY TRP GLN TYR LEU VAL ASN ASN ASN LEU GLY GLY ASN LEU ASP SER THR SER ILE SER LYS TYR ASP GLN LEU VAL GLN GLY CYS LEU SER LEU GLY ALA TYR CYS ILE VAL ASP ILE HIS ASN TYR ALA ARG TRP ASN GLY GLY ILE ILE GLY GLN GLY GLY PRO THR ASN ALA GLN PHE THR SER LEU TRP SER GLN LEU ALA SER LYS TYR ALA SER GLN SER ARG VAL TRP PHE GLY ILE MET ASN GLU PRO HIS ASP VAL ASN ILE ASN THR TRP ALA ALA THR VAL GLN GLU VAL VAL THR ALA ILE ARG ASN ALA GLY ALA THR SER GLN PHE ILE SER LEU PRO GLY ASN ASP TRP GLN SER ALA GLY ALA PHE ILE SER ASP GLY SER ALA ALA ALA LEU SER GLN VAL THR ASN PRO ASP GLY SER THR THR ASN LEU ILE PHE ASP VAL HIS LYS TYR LEU ASP SER ASP ASN SER GLY THR HIS ALA GLU CYS THR THR ASN ASN ILE ASP GLY ALA PHE SER PRO LEU ALA THR TRP LEU ARG GLN ASN ASN ARG GLN ALA ILE LEU THR GLU THR GLY GLY GLY ASN SER TRP THR ASP THR SER LEU VAL SER SER CYS LEU ALA ARG LYS GLY [('VAL', 'SER', 355, 356), ('GLN', 'TRP', 356, 357), ('SER', 'THR', 357, 358), ('CYS', 'ASP', 358, 359), ('ILE', 'THR', 359, 360), ('GLN', 'SER', 360, 361), ('ASP', 'LEU', 361, 362), ('MET', 'VAL', 362, 363), ('CYS', 'SER', 363, 364), ('GLN', 'SER', 364, 365), ('GLN', 'CYS', 365, 366), ('ILE', 'LEU', 366, 367), ('GLN', 'ALA', 367, 368), ('TYR', 'ARG', 368, 369), ('LEU', 'LYS', 369, 370), ('ASN', 'GLY', 370, 371)]\n",
      "\n",
      "input  : MET ALA PRO SER VAL THR LEU PRO LEU THR THR ALA ILE LEU ALA ILE ALA ARG LEU VAL ALA ALA GLN GLN PRO GLY THR SER THR PRO GLU VAL HIS PRO LYS LEU THR THR TYR LYS CYS THR LYS SER GLY GLY CYS VAL ALA GLN ASP THR SER VAL VAL LEU ASP TRP ASN TYR ARG TRP MET HIS ASP ALA ASN TYR ASN SER CYS THR VAL ASN GLY GLY VAL ASN THR THR LEU CYS PRO ASP GLU ALA THR CYS GLY LYS ASN CYS PHE ILE GLU GLY VAL ASP TYR ALA ALA SER GLY VAL THR THR SER GLY SER SER LEU THR MET ASN GLN TYR MET PRO SER SER SER GLY GLY TYR SER SER VAL SER PRO ARG LEU TYR LEU LEU ASP SER ASP GLY GLU TYR VAL MET LEU LYS LEU ASN GLY GLN GLU LEU SER PHE ASP VAL ASP LEU SER ALA LEU PRO CYS GLY GLU ASN GLY SER LEU TYR LEU SER GLN MET ASP GLU ASN GLY GLY ALA ASN GLN TYR ASN THR ALA GLY ALA ASN TYR GLY SER GLY TYR CYS ASP ALA GLN CYS PRO VAL GLN THR TRP ARG ASN GLY THR LEU ASN THR SER HIS GLN GLY PHE CYS CYS ASN GLU MET ASP ILE LEU GLU GLY ASN SER ARG ALA ASN ALA LEU THR PRO HIS SER CYS THR ALA THR ALA CYS ASP SER ALA GLY CYS GLY PHE ASN PRO TYR GLY SER GLY TYR LYS SER TYR TYR GLY PRO GLY ASP THR VAL ASP THR SER LYS THR PHE THR ILE ILE THR GLN PHE ASN THR ASP ASN GLY SER PRO SER GLY ASN LEU VAL SER ILE THR ARG LYS TYR GLN GLN ASN GLY VAL ASP ILE PRO SER ALA GLN PRO GLY GLY ASP THR ILE SER SER CYS PRO SER ALA SER ALA TYR GLY GLY LEU ALA THR MET GLY LYS ALA LEU SER SER GLY MET VAL LEU VAL PHE SER ILE TRP ASN ASP ASN SER GLN TYR MET ASN TRP LEU ASP SER GLY ASN ALA GLY PRO CYS SER SER THR GLU GLY ASN PRO SER ASN ILE LEU ALA ASN ASN PRO ASN THR HIS VAL VAL PHE SER ASN ILE ARG TRP GLY ASP ILE GLY SER THR THR ASN SER THR ALA PRO PRO PRO PRO PRO ALA SER SER THR THR PHE SER THR THR ARG ARG SER SER THR THR SER SER SER PRO SER CYS THR GLN THR HIS TRP GLY GLN CYS GLY GLY ILE GLY TYR SER GLY CYS LYS THR CYS THR SER GLY THR THR CYS GLN TYR SER ASN ASP TYR TYR SER GLN CYS LEU\n",
      "predict: MET ALA PRO SER VAL THR LEU PRO LEU THR THR ALA ILE LEU ALA ILE ALA ARG LEU VAL ALA ALA GLN GLN PRO GLY THR SER THR PRO GLU VAL HIS PRO LYS LEU THR THR TYR LYS CYS THR LYS SER GLY GLY CYS VAL ALA GLN ASP THR SER VAL VAL LEU ASP TRP ASN TYR ARG TRP MET HIS ASP ALA ASN TYR ASN SER CYS THR VAL ASN GLY GLY VAL ASN THR THR LEU CYS PRO ASP GLU ALA THR CYS GLY LYS ASN CYS PHE ILE GLU GLY VAL ASP TYR ALA ALA SER GLY VAL THR THR SER GLY SER SER LEU THR MET ASN GLN TYR MET PRO SER SER SER GLY GLY TYR SER SER VAL SER PRO ARG LEU TYR LEU LEU ASP SER ASP GLY GLU TYR VAL MET LEU LYS LEU ASN GLY GLN GLU LEU SER PHE ASP VAL ASP LEU SER ALA LEU PRO CYS GLY GLU ASN GLY SER LEU TYR LEU SER GLN MET ASP GLU ASN GLY GLY ALA ASN GLN TYR ASN THR ALA GLY ALA ASN TYR GLY SER GLY TYR CYS ASP ALA GLN CYS PRO VAL GLN THR TRP ARG ASN GLY THR LEU ASN THR SER HIS GLN GLY PHE CYS CYS ASN GLU MET ASP ILE LEU GLU GLY ASN SER ARG ALA ASN ALA LEU THR PRO HIS SER CYS THR ALA THR ALA CYS ASP SER ALA GLY CYS GLY PHE ASN PRO TYR GLY SER GLY TYR LYS SER TYR TYR GLY PRO GLY ASP THR VAL ASP THR SER LYS THR PHE THR ILE ILE THR GLN PHE ASN THR ASP ASN GLY SER PRO SER GLY ASN LEU VAL SER ILE THR ARG LYS TYR GLN GLN ASN GLY VAL ASP ILE PRO SER ALA GLN PRO GLY GLY ASP THR ILE SER SER CYS PRO SER ALA SER ALA TYR GLY GLY LEU ALA THR MET GLY LYS ALA LEU SER SER GLY MET VAL LEU VAL PHE SER ILE TRP ASN ASP ASN SER GLN TYR MET ASN TRP LEU ASP SER GLY ASN ALA GLY PRO CYS SER SER THR GLU GLY ASN PRO SER ASN ILE LEU ALA ASN ASN PRO ASN THR HIS VAL VAL PHE SER ASN ILE ARG TRP GLY ASP ILE GLY SER THR THR ASN SER THR ALA PRO PRO PRO PRO PRO ALA SER SER THR THR PHE SER THR THR ARG ARG SER SER THR THR SER SER SER PRO SER CYS THR GLN THR HIS TRP GLY GLN CYS GLY GLY ILE GLY TYR SER GLY CYS LYS THR CYS THR SER GLY THR THR CYS GLN TYR SER ASN ASP TYR TYR SER GLN CYS LEU []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = Inference(args.model_dir,\n",
    "                  args.arch,\n",
    "                  embed_size=args.embed_size,\n",
    "                  hidden_size=args.hidden_size,\n",
    "                  dropout=args.dropout,\n",
    "                  max_length=args.max_length\n",
    "                  )\n",
    "\n",
    "inputs = [eg5, eg7]\n",
    "\n",
    "#inputs = [data[i][0] for i in res[:2]]\n",
    "outputs = m.predict(inputs)\n",
    "\n",
    "for a, b in zip(inputs, outputs):\n",
    "    print('input  :', a)\n",
    "    print('predict:', b[0], b[1])\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3cd0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf5ef44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
